{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://localhost:8081/notebooks/git/recsys20/working/0324_6_3_lgb_feat_engr-1e7.ipynb\n",
    "- http://localhost:8081/notebooks/git/recsys20/working/mdl0404_1__xgb_mean_encode.ipynb\n",
    "- http://localhost:8081/notebooks/git/recsys20/working/eda_0404_1.ipynb#v.s.-target\n",
    "- https://www.kaggle.com/discdiver/category-encoders-examples\n",
    "- https://www.kaggle.com/snakayama/lightgbm-using-optuna-optuna-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_total 148,075,238, test_total 14,000,000\n",
      "['2020-03-17 02:32:24', '2020-04-06 00:35:47']\n",
      "['2020-02-06 00:00:00', '2020-02-12 23:59:59']\n",
      "['2020-02-13 00:00:00', '2020-02-19 23:59:59']\n"
     ]
    }
   ],
   "source": [
    "TGT='RTwCmnt'\n",
    "PRFX='RTwCmnt0411_1'\n",
    "\n",
    "trntmstmp=1584412344\n",
    "tsttmstmp=1586133347\n",
    "\n",
    "tm_trn_min,tm_trn_max=(1580947200, 1581551999)\n",
    "tm_tst_min,tm_tst_max=(1581552000, 1582156799)\n",
    "\n",
    "SEED=101\n",
    "\n",
    "valsz = int(5e5)#int(1e5)\n",
    "trnsz = int(5e5)#int(5e5)\n",
    "\n",
    "train_total=148075238\n",
    "test_total=int(1.4e7)\n",
    "print(f'train_total {train_total:,}, test_total {test_total:,}')\n",
    "\n",
    "\n",
    "import datetime\n",
    "def showtm(tm): return datetime.datetime.fromtimestamp(tm).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print([showtm(tm) for tm in (trntmstmp, tsttmstmp)])\n",
    "print([showtm(tm) for tm in (tm_trn_min,tm_trn_max)])\n",
    "print([showtm(tm) for tm in (tm_tst_min,tm_tst_max)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCOL retwt_cmmnt\n",
      "{'Retweet': 'retwt', 'Reply': 'reply', 'Like': 'like', 'RTwCmnt': 'retwt_cmmnt'}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter,defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "import pickle\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "import gc\n",
    "\n",
    "import optuna\n",
    "# optuna.logging.CRITICAL, optuna.logging.FATAL\n",
    "# optuna.logging.ERROR\n",
    "# optuna.logging.WARNING, optuna.logging.WARN\n",
    "# optuna.logging.INFO\n",
    "# optuna.logging.DEBUG\n",
    "# optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "import optuna.integration.lightgbm as lgb\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "import datetime\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def iou(s1,s2):\n",
    "    return len(s1&s2) / len(s1|s2)\n",
    "\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "p_out=f'{HOME}/output/{PRFX}'\n",
    "Path(p_out).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, log_loss\n",
    "\n",
    "def compute_prauc(pred, gt):\n",
    "    prec, recall, thresh = precision_recall_curve(gt, pred)\n",
    "    prauc = auc(recall, prec)\n",
    "    return prauc\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "    positive = len([x for x in gt if x == 1])\n",
    "    ctr = positive/float(len(gt))\n",
    "    return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "# https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
    "# How to use the function?\n",
    "# Letâ€™s say your goal is to generate a model that shows the credit default probabilities and your original \n",
    "# training data has 50,000 rows with only 500 of them labeled as target class. When you sample your non-target \n",
    "# instances randomly and reduce the total row count to 10,000, while conserving 500 target rows, our calibration\n",
    "# function becomes:\n",
    "# calibration(model_results, 50000, 500, 10000, 500)\n",
    "# Here model_results is your model probability output array. After you train your model and put the results in it, your function is ready to use. \n",
    "def calibration(data, train_pop, target_pop, sampled_train_pop, sampled_target_pop):\n",
    "    calibrated_data = ((data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop)) /\n",
    "    (((1 - data) * (1 - target_pop / train_pop) / (1 - sampled_target_pop / sampled_train_pop)) +\n",
    "     (data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop))))\n",
    "    return calibrated_data\n",
    "\n",
    "\n",
    "cols=['toks','hshtgs','twtid','media','links','domns','twttyp','lang','tm','u1id','u1_fllwer_cnt','u1_fllwing_cnt','u1_vrfed','u1_create_tm','u2id','u2_fllwer_cnt','u2_fllwng_cnt','u2_vrfed','u2_create_tm','u1_fllw_u2','reply_tm','retwt_tm','retwt_cmmnt_tm','like_tm',]\n",
    "\n",
    "cols_val = cols[:-4]\n",
    "cols_tgt_tmstmp=[ 'retwt_tm', 'reply_tm', 'like_tm', 'retwt_cmmnt_tm',]\n",
    "cols_tgt=[o.split('_tm')[0] for o in cols_tgt_tmstmp]\n",
    "tgts             = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "assert cols_tgt == ['retwt',  'reply','like','retwt_cmmnt',]\n",
    "tgt2col = dict(zip(tgts, cols_tgt))\n",
    "TCOL=tgt2col[TGT]\n",
    "print('TCOL', TCOL)\n",
    "print(tgt2col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prp_tgt(df):\n",
    "    df[cols_tgt]=df[cols_tgt_tmstmp].notna()\n",
    "    df.drop(columns=cols_tgt_tmstmp, inplace=True)\n",
    "    display(df[cols_tgt].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "retwt          0.112638\n",
       "reply          0.027980\n",
       "like           0.439010\n",
       "retwt_cmmnt    0.007676\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.17 s, sys: 530 ms, total: 5.7 s\n",
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfval = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,nrows=valsz)\n",
    "print(dfval.shape)\n",
    "prp_tgt(dfval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maybe oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,nrows=5)\n",
    "# dfval = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,nrows=2)\n",
    "# dftrn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,skiprows=2,nrows=3)\n",
    "# display(df.twtid)\n",
    "# display(dfval.twtid)\n",
    "# display(dftrn.twtid)\n",
    "\n",
    "# 0    D4D1EBDE74F74C5DA529959AF979625C\n",
    "# 1    BFB529DAB6D384EB83E899A72AB3830D\n",
    "# 2    519078C7834E9642508F72A6C2D0F3B7\n",
    "# 3    52AAE9E33EFAC8C478C57B31A9E31ED1\n",
    "# 4    89C1298C55EB3D68E2784F0BFB69E6F8\n",
    "# Name: twtid, dtype: object\n",
    "# 0    D4D1EBDE74F74C5DA529959AF979625C\n",
    "# 1    BFB529DAB6D384EB83E899A72AB3830D\n",
    "# Name: twtid, dtype: object\n",
    "# 0    519078C7834E9642508F72A6C2D0F3B7\n",
    "# 1    52AAE9E33EFAC8C478C57B31A9E31ED1\n",
    "# 2    89C1298C55EB3D68E2784F0BFB69E6F8\n",
    "# Name: twtid, dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5750000, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "retwt          0.113120\n",
       "reply          0.027393\n",
       "like           0.439475\n",
       "retwt_cmmnt    0.007757\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 5.29 s, total: 1min 6s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if TGT in ('Retweet','Like'): trnpop=trnsz\n",
    "if TGT=='Reply': trnpop=trnsz*3.7\n",
    "if TGT=='RTwCmnt': trnpop=trnsz*11.5\n",
    "assert trnpop<train_total\n",
    "\n",
    "dftrn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,\n",
    "                     skiprows=valsz, nrows=trnpop)\n",
    "print(dftrn.shape)\n",
    "prp_tgt(dftrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 24) 0.089206\n",
      "5750000 44603 500000 44603\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toks</th>\n",
       "      <th>hshtgs</th>\n",
       "      <th>twtid</th>\n",
       "      <th>media</th>\n",
       "      <th>links</th>\n",
       "      <th>domns</th>\n",
       "      <th>twttyp</th>\n",
       "      <th>lang</th>\n",
       "      <th>tm</th>\n",
       "      <th>u1id</th>\n",
       "      <th>u1_fllwer_cnt</th>\n",
       "      <th>u1_fllwing_cnt</th>\n",
       "      <th>u1_vrfed</th>\n",
       "      <th>u1_create_tm</th>\n",
       "      <th>u2id</th>\n",
       "      <th>u2_fllwer_cnt</th>\n",
       "      <th>u2_fllwng_cnt</th>\n",
       "      <th>u2_vrfed</th>\n",
       "      <th>u2_create_tm</th>\n",
       "      <th>u1_fllw_u2</th>\n",
       "      <th>retwt</th>\n",
       "      <th>reply</th>\n",
       "      <th>like</th>\n",
       "      <th>retwt_cmmnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>101\\t106005\\t25054\\t173\\t26578\\t11259\\t34768\\t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5621D6D1BF0187714D7939A548490B2E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07F4839C08DE4D72B0B62E4AA3B44AFA</td>\n",
       "      <td>CFAEB8CECABB888C2B2F8E24D4FFB291</td>\n",
       "      <td>TopLevel</td>\n",
       "      <td>ECED8A16BE2A5E8871FD55F4842F16B1</td>\n",
       "      <td>1581265760</td>\n",
       "      <td>0344E02433F065C26201B3BB1AAA40E8</td>\n",
       "      <td>1305792</td>\n",
       "      <td>102</td>\n",
       "      <td>True</td>\n",
       "      <td>1250373764</td>\n",
       "      <td>06EA0B8FB004AFD3383F53FEB3539ECA</td>\n",
       "      <td>256</td>\n",
       "      <td>724</td>\n",
       "      <td>False</td>\n",
       "      <td>1249307691</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>101\\t41113\\t146\\t41541\\t58768\\t85110\\t10454\\t1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF2EDD10CD8D4EFF8A3DF5285D78CB99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quote</td>\n",
       "      <td>D3164C7FBCF2565DDF915B1B3AEFB1DC</td>\n",
       "      <td>1581069466</td>\n",
       "      <td>7B7C09388456C0B9B6B6A61A11C60FB9</td>\n",
       "      <td>313</td>\n",
       "      <td>852</td>\n",
       "      <td>False</td>\n",
       "      <td>1262677136</td>\n",
       "      <td>06EA0BEC97C5976D51DAC008A423FF64</td>\n",
       "      <td>545</td>\n",
       "      <td>413</td>\n",
       "      <td>False</td>\n",
       "      <td>1233815347</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>101\\t44783\\t10133\\t10154\\t10176\\t60914\\t11643\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1C59F814F14A8F712E78404514CC829C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TopLevel</td>\n",
       "      <td>FA3F382BC409C271E3D6EAF8BE4648DD</td>\n",
       "      <td>1581097149</td>\n",
       "      <td>BA9258113A997F6DBA8C03D2E5B7A2EC</td>\n",
       "      <td>2380</td>\n",
       "      <td>932</td>\n",
       "      <td>False</td>\n",
       "      <td>1488470116</td>\n",
       "      <td>06EB34C6D35E065DC0B30F5B5183701B</td>\n",
       "      <td>1214</td>\n",
       "      <td>437</td>\n",
       "      <td>False</td>\n",
       "      <td>1473612676</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>101\\t56898\\t137\\t27689\\t30783\\t10305\\t61211\\t1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3609D6CF717C7EF925B143F3E22B452F</td>\n",
       "      <td>Video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retweet</td>\n",
       "      <td>2996EB2FE8162C076D070A4C8D6532CD</td>\n",
       "      <td>1580953712</td>\n",
       "      <td>9B7E1E488B04E56D67105BAA9605174F</td>\n",
       "      <td>944</td>\n",
       "      <td>975</td>\n",
       "      <td>False</td>\n",
       "      <td>1513003339</td>\n",
       "      <td>06EB3ADFEB5B0182B664104683C5A5EB</td>\n",
       "      <td>344</td>\n",
       "      <td>211</td>\n",
       "      <td>False</td>\n",
       "      <td>1500711522</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>101\\t12845\\t37583\\t10310\\t10173\\t82669\\t10107\\...</td>\n",
       "      <td>12C21C6E6EF1564DEE890157431DDAD8\\t1B9D1276F79E...</td>\n",
       "      <td>0467DCED50A710815F1300276439B763</td>\n",
       "      <td>Photo</td>\n",
       "      <td>56DAFFF9D8E08D4E295F4C6F8B7D6827</td>\n",
       "      <td>AB0CD6B8058B8FE3EC0F5168D1E00693</td>\n",
       "      <td>TopLevel</td>\n",
       "      <td>06D61DCBBE938971E1EA0C38BD9B5446</td>\n",
       "      <td>1581301119</td>\n",
       "      <td>5307B1672E1C07BB78FCC485A745CC71</td>\n",
       "      <td>52</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>1438619653</td>\n",
       "      <td>06EBF31CE5E0F663E4B431249F9FBF0F</td>\n",
       "      <td>161</td>\n",
       "      <td>747</td>\n",
       "      <td>False</td>\n",
       "      <td>1260382465</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  toks  \\\n",
       "108  101\\t106005\\t25054\\t173\\t26578\\t11259\\t34768\\t...   \n",
       "112  101\\t41113\\t146\\t41541\\t58768\\t85110\\t10454\\t1...   \n",
       "408  101\\t44783\\t10133\\t10154\\t10176\\t60914\\t11643\\...   \n",
       "414  101\\t56898\\t137\\t27689\\t30783\\t10305\\t61211\\t1...   \n",
       "591  101\\t12845\\t37583\\t10310\\t10173\\t82669\\t10107\\...   \n",
       "\n",
       "                                                hshtgs  \\\n",
       "108                                                NaN   \n",
       "112                                                NaN   \n",
       "408                                                NaN   \n",
       "414                                                NaN   \n",
       "591  12C21C6E6EF1564DEE890157431DDAD8\\t1B9D1276F79E...   \n",
       "\n",
       "                                twtid  media  \\\n",
       "108  5621D6D1BF0187714D7939A548490B2E    NaN   \n",
       "112  AF2EDD10CD8D4EFF8A3DF5285D78CB99    NaN   \n",
       "408  1C59F814F14A8F712E78404514CC829C    NaN   \n",
       "414  3609D6CF717C7EF925B143F3E22B452F  Video   \n",
       "591  0467DCED50A710815F1300276439B763  Photo   \n",
       "\n",
       "                                links                             domns  \\\n",
       "108  07F4839C08DE4D72B0B62E4AA3B44AFA  CFAEB8CECABB888C2B2F8E24D4FFB291   \n",
       "112                               NaN                               NaN   \n",
       "408                               NaN                               NaN   \n",
       "414                               NaN                               NaN   \n",
       "591  56DAFFF9D8E08D4E295F4C6F8B7D6827  AB0CD6B8058B8FE3EC0F5168D1E00693   \n",
       "\n",
       "       twttyp                              lang          tm  \\\n",
       "108  TopLevel  ECED8A16BE2A5E8871FD55F4842F16B1  1581265760   \n",
       "112     Quote  D3164C7FBCF2565DDF915B1B3AEFB1DC  1581069466   \n",
       "408  TopLevel  FA3F382BC409C271E3D6EAF8BE4648DD  1581097149   \n",
       "414   Retweet  2996EB2FE8162C076D070A4C8D6532CD  1580953712   \n",
       "591  TopLevel  06D61DCBBE938971E1EA0C38BD9B5446  1581301119   \n",
       "\n",
       "                                 u1id  u1_fllwer_cnt  u1_fllwing_cnt  \\\n",
       "108  0344E02433F065C26201B3BB1AAA40E8        1305792             102   \n",
       "112  7B7C09388456C0B9B6B6A61A11C60FB9            313             852   \n",
       "408  BA9258113A997F6DBA8C03D2E5B7A2EC           2380             932   \n",
       "414  9B7E1E488B04E56D67105BAA9605174F            944             975   \n",
       "591  5307B1672E1C07BB78FCC485A745CC71             52             255   \n",
       "\n",
       "     u1_vrfed  u1_create_tm                              u2id  u2_fllwer_cnt  \\\n",
       "108      True    1250373764  06EA0B8FB004AFD3383F53FEB3539ECA            256   \n",
       "112     False    1262677136  06EA0BEC97C5976D51DAC008A423FF64            545   \n",
       "408     False    1488470116  06EB34C6D35E065DC0B30F5B5183701B           1214   \n",
       "414     False    1513003339  06EB3ADFEB5B0182B664104683C5A5EB            344   \n",
       "591     False    1438619653  06EBF31CE5E0F663E4B431249F9FBF0F            161   \n",
       "\n",
       "     u2_fllwng_cnt  u2_vrfed  u2_create_tm  u1_fllw_u2  retwt  reply   like  \\\n",
       "108            724     False    1249307691       False   True  False  False   \n",
       "112            413     False    1233815347        True   True  False  False   \n",
       "408            437     False    1473612676        True   True   True  False   \n",
       "414            211     False    1500711522        True   True  False  False   \n",
       "591            747     False    1260382465        True   True  False   True   \n",
       "\n",
       "     retwt_cmmnt  \n",
       "108         True  \n",
       "112         True  \n",
       "408         True  \n",
       "414         True  \n",
       "591         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['toks', 'hshtgs', 'twtid', 'media', 'links', 'domns', 'twttyp', 'lang',\n",
       "       'tm', 'u1id', 'u1_fllwer_cnt', 'u1_fllwing_cnt', 'u1_vrfed',\n",
       "       'u1_create_tm', 'u2id', 'u2_fllwer_cnt', 'u2_fllwng_cnt', 'u2_vrfed',\n",
       "       'u2_create_tm', 'u1_fllw_u2', 'retwt', 'reply', 'like', 'retwt_cmmnt'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pop=len(dftrn)\n",
    "sampled_train_pop=trnsz\n",
    "idx_pos = np.where(dftrn[TCOL])[0]\n",
    "target_pop=sampled_target_pop=len(idx_pos)\n",
    "if TGT in ('Reply','RTwCmnt'):\n",
    "    idx_neg0 = np.where(~dftrn[TCOL])[0]\n",
    "    idx_neg = np.random.choice(idx_neg0, trnsz-len(idx_pos), replace=False)\n",
    "    idx = np.concatenate([idx_pos,idx_neg])\n",
    "    dftrn = dftrn.iloc[idx].copy()\n",
    "print(dftrn.shape, dftrn[TCOL].mean())\n",
    "print(train_pop, target_pop, sampled_train_pop, sampled_target_pop)\n",
    "\n",
    "display(dftrn.head())\n",
    "display(dftrn.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prp_df(df, tm_max):\n",
    "    '''\n",
    "    tm_max = tm_trn_max for train tm_tst_max for test\n",
    "    '''\n",
    "    lendf = len(df)\n",
    "    print(dtnow(), 'start')\n",
    "    set_u1 = set(df.u1id)\n",
    "    set_u2 = set(df.u2id)\n",
    "    df['u1inu2']=df.u1id.isin(set_u2)\n",
    "    df['u2inu1']=df.u2id.isin(set_u1)\n",
    "\n",
    "    #counts\n",
    "    df['len_toks'] = df.toks.apply(lambda x: len(x.split('\\t')))\n",
    "    df.drop(columns=['toks'], inplace=True)    \n",
    "    for m in ['Photo', 'Video', 'GIF']:\n",
    "        df[f'n_media_{m}'] = df['media'].fillna('').apply(lambda x: x.split('\\t').count(m))\n",
    "    tgnms = ['hshtgs','media', 'links', 'domns',]\n",
    "    for tgnm in tgnms:\n",
    "        df[f'has_{tgnm}']=df[tgnm].notna()\n",
    "        df[f'lst_{tgnm}'] = df[tgnm].fillna('').apply(lambda x: x.split('\\t') if len(x) else [])\n",
    "        df[f'n_{tgnm}'] = df[f'lst_{tgnm}'].apply(len)  \n",
    "    df.drop(columns=['has_links','n_links'], inplace=True) #duplicates has_domns,n_domns \n",
    "    \n",
    "    #time\n",
    "    dt = pd.to_datetime(df.tm, unit='s')\n",
    "    df['dayofweek'] = dt.dt.dayofweek\n",
    "    df['hour'] = dt.dt.hour\n",
    "    \n",
    "    df['tmdlta_u2u1']  = df.u2_create_tm - df.u1_create_tm\n",
    "    df['tmdlta_twtu1'] = df.tm - df.u1_create_tm\n",
    "    df['tmdlta_twtu2'] = df.tm - df.u2_create_tm\n",
    "\n",
    "    df['twt_age']   = tm_max-df.tm\n",
    "    df['u1_age']    = tm_max-df.u1_create_tm\n",
    "    df['u2_age']    = tm_max-df.u2_create_tm\n",
    "    df.drop(columns=['tm', 'u1_create_tm', 'u2_create_tm'], inplace=True)\n",
    "\n",
    "    #time derived\n",
    "    df['u1_fllwer_cnt_by_age'] = df.u1_fllwer_cnt / df.u1_age\n",
    "    df['u1_fllwng_cnt_by_age'] = df.u2_fllwng_cnt / df.u2_age\n",
    "    \n",
    "    #interaction\n",
    "    df['u1u2']=df.u1id+'_'+df.u2id\n",
    "    df['langhour']=df.lang+'_'+df.hour.astype(str)\n",
    "    \n",
    "\n",
    "    #freq of feature values\n",
    "    print(dtnow(), 'freq of columns using CountEncoder')\n",
    "    encoder = ce.CountEncoder()\n",
    "    encoded = encoder.fit_transform(\n",
    "    df[['twtid', 'twttyp', 'lang', 'u1id', 'u1_fllwing_cnt', 'u1_vrfed', 'u2id', 'u2_fllwer_cnt', 'u2_vrfed', 'u1_fllw_u2', \n",
    "       'n_media_Photo', 'n_media_Video', 'n_media_GIF', \n",
    "       'has_hshtgs', 'n_hshtgs', 'has_media', 'n_media','has_domns', 'n_domns', \n",
    "       'dayofweek', 'hour', 'u1u2', 'langhour']].astype(object))\n",
    "    encoded = encoded.astype(int)/lendf\n",
    "    encoded.columns = [f'frq_{col}' for col in encoded.columns]\n",
    "    df = pd.concat([df,encoded],1)\n",
    "    \n",
    "    #freq of tgnm values\n",
    "    print(dtnow(), 'freq of tags')\n",
    "    for tgnm in tgnms:\n",
    "        vs = [j for i in df[f'lst_{tgnm}'] for j in i]\n",
    "        cnt = Counter(vs)\n",
    "        frq = {k:v/lendf for k,v in cnt.items()}\n",
    "        df[f'sumfrq_{tgnm}']=df[f'lst_{tgnm}'].apply(lambda x: sum([frq.get(o,0) for o in x]))\n",
    "        df[f'maxfrq_{tgnm}']=df[f'lst_{tgnm}'].apply(lambda x: max([frq.get(o,0) for o in x]) if len(x) else 0)\n",
    "    df.drop(columns=tgnms+[f'lst_{tgnm}' for tgnm in tgnms],inplace=True)\n",
    "\n",
    "    print(dtnow(), 'done')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 20:15:47 start\n",
      "2020-04-11 20:16:03 freq of columns using CountEncoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/category_encoders/count.py:255: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  X.loc[:, self.cols] = X.fillna(value=pd.np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 20:16:26 freq of tags\n",
      "2020-04-11 20:16:34 done\n",
      "CPU times: user 42.1 s, sys: 3.96 s, total: 46 s\n",
      "Wall time: 48.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dftrn=prp_df(dftrn, tm_max=tm_trn_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 20:16:35 start\n",
      "2020-04-11 20:16:47 freq of columns using CountEncoder\n",
      "2020-04-11 20:17:03 freq of tags\n",
      "2020-04-11 20:17:11 done\n",
      "CPU times: user 33.6 s, sys: 1.22 s, total: 34.8 s\n",
      "Wall time: 36.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfval=prp_df(dfval, tm_max=tm_trn_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tr vl split and target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk_vl=np.random.rand(len(dftrn))<0.15\n",
    "idxvl=np.where( msk_vl)[0]\n",
    "idxtr=np.where(~msk_vl)[0]\n",
    "\n",
    "dftr = dftrn.iloc[idxtr].copy()\n",
    "dfvl = dftrn.iloc[idxvl].copy()\n",
    "del dftrn\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['twtid', 'twttyp', 'lang', 'u1id', 'u1_fllwer_cnt', 'u1_fllwing_cnt',\n",
       "       'u1_vrfed', 'u2id', 'u2_fllwer_cnt', 'u2_fllwng_cnt', 'u2_vrfed',\n",
       "       'u1_fllw_u2', 'retwt', 'reply', 'like', 'retwt_cmmnt', 'u1inu2',\n",
       "       'u2inu1', 'len_toks', 'n_media_Photo', 'n_media_Video', 'n_media_GIF',\n",
       "       'has_hshtgs', 'n_hshtgs', 'has_media', 'n_media', 'has_domns',\n",
       "       'n_domns', 'dayofweek', 'hour', 'tmdlta_u2u1', 'tmdlta_twtu1',\n",
       "       'tmdlta_twtu2', 'twt_age', 'u1_age', 'u2_age', 'u1_fllwer_cnt_by_age',\n",
       "       'u1_fllwng_cnt_by_age', 'u1u2', 'langhour', 'frq_twtid', 'frq_twttyp',\n",
       "       'frq_lang', 'frq_u1id', 'frq_u1_fllwing_cnt', 'frq_u1_vrfed',\n",
       "       'frq_u2id', 'frq_u2_fllwer_cnt', 'frq_u2_vrfed', 'frq_u1_fllw_u2',\n",
       "       'frq_n_media_Photo', 'frq_n_media_Video', 'frq_n_media_GIF',\n",
       "       'frq_has_hshtgs', 'frq_n_hshtgs', 'frq_has_media', 'frq_n_media',\n",
       "       'frq_has_domns', 'frq_n_domns', 'frq_dayofweek', 'frq_hour', 'frq_u1u2',\n",
       "       'frq_langhour', 'sumfrq_hshtgs', 'maxfrq_hshtgs', 'sumfrq_media',\n",
       "       'maxfrq_media', 'sumfrq_links', 'maxfrq_links', 'sumfrq_domns',\n",
       "       'maxfrq_domns'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.4 s, sys: 2.33 s, total: 40.7 s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "col2tgtenc=['twtid', 'twttyp', 'lang', 'u1id', 'u1_fllwing_cnt', 'u1_vrfed', 'u2id', 'u2_fllwer_cnt', 'u2_vrfed', 'u1_fllw_u2', \n",
    "   'n_media_Photo', 'n_media_Video', 'n_media_GIF', \n",
    "   'has_hshtgs', 'n_hshtgs', 'has_media', 'n_media','has_domns', 'n_domns', \n",
    "   'dayofweek', 'hour', 'u1u2', 'langhour']\n",
    "tgt_encoder = ce.TargetEncoder()\n",
    "encoded_tr = tgt_encoder.fit_transform(dftr[col2tgtenc].astype(object), dftr[TCOL])\n",
    "encoded_vl = tgt_encoder.transform(dfvl[col2tgtenc].astype(object))\n",
    "encoded_val = tgt_encoder.transform(dfval[col2tgtenc].astype(object))\n",
    "\n",
    "tgtenc_columns = [f'tgtenc_{col}' for col in encoded_tr.columns]\n",
    "encoded_tr.columns = tgtenc_columns\n",
    "encoded_vl.columns = tgtenc_columns\n",
    "encoded_val.columns = tgtenc_columns\n",
    "\n",
    "dftr = pd.concat([dftr, encoded_tr], 1)\n",
    "dfvl = pd.concat([dfvl, encoded_vl], 1)\n",
    "dfval = pd.concat([dfval, encoded_val], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_category=['twttyp', 'lang', 'langhour']\n",
    "for df in dftr,dfvl,dfval:\n",
    "    df.drop(columns=['twtid','u1id','u2id','u1u2'], inplace=True)\n",
    "    df[cols_category]=df[cols_category].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_feat = [col for col in dftr.columns if col not in cols_tgt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cols_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(cols_feat))\n",
    "cols_feat=['twttyp',\n",
    " 'lang',\n",
    " 'u1_fllwer_cnt',\n",
    " 'u1_fllwing_cnt',\n",
    " 'u1_vrfed',\n",
    " 'u2_fllwer_cnt',\n",
    " 'u2_fllwng_cnt',\n",
    " 'u2_vrfed',\n",
    " 'u1_fllw_u2',\n",
    " 'u1inu2',\n",
    " 'u2inu1',\n",
    " 'len_toks',\n",
    " 'n_media_Photo',\n",
    " 'n_media_Video',\n",
    " 'n_media_GIF',\n",
    "#  'has_hshtgs',\n",
    " 'n_hshtgs',\n",
    "#  'has_media',\n",
    " 'n_media',\n",
    "#  'has_domns',\n",
    " 'n_domns',\n",
    " 'dayofweek',\n",
    " 'hour',\n",
    " 'tmdlta_u2u1',\n",
    " 'tmdlta_twtu1',\n",
    " 'tmdlta_twtu2',\n",
    " 'twt_age',\n",
    " 'u1_age',\n",
    " 'u2_age',\n",
    " 'u1_fllwer_cnt_by_age',\n",
    " 'u1_fllwng_cnt_by_age',\n",
    " 'langhour',\n",
    "#  'frq_twtid',\n",
    "#  'frq_twttyp',\n",
    "#  'frq_lang',\n",
    "#  'frq_u1id',\n",
    "#  'frq_u1_fllwing_cnt',\n",
    "#  'frq_u1_vrfed',\n",
    "#  'frq_u2id',\n",
    "#  'frq_u2_fllwer_cnt',\n",
    "#  'frq_u2_vrfed',\n",
    "#  'frq_u1_fllw_u2',\n",
    "#  'frq_n_media_Photo',\n",
    "#  'frq_n_media_Video',\n",
    "#  'frq_n_media_GIF',\n",
    "#  'frq_has_hshtgs',\n",
    "#  'frq_n_hshtgs',\n",
    "#  'frq_has_media',\n",
    "#  'frq_n_media',\n",
    "#  'frq_has_domns',\n",
    "#  'frq_n_domns',\n",
    "#  'frq_dayofweek',\n",
    "#  'frq_hour',\n",
    "#  'frq_u1u2',\n",
    "#  'frq_langhour',\n",
    "#  'sumfrq_hshtgs',\n",
    "#  'maxfrq_hshtgs',\n",
    "#  'sumfrq_media',\n",
    "#  'maxfrq_media',\n",
    "#  'sumfrq_links',\n",
    "#  'maxfrq_links',\n",
    "#  'sumfrq_domns',\n",
    "#  'maxfrq_domns',\n",
    "#  'tgtenc_twtid',\n",
    "#  'tgtenc_twttyp',\n",
    "#  'tgtenc_lang',\n",
    "#  'tgtenc_u1id',\n",
    "#  'tgtenc_u1_fllwing_cnt',\n",
    "#  'tgtenc_u1_vrfed',\n",
    "#  'tgtenc_u2id',\n",
    "#  'tgtenc_u2_fllwer_cnt',\n",
    "#  'tgtenc_u2_vrfed',\n",
    "#  'tgtenc_u1_fllw_u2',\n",
    "#  'tgtenc_n_media_Photo',\n",
    "#  'tgtenc_n_media_Video',\n",
    "#  'tgtenc_n_media_GIF',\n",
    "#  'tgtenc_has_hshtgs',\n",
    "#  'tgtenc_n_hshtgs',\n",
    "#  'tgtenc_has_media',\n",
    "#  'tgtenc_n_media',\n",
    "#  'tgtenc_has_domns',\n",
    "#  'tgtenc_n_domns',\n",
    "#  'tgtenc_dayofweek',\n",
    "#  'tgtenc_hour',\n",
    "#  'tgtenc_u1u2',\n",
    "#  'tgtenc_langhour'\n",
    "          ]\n",
    "print(len(cols_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['PRFX'] = PRFX\n",
    "results['TGT'] = TGT\n",
    "results['cols_feat'] = cols_feat\n",
    "results['tgt_encoder'] = tgt_encoder\n",
    "results['col2tgtenc'] = col2tgtenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': 0,    \n",
    "}\n",
    "results['params'] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/_experimental.py:87: ExperimentalWarning: train is experimental (supported from v0.18.0). The interface can change in the future.\n",
      "  ExperimentalWarning\n",
      "tune_feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttr's binary_logloss: 0.265768\tvl's binary_logloss: 0.282753\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtr = lgb.Dataset(dftr[cols_feat], label=dftr[TCOL])\n",
    "dvl = lgb.Dataset(dfvl[cols_feat], label=dfvl[TCOL])\n",
    "best_params, tuning_history = {}, []\n",
    "evalres = {}\n",
    "evallist = [(dtr, 'train'), (dvl, 'eval')]\n",
    "bst = lgb.train(params=params, \n",
    "                train_set=dtr, \n",
    "                num_boost_round=50000,\n",
    "                valid_sets=[dtr, dvl],\n",
    "                valid_names=['tr','vl'],\n",
    "                best_params=best_params,\n",
    "                tuning_history=tuning_history,\n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds=100,\n",
    "                evals_result=evalres,\n",
    "               )\n",
    "results['bst'] = bst\n",
    "results['evalres'] = evalres\n",
    "results['best_params']=best_params\n",
    "results['tuning_history']=tuning_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tr vl trajec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(evalres['tr']['binary_logloss'])\n",
    "plt.plot(evalres['vl']['binary_logloss'])\n",
    "plt.title(f\"logloss; best_iteration {bst.best_iteration}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = lgb.plot_importance(bst, height=0.8, max_num_features=50, figsize=(10,15))\n",
    "ax.grid(False, axis=\"y\")\n",
    "ax.set_title(f'Estimated feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([bst.feature_name(), bst.feature_importance()]).T.sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2imp = dict(zip(bst.feature_name(), bst.feature_importance()))\n",
    "sorted(col2imp.items(), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[o[0] for o in sorted(col2imp.items(), key=lambda x: -x[1]) if o[1]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prdtr = bst.predict(dftr[cols_feat],num_iteration=bst.best_iteration)\n",
    "prdvl = bst.predict(dfvl[cols_feat],num_iteration=bst.best_iteration)\n",
    "prdval0 = bst.predict(dfval[cols_feat],num_iteration=bst.best_iteration)\n",
    "prdval = calibration(prdval0, train_pop, target_pop, sampled_train_pop, sampled_target_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ytr,yvl,yval=[df[TCOL].values for df in (dftr,dfvl,dfval)]\n",
    "\n",
    "auc_tr=compute_prauc(prdtr, ytr)\n",
    "rce_tr=compute_rce(prdtr, ytr)\n",
    "auc_vl=compute_prauc(prdvl, yvl)\n",
    "rce_vl=compute_rce(prdvl, yvl)\n",
    "auc_val=compute_prauc(prdval, yval)\n",
    "rce_val=compute_rce(prdval, yval)\n",
    "\n",
    "results['scrs'] = {}\n",
    "results['scrs']['auc_tr']=auc_tr\n",
    "results['scrs']['rce_tr']=rce_tr\n",
    "results['scrs']['auc_vl']=auc_vl\n",
    "results['scrs']['rce_vl']=rce_vl\n",
    "results['scrs']['auc_val']=auc_val\n",
    "results['scrs']['rce_val']=rce_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'auc_tr:  {auc_tr:.4f}')\n",
    "print(f'auc_vl:  {auc_vl:.4f}')\n",
    "print(f'auc_val: {auc_val:.4f}')\n",
    "print()\n",
    "print(f'rce_tr:  {rce_tr:.4f}')\n",
    "print(f'rce_vl:  {rce_vl:.4f}')\n",
    "print(f'rce_val: {rce_val:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'-{auc_val:.4f}-{rce_val:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results, open(f'{p_out}/results_{PRFX}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load( open(f'{p_out}/results_{PRFX}.p', 'rb'))\n",
    "bst = results['bst']\n",
    "col2tgtenc = results['col2tgtenc']\n",
    "cols_feat = results['cols_feat']\n",
    "tgt_encoder = results['tgt_encoder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst=pd.read_csv(\n",
    "    f'{p_in}/val_{tsttmstmp}.tsv',\n",
    "    sep='\\x01', header=None, names=cols_val, \n",
    "    nrows=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst=prp_df(dftst, tm_max=tm_tst_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_tst = tgt_encoder.transform(dftst[col2tgtenc].astype(object))\n",
    "tgtenc_columns = [f'tgtenc_{col}' for col in encoded_tst.columns]\n",
    "encoded_tst.columns = tgtenc_columns\n",
    "dftst = pd.concat([dftst, encoded_tst], 1)\n",
    "dftst.drop(columns=['u1id','u1u2'], inplace=True)\n",
    "cols_category=['twttyp', 'lang', 'langhour']\n",
    "dftst[cols_category]=dftst[cols_category].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prdtst0 = bst.predict(dftst[cols_feat],num_iteration=bst.best_iteration)\n",
    "prdtst = calibration(prdtst0, train_pop, target_pop, sampled_train_pop, sampled_target_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub_ids = dftst[['twtid','u2id',]]\n",
    "dfsub = dfsub_ids.copy()\n",
    "dfsub['scr'] = prdtst\n",
    "dfsub.to_csv(f'{p_out}/{TGT}__{PRFX}.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
