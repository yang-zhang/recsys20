{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-03-17 02:32:24', '2020-03-24 17:09:45']\n",
      "['2020-02-06 00:00:00', '2020-02-13 00:00:00']\n"
     ]
    }
   ],
   "source": [
    "PRFX='0323_6'\n",
    "trntmstmp=1584412344\n",
    "valtmstmp=1585069785\n",
    "import datetime\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (trntmstmp, valtmstmp)])\n",
    "\n",
    "grand_total=1.5e8\n",
    "MIN_TM_TRN=1580947200\n",
    "MIN_TM_TST=1581552000\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (MIN_TM_TRN, MIN_TM_TST)])\n",
    "\n",
    "\n",
    "CHNKSZ=1e6\n",
    "POST_RATE_WANTED=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Retweet': 'retwt',\n",
       " 'Reply': 'reply',\n",
       " 'Like': 'like',\n",
       " 'RTwCmnt': 'retwt_cmmnt'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# import dask\n",
    "# print('dask.__version__', dask.__version__)\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "# import dask_xgboost\n",
    "# import dask.dataframe as dd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "from dask.distributed import Client\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from functools import reduce\n",
    "import datetime\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "SEED=101\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "p_out=f'{HOME}/output/{PRFX}'\n",
    "Path(p_out).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, log_loss\n",
    "\n",
    "def compute_prauc(pred, gt):\n",
    "    prec, recall, thresh = precision_recall_curve(gt, pred)\n",
    "    prauc = auc(recall, prec)\n",
    "    return prauc\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "    positive = len([x for x in gt if x == 1])\n",
    "    ctr = positive/float(len(gt))\n",
    "    return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "# https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
    "# How to use the function?\n",
    "# Letâ€™s say your goal is to generate a model that shows the credit default probabilities and your original \n",
    "# training data has 50,000 rows with only 500 of them labeled as target class. When you sample your non-target \n",
    "# instances randomly and reduce the total row count to 10,000, while conserving 500 target rows, our calibration\n",
    "# function becomes:\n",
    "# calibration(model_results, 50000, 500, 10000, 500)\n",
    "# Here model_results is your model probability output array. After you train your model and put the results in it, your function is ready to use. \n",
    "\n",
    "def calibration(data, train_pop, target_pop, sampled_train_pop, sampled_target_pop):\n",
    "    calibrated_data = \\\n",
    "    ((data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop)) /\n",
    "    ((\n",
    "        (1 - data) * (1 - target_pop / train_pop) / (1 - sampled_target_pop / sampled_train_pop)\n",
    "     ) +\n",
    "     (\n",
    "        data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop)\n",
    "     )))\n",
    "\n",
    "    return calibrated_data\n",
    "\n",
    "cols=[\n",
    "'toks',\n",
    "'hshtgs',\n",
    "'twtid',\n",
    "'media',\n",
    "'links',\n",
    "'domns',\n",
    "'twttyp',\n",
    "'lang',\n",
    "'tm',\n",
    "\n",
    "'u1id',\n",
    "'u1_fllwer_cnt',\n",
    "'u1_fllwng_cnt',\n",
    "'u1_vrfed',\n",
    "'u1_create_tm',\n",
    "\n",
    "'u2id',\n",
    "'u2_fllwer_cnt',\n",
    "'u2_fllwng_cnt',\n",
    "'u2_vrfed',\n",
    "'u2_create_tm',\n",
    "\n",
    "'u1_fllw_u2',\n",
    "'reply_tm',\n",
    "'retwt_tm',\n",
    "'retwt_cmmnt_tm',\n",
    "'like_tm',\n",
    "]\n",
    "\n",
    "cols_val = cols[:-4]\n",
    "cols_tgt_tmstmp=[\n",
    "    'retwt_tm',\n",
    "    'reply_tm',\n",
    "    'like_tm',\n",
    "    'retwt_cmmnt_tm',\n",
    "]\n",
    "cols_tgt=[o.split('_tm')[0] for o in cols_tgt_tmstmp]\n",
    "tgts             = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "assert cols_tgt == ['retwt',  'reply','like','retwt_cmmnt',]\n",
    "ntgts=len(tgts)\n",
    "\n",
    "tgt2col=dict(zip(tgts,cols_tgt))\n",
    "tgt2col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get maps from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfval=dd.read_csv(\n",
    "#     f'{p_in}/val_{valtmstmp}.tsv',\n",
    "#     sep='\\x01', header=None, names=cols_val,)\n",
    "# lang2cnt=dict(dfval.lang.value_counts().compute())\n",
    "# ttl=sum(lang2cnt.values())\n",
    "# lang2perc={k:v/ttl for k,v in lang2cnt.items()}\n",
    "langs=['D3164C7FBCF2565DDF915B1B3AEFB1DC', '22C448FF81263D4BAF2A176145EE9EAD', '06D61DCBBE938971E1EA0C38BD9B5446', 'ECED8A16BE2A5E8871FD55F4842F16B1', 'B9175601E87101A984A50F8A62A1C374', '4DC22C3F31C5C43721E6B5815A595ED6', '167115458A0DBDFF7E9C0C53A83BAC9B', '125C57F4FA6D4E110983FB11B52EFD4E', '022EC308651FACB02794A8147AEE1B78', 'FA3F382BC409C271E3D6EAF8BE4648DD', '9BF3403E0EB7EA8A256DA9019C0B0716', '975B38F44D65EE42A547283787FF5A21', '2996EB2FE8162C076D070A4C8D6532CD', 'FF60A88F53E63000266F8B9149E35AD9', '717293301FE296B0B61950D041485825', '3E16B11B7ADE3A22DDFC4423FBCEAD5D', '3820C29CBCA409A33BADF68852057C4A', '9ECD42BC079C20F156F53CB3B99E600E', '76B8A9C3013AE6414A3E6012413CDC3B', 'AEF22666801F0A5846D853B9CEB2E327', '190BA7DA361BC06BC1D7E824C378064D', '1FFD2FE4297F5E70EBC6C3230D95CB9C', 'A0C7021AD8299ADF0C9EBE326C115F6F', 'D413F5FE5236E5650A46FD983AB39212', '48236EC80FDDDFADE99420ABC9210DDF', '691890251F2B9FF922BE6D3699ABEFD2', '920502FAA080485768AA89BC96A55C47', '0331BF70E606D62D92C96CE9AD71A7CF', '89616CFF8EC8637092F885C7EFF43D74', '06BEAB41D66CCFF329D1ED8BA120A6C2', '60FBA0E834CC59D647C3599AD763FFDF', 'C7A400D9AD489ACF673CF12FBB80AAE5', 'E59EF8BB86A6D815331DDF4C467CE0C7', '4249CE88433AEA3F8DCEECF008B3CB95', '544FA32458C903F1125FE6598300A047', 'CB11E9CF42BD0A1BAD5E27BF3422D99D', '3A85BCEC571C3F5AB1069E4924189177', 'FF7EABB5A382356D54D9C41BA0125E09', 'E7BB61D2A87C1E72DF1C7BC292B86A1C', '69C4A33B9AD29AF883D60BA61CC08702', 'F4FD40A716F1572C9A28E9CAA58BE3A5', '259A6F6DFD672CB1F883CBEC01B99F2D', '6431A618DCF7F4CB7F62A95A39BAB77A', '3121F7240D488F74EEED9312E174B217', '54208B51D44E7D91DC2F3DD02ADEDEC2', 'DBEEFB80F8A314311E2B4BD593E11DFE', 'B6D90127A09AB1229731898AEF9D4D7C', 'F3E1016563360F9434FA986CA86C249C', '2216D01F7B48554E4211021A46816FCF', '1BC639981AE88E09129594B11F894A21', 'C942E369C88CE7C56E69A84D04319FF0', '57ADD4576E2AD6648E9B2DE32F3462A5', 'AC1F0671A4B0D5B8112F87DE7B490E6D', 'C2EF5FABE7619D8A333D5F0FF76E1BFA', 'AA0254541959271ED3453119B787D0C3', 'A6B70CDF8C7B934D4A218CA9B6B7FDB4', 'BF477808A37E3E4E9C5D9F1839E8519E', '97F81BD92A1ACA3F1F43C154E689350F', '60A3DB168094D41241E45E0DE3539BC0', '12D8CEB94F89D11D7EB95EAE9689B009', 'F73266A79468BB89C4325FDEDB0B533C', '4690215948DBF6872B8ED1C2BC87B17E', 'D18801336202297E6484F634CAC6592E', '2E18F6F53E3CF073911AF0A93BBE5373', 'B2235C8B73239FDC5780DD132419833A', '515E873C86EE1577E75FA2387B7FA59E',]\n",
    "\n",
    "# dfval.twttyp.value_counts().compute()\n",
    "# TopLevel    2932\n",
    "# Retweet      994\n",
    "# Quote        213\n",
    "twttyps=['TopLevel','Retweet','Quote']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prp_df(df, istrn=True):\n",
    "    tm_min = MIN_TM_TRN if istrn else MIN_TM_TST\n",
    "    df['len_toks'] = df.toks.apply(len)\n",
    "    for media in ['Photo', 'Video', 'GIF']:\n",
    "        df[f'has_media_{media}'] = df.media.fillna('').apply(lambda x: media in x)\n",
    "    for col in ['hshtgs', 'links', 'domns',]:\n",
    "        df[f'num_{col}'] = df[col].fillna('').apply(lambda x: len(x.split('\\t')) if len(x) else 0)\n",
    "    \n",
    "    df['twt_age'] = df.tm - tm_min\n",
    "    df['u1_age']  = df.tm - df.u1_create_tm\n",
    "    df['u2_age']  = df.tm - df.u2_create_tm\n",
    "        \n",
    "    tm_dt=pd.to_datetime(df.tm, unit='s')\n",
    "    df['tm_dayofweek']=tm_dt.dt.dayofweek\n",
    "    df['tm_hour']=tm_dt.dt.hour\n",
    "    \n",
    "    df['tmdlta_u2u1']  = df.u2_create_tm - df.u1_create_tm\n",
    "    \n",
    "    df['u1_fllwer_cnt_by_age'] = df.u1_fllwer_cnt / df.u1_age\n",
    "    df['u1_fllwng_cnt_by_age'] = df.u2_fllwng_cnt / df.u2_age\n",
    "    \n",
    "    for typ in twttyps:\n",
    "        df[f'twttyp_{typ}']=(df.twttyp==typ).astype('int8')\n",
    "\n",
    "    for lang in langs:\n",
    "        df[f'lang_{lang}']=(df.lang==lang).astype('int8')\n",
    "    if istrn: \n",
    "        df[cols_tgt]=df[cols_tgt_tmstmp].notna().astype('int8')\n",
    "        df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns', 'twttyp', 'lang', \n",
    "                                       'tm', 'u1_create_tm','u2_create_tm', 'u1id', 'u2id', 'twtid', ]+cols_tgt_tmstmp, )\n",
    "    else:\n",
    "        df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns', 'twttyp', 'lang', \n",
    "                                       'tm', 'u1_create_tm','u2_create_tm', 'u1id', ])        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ls -hlS $p_in | grep {trntmstmp} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000000.0, 150.0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_total, grand_total/CHNKSZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24 03:25:07 chunk 0\n",
      "['2020-02-06 00:00:00', '2020-02-12 23:59:59']\n"
     ]
    }
   ],
   "source": [
    "chnks_trn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',\n",
    "                    header=None,names=cols, \n",
    "                        chunksize=CHNKSZ)\n",
    "# first chunk as validate data\n",
    "for ichnk,df in enumerate(chnks_trn):\n",
    "    print(dtnow(), 'chunk', ichnk)\n",
    "    print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') \n",
    "           for o in (df.tm.min(), df.tm.max())])\n",
    "    dfvalid = prp_df(df)\n",
    "    break\n",
    "dfvalid.shape\n",
    "\n",
    "cols_feat=[o for o in dfvalid.columns if o not in cols_tgt]\n",
    "\n",
    "# Xvl,yvl=dfvl[cols_feat],dfvl[cols_tgt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trnval data func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdftrvl(tgt):\n",
    "    print(tgt)\n",
    "    tgtcol=tgt2col[tgt]\n",
    "    chnks_trn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',\n",
    "                        header=None,names=cols, \n",
    "                            chunksize=CHNKSZ)\n",
    "    len_df_wanted = int(CHNKSZ)\n",
    "    # retwt          0.113031\n",
    "    # reply          0.027488\n",
    "    # like           0.439499\n",
    "    # retwt_cmmnt    0.007742\n",
    "    pos_rate_wanted = POST_RATE_WANTED\n",
    "    n_pos_wanted = int(len_df_wanted*pos_rate_wanted)\n",
    "    print('n_pos_wanted', n_pos_wanted)\n",
    "    np.random.seed(SEED)\n",
    "    lst_df = []\n",
    "    n_pos_ttl = 0\n",
    "    for ichnk,df in enumerate(chnks_trn):\n",
    "        #skip first chunk (it was validate data)\n",
    "        if ichnk==0: continue\n",
    "        print(dtnow(), 'chunk', ichnk)\n",
    "        df = prp_df(df)\n",
    "        n_pos_ttl+= df[tgtcol].sum()\n",
    "        lst_df.append(df)\n",
    "        if n_pos_ttl>=n_pos_wanted: break\n",
    "\n",
    "    df = pd.concat(lst_df)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/questions/28556942/pandas-remove-rows-at-random-without-shuffling-dataset\n",
    "    idx_neg=np.where(df[tgtcol]==0)[0]\n",
    "    n_neg = len(idx_neg)\n",
    "    n_pos = len(df)-len(idx_neg)\n",
    "    n_neg2keep = len_df_wanted-n_pos\n",
    "    n_neg2rmv = n_neg-n_neg2keep\n",
    "    idx_neg2rmv = np.random.choice(idx_neg, n_neg2rmv, replace=False)\n",
    "    dftrvl = df.drop(idx_neg2rmv)\n",
    "    dftrvl = dftrvl.sample(len(dftrvl))\n",
    "    print('dftrvl.shape:',dftrvl.shape,'dftrvl[tgtcol].mean():',dftrvl[tgtcol].mean())\n",
    "\n",
    "    pops={\n",
    "        'train_pop':len(df),\n",
    "        'target_pop':n_pos,\n",
    "        'sampled_train_pop':len_df_wanted,\n",
    "        'sampled_target_pop':n_pos,\n",
    "    }\n",
    "    print(pops)\n",
    "    return dftrvl, pops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params,dtr,dvl):\n",
    "    print(params)\n",
    "    evals_result = {}\n",
    "    evallist = [(dtr, 'train'), (dvl, 'eval')]\n",
    "    bst = lgb.train(params=params, train_set=dtr, \n",
    "                    num_boost_round=10,#1000, \n",
    "                    valid_sets=[dvl],\n",
    "                    evals_result=evals_result, \n",
    "                    verbose_eval=5,\n",
    "                    early_stopping_rounds=5)\n",
    "    return bst,evals_result\n",
    "\n",
    "def valid(bst,dftr,dfvl):\n",
    "#     prdtr = bst.predict(dtr, ntree_limit=bst.best_ntree_limit)\n",
    "#     prdvl = bst.predict(dvl, ntree_limit=bst.best_ntree_limit)\n",
    "    prdtr = bst.predict(dftr[cols_feat])\n",
    "    prdvl = bst.predict(dfvl[cols_feat])\n",
    "    return prdtr,prdvl\n",
    "\n",
    "def do_tgt(tgt):\n",
    "    params=tgt2params[tgt]\n",
    "    tgtcol=tgt2col[tgt]\n",
    "    dftrvl, pops=getdftrvl(tgt)\n",
    "    split=int(len(dftrvl)*0.85)\n",
    "    dftr,dfvl=dftrvl[:split],dftrvl[split:]\n",
    "    dtr = lgb.Dataset(dftr[cols_feat], label=dftr[tgtcol])\n",
    "    dvl = lgb.Dataset(dfvl[cols_feat], label=dfvl[tgtcol])\n",
    "    bst,evals_result=train(params,dtr,dvl)\n",
    "    prdtr,prdvl=valid(bst,dftr,dfvl)\n",
    "    \n",
    "    tgt2bst[tgt]=bst\n",
    "    tgt2evalres[tgt]=evals_result\n",
    "    tgt2ytr[tgt]=dftr[tgtcol]\n",
    "    tgt2yvl[tgt]=dfvl[tgtcol]\n",
    "    tgt2pops[tgt]=pops\n",
    "    tgt2prdtr[tgt]=prdtr\n",
    "    tgt2prdvl[tgt]=prdvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24 03:25:15 Retweet ********************************************************************************\n",
      "Retweet\n",
      "n_pos_wanted 100000\n",
      "2020-03-24 03:25:31 chunk 1\n",
      "dftrvl.shape: (1000000, 95) dftrvl[tgtcol].mean(): 0.112823\n",
      "{'train_pop': 1000000, 'target_pop': 112823, 'sampled_train_pop': 1000000, 'sampled_target_pop': 112823}\n",
      "{'num_leaves': 64, 'objective': 'binary', 'metric': 'auc'}\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\tvalid_0's auc: 0.708164\n",
      "[10]\tvalid_0's auc: 0.715193\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's auc: 0.715193\n",
      "2020-03-24 03:25:57 Reply ********************************************************************************\n",
      "Reply\n",
      "n_pos_wanted 100000\n",
      "2020-03-24 03:26:13 chunk 1\n",
      "2020-03-24 03:26:29 chunk 2\n",
      "2020-03-24 03:26:45 chunk 3\n",
      "2020-03-24 03:27:01 chunk 4\n",
      "dftrvl.shape: (1000000, 95) dftrvl[tgtcol].mean(): 0.109752\n",
      "{'train_pop': 4000000, 'target_pop': 109752, 'sampled_train_pop': 1000000, 'sampled_target_pop': 109752}\n",
      "{'num_leaves': 64, 'objective': 'binary', 'metric': 'auc'}\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\tvalid_0's auc: 0.762674\n",
      "[10]\tvalid_0's auc: 0.765536\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's auc: 0.765536\n",
      "2020-03-24 03:27:27 Like ********************************************************************************\n",
      "Like\n",
      "n_pos_wanted 100000\n",
      "2020-03-24 03:27:42 chunk 1\n",
      "dftrvl.shape: (1000000, 95) dftrvl[tgtcol].mean(): 0.439225\n",
      "{'train_pop': 1000000, 'target_pop': 439225, 'sampled_train_pop': 1000000, 'sampled_target_pop': 439225}\n",
      "{'num_leaves': 64, 'objective': 'binary', 'metric': 'auc'}\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\tvalid_0's auc: 0.707092\n",
      "[10]\tvalid_0's auc: 0.710289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's auc: 0.710289\n",
      "2020-03-24 03:28:06 RTwCmnt ********************************************************************************\n",
      "RTwCmnt\n",
      "n_pos_wanted 100000\n",
      "2020-03-24 03:28:21 chunk 1\n",
      "2020-03-24 03:28:37 chunk 2\n",
      "2020-03-24 03:28:53 chunk 3\n",
      "2020-03-24 03:29:09 chunk 4\n",
      "2020-03-24 03:29:25 chunk 5\n",
      "2020-03-24 03:29:41 chunk 6\n",
      "2020-03-24 03:29:57 chunk 7\n",
      "2020-03-24 03:30:13 chunk 8\n",
      "2020-03-24 03:30:29 chunk 9\n",
      "2020-03-24 03:30:45 chunk 10\n",
      "2020-03-24 03:31:01 chunk 11\n",
      "2020-03-24 03:31:16 chunk 12\n",
      "2020-03-24 03:31:33 chunk 13\n",
      "dftrvl.shape: (1000000, 95) dftrvl[tgtcol].mean(): 0.101203\n",
      "{'train_pop': 13000000, 'target_pop': 101203, 'sampled_train_pop': 1000000, 'sampled_target_pop': 101203}\n",
      "{'num_leaves': 64, 'objective': 'binary', 'metric': 'auc'}\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\tvalid_0's auc: 0.689441\n",
      "[10]\tvalid_0's auc: 0.69542\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's auc: 0.69542\n"
     ]
    }
   ],
   "source": [
    "tgt2params = {k:\n",
    "              {'num_leaves': 64, 'objective': 'binary', \n",
    "             'metric': 'auc'}\n",
    "              for k in tgts}\n",
    "\n",
    "tgt2bst={}\n",
    "tgt2evalres={}\n",
    "tgt2ytr={}\n",
    "tgt2yvl={}\n",
    "tgt2prdtr={}\n",
    "tgt2prdvl={}\n",
    "tgt2pops={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt, '*'*80)\n",
    "    do_tgt(tgt)\n",
    "    \n",
    "pickle.dump(tgt2bst, open(f\"{p_out}/tgt2bst.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tr vl"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for tgt in tgt2evalres:\n",
    "    evalres=tgt2evalres[tgt]\n",
    "    plt.plot(evalres['train']['logloss'][10:])\n",
    "    plt.plot(evalres['eval']['logloss'][10:])\n",
    "    plt.title(f\"{tgt} logloss {len(evalres['train']['logloss'])} rounds\")\n",
    "    plt.show()\n",
    "    plt.plot(evalres['train']['aucpr'])\n",
    "    plt.plot(evalres['eval']['aucpr'])\n",
    "    plt.title(f\"{tgt} aucpr {len(evalres['train']['aucpr'])} rounds\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def show_feat_importance(tgt):\n",
    "    bst=tgt2bst[tgt]\n",
    "    ax = xgb.plot_importance(bst, height=0.8, max_num_features=9)\n",
    "    ax.grid(False, axis=\"y\")\n",
    "    ax.set_title(f'{tgt} Estimated feature importance')\n",
    "    plt.show()\n",
    "    feat2importance=bst.get_fscore()\n",
    "    print(tgt)\n",
    "    display(pd.DataFrame([feat2importance.keys(), \n",
    "                          feat2importance.values()]).T.sort_values(1, ascending=False))\n",
    "\n",
    "for tgt in tgt2bst:\n",
    "    show_feat_importance(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retweet\n",
      "tr prauc: 0.2990 tr rce: 8.5593\n",
      "vl prauc: 0.2934 vl rce: 8.1900\n",
      "Reply\n",
      "tr prauc: 0.3034 tr rce: 11.6584\n",
      "vl prauc: 0.3041 vl rce: 11.5324\n",
      "Like\n",
      "tr prauc: 0.6533 tr rce: 8.7089\n",
      "vl prauc: 0.6484 vl rce: 8.4582\n",
      "RTwCmnt\n",
      "tr prauc: 0.2178 tr rce: 5.9845\n",
      "vl prauc: 0.2116 vl rce: 5.7776\n"
     ]
    }
   ],
   "source": [
    "tgt2auc_tr={}\n",
    "tgt2rce_tr={}\n",
    "tgt2auc_vl={}\n",
    "tgt2rce_vl={}\n",
    "for tgt in tgt2bst:\n",
    "    print(tgt)\n",
    "    prdtr_i, prdvl_i = tgt2prdtr[tgt], tgt2prdvl[tgt]\n",
    "    ytr_i, yvl_i = tgt2ytr[tgt], tgt2yvl[tgt]\n",
    "    scr_auc_tr=compute_prauc(prdtr_i, ytr_i)\n",
    "    scr_rce_tr=compute_rce(prdtr_i, ytr_i)\n",
    "    scr_auc_vl=compute_prauc(prdvl_i, yvl_i)\n",
    "    scr_rce_vl=compute_rce(prdvl_i, yvl_i)\n",
    "\n",
    "    tgt2auc_tr[tgt]=scr_auc_tr\n",
    "    tgt2rce_tr[tgt]=scr_rce_tr\n",
    "    tgt2auc_vl[tgt]=scr_auc_vl\n",
    "    tgt2rce_vl[tgt]=scr_rce_vl\n",
    "    \n",
    "    print('tr prauc:', f'{scr_auc_tr:.4f}','tr rce:', f'{scr_rce_tr:.4f}', )\n",
    "    print('vl prauc:', f'{scr_auc_vl:.4f}','vl rce:', f'{scr_rce_vl:.4f}', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>PRAUC Retweet</td>\n",
       "      <td>RCE Retweet</td>\n",
       "      <td>PRAUC Reply</td>\n",
       "      <td>RCE Reply</td>\n",
       "      <td>PRAUC Like</td>\n",
       "      <td>RCE Like</td>\n",
       "      <td>PRAUC RTwCmnt</td>\n",
       "      <td>RCE RTwCmnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrtr</th>\n",
       "      <td>0.299043</td>\n",
       "      <td>8.55929</td>\n",
       "      <td>0.303391</td>\n",
       "      <td>11.6584</td>\n",
       "      <td>0.653263</td>\n",
       "      <td>8.70891</td>\n",
       "      <td>0.217795</td>\n",
       "      <td>5.98445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrvl</th>\n",
       "      <td>0.293397</td>\n",
       "      <td>8.18997</td>\n",
       "      <td>0.30405</td>\n",
       "      <td>11.5324</td>\n",
       "      <td>0.648404</td>\n",
       "      <td>8.45819</td>\n",
       "      <td>0.211643</td>\n",
       "      <td>5.7776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0            1            2          3           4  \\\n",
       "metric  PRAUC Retweet  RCE Retweet  PRAUC Reply  RCE Reply  PRAUC Like   \n",
       "scrtr        0.299043      8.55929     0.303391    11.6584    0.653263   \n",
       "scrvl        0.293397      8.18997      0.30405    11.5324    0.648404   \n",
       "\n",
       "               5              6            7  \n",
       "metric  RCE Like  PRAUC RTwCmnt  RCE RTwCmnt  \n",
       "scrtr    8.70891       0.217795      5.98445  \n",
       "scrvl    8.45819       0.211643       5.7776  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsttr=[]\n",
    "lstvl=[]\n",
    "for tgt in ['Retweet','Reply','Like','RTwCmnt',]:\n",
    "    if tgt not in tgt2bst: continue\n",
    "    lsttr+=[(f'PRAUC {tgt}',tgt2auc_tr[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_tr[tgt])]\n",
    "    lstvl+=[(f'PRAUC {tgt}',tgt2auc_vl[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_vl[tgt])]\n",
    "\n",
    "dfscrtr=pd.DataFrame(lsttr)\n",
    "dfscrtr.columns=['metric','scr']\n",
    "dfscrvl=pd.DataFrame(lstvl)\n",
    "dfscrvl.columns=['metric','scr']\n",
    "dfscr = pd.merge(dfscrtr, dfscrvl, on='metric', suffixes=('tr','vl'))\n",
    "dfscr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt=tgts[1]\n",
    "# tgtcol=tgt2col[tgt]\n",
    "# bst=tgt2bst[tgt]\n",
    "\n",
    "# dvalid=xgb.DMatrix(dfvalid[cols_feat], label=dfvalid[tgtcol], feature_names=cols_feat)\n",
    "\n",
    "# prdvalid = bst.predict(dvalid, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "# pops=tgt2pops[tgt]\n",
    "\n",
    "# prdvalid[:10]\n",
    "# # array([0.11734424, 0.09971393, 0.05619054, 0.03059793, 0.07979691,\n",
    "# #        0.01358252, 0.05293725, 0.27954698, 0.05738379, 0.01741553],\n",
    "# #       dtype=float32)\n",
    "\n",
    "\n",
    "# pops\n",
    "# # {'train_pop': 4000000,\n",
    "# #  'target_pop': 109752,\n",
    "# #  'sampled_train_pop': 1000000,\n",
    "# #  'sampled_target_pop': 109752}\n",
    "\n",
    "# prdvalid_calib = calibration(prdvalid, **pops)\n",
    "\n",
    "# prdvalid_calib[:10]\n",
    "# # array([0.02952491, 0.02471944, 0.01344113, 0.00717127, 0.01945818,\n",
    "# #        0.00314114, 0.0126298 , 0.08155248, 0.01373977, 0.00403964],\n",
    "# #       dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_post_valid(tgt):\n",
    "    tgtcol=tgt2col[tgt]\n",
    "    bst=tgt2bst[tgt]\n",
    "    pops=tgt2pops[tgt]\n",
    "    prdvalid = bst.predict(dfvalid[cols_feat])\n",
    "    prdvalid_calib = calibration(prdvalid, **pops)\n",
    "    return prdvalid,prdvalid_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24 03:33:23 Retweet\n",
      "2020-03-24 03:33:34 Reply\n",
      "2020-03-24 03:33:43 Like\n",
      "2020-03-24 03:33:55 RTwCmnt\n"
     ]
    }
   ],
   "source": [
    "tgt2yvalid={tgt:dfvalid[tgt2col[tgt]] for tgt in tgts}\n",
    "tgt2prdvalid={}\n",
    "tgt2prdvalid_calib={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt)\n",
    "    tgt2prdvalid[tgt],tgt2prdvalid_calib[tgt]=do_post_valid(tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24 03:34:07 Retweet\n",
      "2020-03-24 03:34:10 Reply\n",
      "2020-03-24 03:34:14 Like\n",
      "2020-03-24 03:34:17 RTwCmnt\n"
     ]
    }
   ],
   "source": [
    "tgt2auc_valid={}\n",
    "tgt2rce_valid={}\n",
    "tgt2auc_valid_calib={}\n",
    "tgt2rce_valid_calib={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt)\n",
    "    prdvalid, prdvalid_calib = tgt2prdvalid[tgt], tgt2prdvalid_calib[tgt]\n",
    "    yvalid = tgt2yvalid[tgt]\n",
    "    scr_auc_valid=compute_prauc(prdvalid, yvalid)\n",
    "    scr_rce_valid=compute_rce(prdvalid, yvalid)\n",
    "    scr_auc_valid_calib=compute_prauc(prdvalid_calib, yvalid)\n",
    "    scr_rce_valid_calib=compute_rce(prdvalid_calib, yvalid)\n",
    "\n",
    "    tgt2auc_valid[tgt]=scr_auc_valid\n",
    "    tgt2rce_valid[tgt]=scr_rce_valid\n",
    "    tgt2auc_valid_calib[tgt]=scr_auc_valid_calib\n",
    "    tgt2rce_valid_calib[tgt]=scr_rce_valid_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retweet\n",
      "tr          prauc: 0.2990 tr rce: 8.5593\n",
      "vl          prauc: 0.2934 tr rce: 8.1900\n",
      "valid       prauc: 0.2905 tr rce: 8.2118\n",
      "valid_calib prauc: 0.2905 tr rce: 8.2118\n",
      "Reply\n",
      "tr          prauc: 0.3034 tr rce: 11.6584\n",
      "vl          prauc: 0.3041 tr rce: 11.5324\n",
      "valid       prauc: 0.0972 tr rce: -26.4591\n",
      "valid_calib prauc: 0.0972 tr rce: 8.9411\n",
      "Like\n",
      "tr          prauc: 0.6533 tr rce: 8.7089\n",
      "vl          prauc: 0.6484 tr rce: 8.4582\n",
      "valid       prauc: 0.6471 tr rce: 8.4671\n",
      "valid_calib prauc: 0.6471 tr rce: 8.4671\n",
      "RTwCmnt\n",
      "tr          prauc: 0.2178 tr rce: 5.9845\n",
      "vl          prauc: 0.2116 tr rce: 5.7776\n",
      "valid       prauc: 0.0195 tr rce: -165.7833\n",
      "valid_calib prauc: 0.0195 tr rce: 3.5912\n"
     ]
    }
   ],
   "source": [
    "for tgt in tgts:\n",
    "    print(tgt)\n",
    "    print('tr          prauc:', f'{tgt2auc_tr[tgt]:.4f}','tr rce:', f'{tgt2rce_tr[tgt]:.4f}', )\n",
    "    print('vl          prauc:', f'{tgt2auc_vl[tgt]:.4f}','tr rce:', f'{tgt2rce_vl[tgt]:.4f}', )\n",
    "    print('valid       prauc:', f'{tgt2auc_valid[tgt]:.4f}','tr rce:', f'{tgt2rce_valid[tgt]:.4f}', )\n",
    "    print('valid_calib prauc:', f'{tgt2auc_valid_calib[tgt]:.4f}','tr rce:', f'{tgt2rce_valid_calib[tgt]:.4f}', )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scr</th>\n",
       "      <td>PRAUC Retweet</td>\n",
       "      <td>RCE Retweet</td>\n",
       "      <td>PRAUC Reply</td>\n",
       "      <td>RCE Reply</td>\n",
       "      <td>PRAUC Like</td>\n",
       "      <td>RCE Like</td>\n",
       "      <td>PRAUC RTwCmnt</td>\n",
       "      <td>RCE RTwCmnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>0.299043</td>\n",
       "      <td>8.55929</td>\n",
       "      <td>0.303391</td>\n",
       "      <td>11.6584</td>\n",
       "      <td>0.653263</td>\n",
       "      <td>8.70891</td>\n",
       "      <td>0.217795</td>\n",
       "      <td>5.98445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vl</th>\n",
       "      <td>0.293397</td>\n",
       "      <td>8.18997</td>\n",
       "      <td>0.30405</td>\n",
       "      <td>11.5324</td>\n",
       "      <td>0.648404</td>\n",
       "      <td>8.45819</td>\n",
       "      <td>0.211643</td>\n",
       "      <td>5.7776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>0.290495</td>\n",
       "      <td>8.21179</td>\n",
       "      <td>0.0971804</td>\n",
       "      <td>-26.4591</td>\n",
       "      <td>0.647119</td>\n",
       "      <td>8.46709</td>\n",
       "      <td>0.0194639</td>\n",
       "      <td>-165.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_calib</th>\n",
       "      <td>0.290495</td>\n",
       "      <td>8.21179</td>\n",
       "      <td>0.0971804</td>\n",
       "      <td>8.94107</td>\n",
       "      <td>0.647119</td>\n",
       "      <td>8.46709</td>\n",
       "      <td>0.0194639</td>\n",
       "      <td>3.59116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0            1            2          3           4  \\\n",
       "scr          PRAUC Retweet  RCE Retweet  PRAUC Reply  RCE Reply  PRAUC Like   \n",
       "tr                0.299043      8.55929     0.303391    11.6584    0.653263   \n",
       "vl                0.293397      8.18997      0.30405    11.5324    0.648404   \n",
       "valid             0.290495      8.21179    0.0971804   -26.4591    0.647119   \n",
       "valid_calib       0.290495      8.21179    0.0971804    8.94107    0.647119   \n",
       "\n",
       "                    5              6            7  \n",
       "scr          RCE Like  PRAUC RTwCmnt  RCE RTwCmnt  \n",
       "tr            8.70891       0.217795      5.98445  \n",
       "vl            8.45819       0.211643       5.7776  \n",
       "valid         8.46709      0.0194639     -165.783  \n",
       "valid_calib   8.46709      0.0194639      3.59116  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsttr=[]\n",
    "lstvl=[]\n",
    "lstvalid=[]\n",
    "lstvalid_calib=[]\n",
    "for tgt in ['Retweet','Reply','Like','RTwCmnt',]:\n",
    "    if tgt not in tgt2bst: continue\n",
    "    lsttr+=[(f'PRAUC {tgt}',tgt2auc_tr[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_tr[tgt])]\n",
    "    lstvl+=[(f'PRAUC {tgt}',tgt2auc_vl[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_vl[tgt])]\n",
    "    lstvalid+=[(f'PRAUC {tgt}',tgt2auc_valid[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_valid[tgt])]\n",
    "    lstvalid_calib+=[(f'PRAUC {tgt}',tgt2auc_valid_calib[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_valid_calib[tgt])]\n",
    "\n",
    "dfscrtr=pd.DataFrame(lsttr)\n",
    "dfscrtr.columns=['metric','scr']\n",
    "dfscrvl=pd.DataFrame(lstvl)\n",
    "dfscrvl.columns=['metric','scr']\n",
    "dfscrvalid=pd.DataFrame(lstvalid)\n",
    "dfscrvalid.columns=['metric','scr']\n",
    "dfscrvalid_calib=pd.DataFrame(lstvalid_calib)\n",
    "dfscrvalid_calib.columns=['metric','scr']\n",
    "\n",
    "dfscr = reduce(lambda df1,df2: pd.merge(df1,df2,on='metric'), \n",
    "            [dfscrtr,dfscrvl,dfscrvalid,dfscrvalid_calib])\n",
    "\n",
    "dfscr.columns=['scr','tr','vl','valid','valid_calib']\n",
    "dfscr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls -lhS $p_in | grep val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst=pd.read_csv(\n",
    "    f'{p_in}/val_{valtmstmp}.tsv',\n",
    "#     f'{p_in}/val_259A6F6DFD672CB1F883CBEC01B99F2D_1584405047.tsv',\n",
    "    sep='\\x01', header=None, names=cols_val,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst = prp_df(dftst, istrn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtst = xgb.DMatrix(dftst[cols_feat], feature_names=cols_feat)\n",
    "tgt2prdtst={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt)\n",
    "    bst = tgt2bst[tgt]\n",
    "    pops=tgt2pops[tgt]\n",
    "    prdtst = bst.predict(dtst, ntree_limit=bst.best_ntree_limit)\n",
    "    prdtst_calib = calibration(prdtst, **pops)\n",
    "    tgt2prdtst[tgt] = prdtst_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub_ids = dftst[['twtid','u2id',]]\n",
    "\n",
    "tgt2dfsub = {}\n",
    "for tgt,prdtst in tgt2prdtst.items():\n",
    "    dfsub = dfsub_ids.copy()\n",
    "    dfsub['scr'] = prdtst\n",
    "    tgt2dfsub[tgt]=dfsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i,tgt in enumerate(['Retweet','Reply','RTwCmnt','Like',]):\n",
    "    dfsub = tgt2dfsub[tgt]\n",
    "    print(dtnow(), tgt)\n",
    "    dfsub.to_csv(f'{p_out}/{i}_{tgt}__{valtmstmp}__{PRFX}.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
