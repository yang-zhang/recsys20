{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-03-17 02:32:24', '2020-03-24 17:09:45']\n",
      "['2020-02-06 00:00:00', '2020-02-13 00:00:00']\n"
     ]
    }
   ],
   "source": [
    "trntmstmp=1584412344\n",
    "valtmstmp=1585069785\n",
    "import datetime\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (trntmstmp, valtmstmp)])\n",
    "\n",
    "grand_total=1.5e8\n",
    "MIN_TM_TRN=1580947200\n",
    "MIN_TM_TST=1581552000\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (MIN_TM_TRN, MIN_TM_TST)])\n",
    "\n",
    "\n",
    "CHNKSZ=1e6\n",
    "POST_RATE_WANTED=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "SEED=101\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "import torch\n",
    "device=torch.device('cpu')\n",
    "\n",
    "pretrained_weights='bert-base-multilingual-cased'\n",
    "model = BertModel.from_pretrained(pretrained_weights, output_hidden_states=True, num_labels=4)\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights, do_lower_case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Retweet': 'retwt',\n",
       " 'Reply': 'reply',\n",
       " 'Like': 'like',\n",
       " 'RTwCmnt': 'retwt_cmmnt'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=[\n",
    "'toks',\n",
    "'hshtgs',\n",
    "'twtid',\n",
    "'media',\n",
    "'links',\n",
    "'domns',\n",
    "'twttyp',\n",
    "'lang',\n",
    "'tm',\n",
    "\n",
    "'u1id',\n",
    "'u1_fllwer_cnt',\n",
    "'u1_fllwng_cnt',\n",
    "'u1_vrfed',\n",
    "'u1_create_tm',\n",
    "\n",
    "'u2id',\n",
    "'u2_fllwer_cnt',\n",
    "'u2_fllwng_cnt',\n",
    "'u2_vrfed',\n",
    "'u2_create_tm',\n",
    "\n",
    "'u1_fllw_u2',\n",
    "'reply_tm',\n",
    "'retwt_tm',\n",
    "'retwt_cmmnt_tm',\n",
    "'like_tm',\n",
    "]\n",
    "cols_cat = ['twttyp','lang']\n",
    "cols_val = cols[:-4]\n",
    "cols_tgt_tmstmp=[\n",
    "    'retwt_tm',\n",
    "    'reply_tm',\n",
    "    'like_tm',\n",
    "    'retwt_cmmnt_tm',\n",
    "]\n",
    "cols_tgt=[o.split('_tm')[0] for o in cols_tgt_tmstmp]\n",
    "tgts             = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "assert cols_tgt == ['retwt',  'reply','like','retwt_cmmnt',]\n",
    "ntgts=len(tgts)\n",
    "\n",
    "\n",
    "tgt2col=dict(zip(tgts,cols_tgt))\n",
    "tgt2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.9 ms, sys: 4.17 ms, total: 89.1 ms\n",
      "Wall time: 87.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dftrn=pd.read_csv(\n",
    "    f'{p_in}/trn_{trntmstmp}.tsv',\n",
    "    sep='\\x01', header=None, \n",
    "    encoding='utf-8', \n",
    "    names=cols, \n",
    "    nrows=1e4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dftrn.toks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 6417, 3410, 3398, 3184, 1909, 56910, 16838, 82904, 1901, 100, 102]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokids=list(map(int, x.split('\\t')))\n",
    "tokids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 美 容 室 変 え ##ど ##き ##かな 〜 [UNK] [SEP]'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(tokenizer.convert_ids_to_tokens(tokids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen=8\n",
    "len(tokids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 6417, 3410, 3398, 3184, 1909, 56910, 16838, 82904, 1901, 100, 102]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokids=tokids + [0] * (maxlen-len(tokids))\n",
    "tokids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokids=tokids[:maxlen-1]+[tokenizer.sep_token_id,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 6417, 3410, 3398, 3184, 1909, 56910, 102]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.pad_token, tokenizer.pad_token_id\n",
    "# ('[PAD]', 0)\n",
    "\n",
    "# tokenizer.sep_token, tokenizer.sep_token_id\n",
    "# ('[SEP]', 102)\n",
    "maxlen=512\n",
    "def mkids(x):\n",
    "    tokids=list(map(int, x.split('\\t')))\n",
    "    l=len(tokids) \n",
    "    if l<=maxlen: \n",
    "        return tokids + [0]*(maxlen-len(tokids))\n",
    "    else: \n",
    "        return tokids[:maxlen-1]+[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 207 ms, sys: 15.8 ms, total: 223 ms\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dftrn['toks']=dftrn.toks.apply(lambda x: mkids(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dftrn.toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [101, 6417, 3410, 3398, 3184, 1909, 56910, 168...\n",
       "1       [101, 14120, 131, 120, 120, 188, 119, 11170, 1...\n",
       "2       [101, 62342, 10858, 54439, 19571, 22480, 7831,...\n",
       "3       [101, 58955, 10898, 103305, 1901, 16181, 7168,...\n",
       "4       [101, 2435, 5656, 2594, 8279, 8623, 1925, 6412...\n",
       "                              ...                        \n",
       "9995    [101, 56898, 137, 18643, 10715, 28580, 47371, ...\n",
       "9996    [101, 1904, 11662, 11166, 2534, 1939, 2452, 81...\n",
       "9997    [101, 2037, 103606, 4449, 4333, 10055, 10055, ...\n",
       "9998    [101, 108, 14864, 45389, 10759, 24558, 168, 89...\n",
       "9999    [101, 56898, 137, 30665, 13420, 10288, 14703, ...\n",
       "Name: toks, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 6417, 3410, 3398, 3184, 1909, 56910, 16838, 82904, 1901, 100, 102]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrn.toks[0]+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[PAD]', 0)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token, tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_toks=dftrn.toks.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lens_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] RT @ Phantom ##A ##rti ##fice : i saw this on red ##dit and haven ' t seen something more true https : / / t . co / k ##7 ##c ##J ##O ##Z ##ht ##X ##x [SEP]\""
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks=dftrn.sample().toks.values[0]\n",
    "\n",
    "\" \".join(tokenizer.convert_ids_to_tokens(toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 40, 768]),\n",
       " torch.Size([1, 768]),\n",
       " 13,\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks=[int(o) for o in toks]\n",
    "\n",
    "# https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "model=model.eval()\n",
    "input_ids = torch.tensor([toks])  \n",
    "with torch.no_grad():\n",
    "    last_hidden_state, pooler_output, hidden_states = model(input_ids)\n",
    "    avg_pool = torch.mean(last_hidden_state,1)\n",
    "    max_pool,_ = torch.max(last_hidden_state,1)\n",
    "last_hidden_state.shape,pooler_output.shape,len(hidden_states), avg_pool.shape, max_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
