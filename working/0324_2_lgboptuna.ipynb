{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258\n",
    "- https://github.com/optuna/optuna/blob/master/examples/lightgbm_tuner_simple.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-03-17 02:32:24', '2020-03-24 17:09:45']\n",
      "['2020-02-06 00:00:00', '2020-02-13 00:00:00']\n"
     ]
    }
   ],
   "source": [
    "PRFX='0324_2'\n",
    "trntmstmp=1584412344\n",
    "valtmstmp=1585069785\n",
    "import datetime\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (trntmstmp, valtmstmp)])\n",
    "\n",
    "grand_total=1.5e8\n",
    "MIN_TM_TRN=1580947200\n",
    "MIN_TM_TST=1581552000\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (MIN_TM_TRN, MIN_TM_TST)])\n",
    "\n",
    "\n",
    "CHNKSZ=1e3\n",
    "POST_RATE_WANTED=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Retweet': 'retwt',\n",
       " 'Reply': 'reply',\n",
       " 'Like': 'like',\n",
       " 'RTwCmnt': 'retwt_cmmnt'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# import dask\n",
    "# print('dask.__version__', dask.__version__)\n",
    "import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "\n",
    "# optuna.logging.CRITICAL, optuna.logging.FATAL\n",
    "# optuna.logging.ERROR\n",
    "# optuna.logging.WARNING, optuna.logging.WARN\n",
    "# optuna.logging.INFO\n",
    "# optuna.logging.DEBUG\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "# import dask_xgboost\n",
    "# import dask.dataframe as dd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "from dask.distributed import Client\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from functools import reduce\n",
    "import datetime\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "SEED=101\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "p_out=f'{HOME}/output/{PRFX}'\n",
    "Path(p_out).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, log_loss\n",
    "\n",
    "def compute_prauc(pred, gt):\n",
    "    prec, recall, thresh = precision_recall_curve(gt, pred)\n",
    "    prauc = auc(recall, prec)\n",
    "    return prauc\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "    positive = len([x for x in gt if x == 1])\n",
    "    ctr = positive/float(len(gt))\n",
    "    return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "# https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
    "# How to use the function?\n",
    "# Letâ€™s say your goal is to generate a model that shows the credit default probabilities and your original \n",
    "# training data has 50,000 rows with only 500 of them labeled as target class. When you sample your non-target \n",
    "# instances randomly and reduce the total row count to 10,000, while conserving 500 target rows, our calibration\n",
    "# function becomes:\n",
    "# calibration(model_results, 50000, 500, 10000, 500)\n",
    "# Here model_results is your model probability output array. After you train your model and put the results in it, your function is ready to use. \n",
    "\n",
    "def calibration(data, train_pop, target_pop, sampled_train_pop, sampled_target_pop):\n",
    "    calibrated_data = \\\n",
    "    ((data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop)) /\n",
    "    ((\n",
    "        (1 - data) * (1 - target_pop / train_pop) / (1 - sampled_target_pop / sampled_train_pop)\n",
    "     ) +\n",
    "     (\n",
    "        data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop)\n",
    "     )))\n",
    "\n",
    "    return calibrated_data\n",
    "\n",
    "cols=[\n",
    "'toks',\n",
    "'hshtgs',\n",
    "'twtid',\n",
    "'media',\n",
    "'links',\n",
    "'domns',\n",
    "'twttyp',\n",
    "'lang',\n",
    "'tm',\n",
    "\n",
    "'u1id',\n",
    "'u1_fllwer_cnt',\n",
    "'u1_fllwng_cnt',\n",
    "'u1_vrfed',\n",
    "'u1_create_tm',\n",
    "\n",
    "'u2id',\n",
    "'u2_fllwer_cnt',\n",
    "'u2_fllwng_cnt',\n",
    "'u2_vrfed',\n",
    "'u2_create_tm',\n",
    "\n",
    "'u1_fllw_u2',\n",
    "'reply_tm',\n",
    "'retwt_tm',\n",
    "'retwt_cmmnt_tm',\n",
    "'like_tm',\n",
    "]\n",
    "cols_cat = ['twttyp','lang']\n",
    "cols_val = cols[:-4]\n",
    "cols_tgt_tmstmp=[\n",
    "    'retwt_tm',\n",
    "    'reply_tm',\n",
    "    'like_tm',\n",
    "    'retwt_cmmnt_tm',\n",
    "]\n",
    "cols_tgt=[o.split('_tm')[0] for o in cols_tgt_tmstmp]\n",
    "tgts             = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "assert cols_tgt == ['retwt',  'reply','like','retwt_cmmnt',]\n",
    "ntgts=len(tgts)\n",
    "\n",
    "\n",
    "\n",
    "tgt2col=dict(zip(tgts,cols_tgt))\n",
    "tgt2col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chnks_trn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',\n",
    "                    header=None,names=cols, \n",
    "                        chunksize=CHNKSZ)\n",
    "# first chunk as validate data\n",
    "for ichnk,df in enumerate(chnks_trn):\n",
    "    df\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "istrn=True\n",
    "tm_min = MIN_TM_TRN if istrn else MIN_TM_TST\n",
    "df['len_toks'] = df.toks.apply(len)\n",
    "for media in ['Photo', 'Video', 'GIF']:\n",
    "    df[f'has_media_{media}'] = df.media.fillna('').apply(lambda x: media in x)\n",
    "for col in ['hshtgs', 'links', 'domns',]:\n",
    "    df[f'num_{col}'] = df[col].fillna('').apply(lambda x: len(x.split('\\t')) if len(x) else 0)\n",
    "\n",
    "df['twt_age'] = df.tm - tm_min\n",
    "df['u1_age']  = df.tm - df.u1_create_tm\n",
    "df['u2_age']  = df.tm - df.u2_create_tm\n",
    "\n",
    "tm_dt=pd.to_datetime(df.tm, unit='s')\n",
    "df['tm_dayofweek']=tm_dt.dt.dayofweek\n",
    "df['tm_hour']=tm_dt.dt.hour\n",
    "\n",
    "df['tmdlta_u2u1']  = df.u2_create_tm - df.u1_create_tm\n",
    "\n",
    "df['u1_fllwer_cnt_by_age'] = df.u1_fllwer_cnt / df.u1_age\n",
    "df['u1_fllwng_cnt_by_age'] = df.u2_fllwng_cnt / df.u2_age\n",
    "\n",
    "for col in ['twttyp','lang']:\n",
    "    df[col]=df[col].astype('category')\n",
    "\n",
    "if istrn: \n",
    "    df[cols_tgt]=df[cols_tgt_tmstmp].notna().astype('int8')\n",
    "    df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns',  \n",
    "                                   'tm', 'u1_create_tm','u2_create_tm', 'u1id', 'u2id', 'twtid', ]+cols_tgt_tmstmp, )\n",
    "else:\n",
    "    df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns', \n",
    "                                   'tm', 'u1_create_tm','u2_create_tm', 'u1id', ])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twttyp                  category\n",
       "lang                    category\n",
       "u1_fllwer_cnt              int64\n",
       "u1_fllwng_cnt              int64\n",
       "u1_vrfed                    bool\n",
       "u2_fllwer_cnt              int64\n",
       "u2_fllwng_cnt              int64\n",
       "u2_vrfed                    bool\n",
       "u1_fllw_u2                  bool\n",
       "len_toks                   int64\n",
       "has_media_Photo             bool\n",
       "has_media_Video             bool\n",
       "has_media_GIF               bool\n",
       "num_hshtgs                 int64\n",
       "num_links                  int64\n",
       "num_domns                  int64\n",
       "twt_age                    int64\n",
       "u1_age                     int64\n",
       "u2_age                     int64\n",
       "tm_dayofweek               int64\n",
       "tm_hour                    int64\n",
       "tmdlta_u2u1                int64\n",
       "u1_fllwer_cnt_by_age     float64\n",
       "u1_fllwng_cnt_by_age     float64\n",
       "retwt                       int8\n",
       "reply                       int8\n",
       "like                        int8\n",
       "retwt_cmmnt                 int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prp_df(df, istrn=True):\n",
    "    tm_min = MIN_TM_TRN if istrn else MIN_TM_TST\n",
    "    df['len_toks'] = df.toks.apply(len)\n",
    "    for media in ['Photo', 'Video', 'GIF']:\n",
    "        df[f'has_media_{media}'] = df.media.fillna('').apply(lambda x: media in x)\n",
    "    for col in ['hshtgs', 'links', 'domns',]:\n",
    "        df[f'num_{col}'] = df[col].fillna('').apply(lambda x: len(x.split('\\t')) if len(x) else 0)\n",
    "\n",
    "    df['twt_age'] = df.tm - tm_min\n",
    "    df['u1_age']  = df.tm - df.u1_create_tm\n",
    "    df['u2_age']  = df.tm - df.u2_create_tm\n",
    "\n",
    "    tm_dt=pd.to_datetime(df.tm, unit='s')\n",
    "    df['tm_dayofweek']=tm_dt.dt.dayofweek\n",
    "    df['tm_hour']=tm_dt.dt.hour\n",
    "\n",
    "    df['tmdlta_u2u1']  = df.u2_create_tm - df.u1_create_tm\n",
    "\n",
    "    df['u1_fllwer_cnt_by_age'] = df.u1_fllwer_cnt / df.u1_age\n",
    "    df['u1_fllwng_cnt_by_age'] = df.u2_fllwng_cnt / df.u2_age\n",
    "\n",
    "    for col in cols_cat:\n",
    "        df[col]=df[col].astype('category')\n",
    "\n",
    "    if istrn: \n",
    "        df[cols_tgt]=df[cols_tgt_tmstmp].notna().astype('int8')\n",
    "        df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns',  \n",
    "                                       'tm', 'u1_create_tm','u2_create_tm', 'u1id', 'u2id', 'twtid', ]+cols_tgt_tmstmp, )\n",
    "    else:\n",
    "        df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns', \n",
    "                                       'tm', 'u1_create_tm','u2_create_tm', 'u1id', ])   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ls -hlS $p_in | grep {trntmstmp} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000000.0, 150000.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_total, grand_total/CHNKSZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24 15:37:51 chunk 0\n",
      "dfvalid.shape: (1000, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "twttyp                  category\n",
       "lang                    category\n",
       "u1_fllwer_cnt              int64\n",
       "u1_fllwng_cnt              int64\n",
       "u1_vrfed                    bool\n",
       "u2_fllwer_cnt              int64\n",
       "u2_fllwng_cnt              int64\n",
       "u2_vrfed                    bool\n",
       "u1_fllw_u2                  bool\n",
       "len_toks                   int64\n",
       "has_media_Photo             bool\n",
       "has_media_Video             bool\n",
       "has_media_GIF               bool\n",
       "num_hshtgs                 int64\n",
       "num_links                  int64\n",
       "num_domns                  int64\n",
       "twt_age                    int64\n",
       "u1_age                     int64\n",
       "u2_age                     int64\n",
       "tm_dayofweek               int64\n",
       "tm_hour                    int64\n",
       "tmdlta_u2u1                int64\n",
       "u1_fllwer_cnt_by_age     float64\n",
       "u1_fllwng_cnt_by_age     float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chnks_trn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',\n",
    "                    header=None,names=cols, \n",
    "                        chunksize=CHNKSZ)\n",
    "# first chunk as validate data\n",
    "for ichnk,df in enumerate(chnks_trn):\n",
    "    print(dtnow(), 'chunk', ichnk)\n",
    "#     print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') \n",
    "#            for o in (df.tm.min(), df.tm.max())])\n",
    "    dfvalid = prp_df(df)\n",
    "    break\n",
    "print('dfvalid.shape:',dfvalid.shape)\n",
    "\n",
    "cols_feat=[o for o in dfvalid.columns if o not in cols_tgt]\n",
    "\n",
    "display(dfvalid[cols_feat].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trnval data func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdftrvl(tgt):\n",
    "    print(tgt)\n",
    "    tgtcol=tgt2col[tgt]\n",
    "    chnks_trn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',\n",
    "                        header=None,names=cols, \n",
    "                            chunksize=CHNKSZ)\n",
    "    len_df_wanted = int(CHNKSZ)\n",
    "    # retwt          0.113031\n",
    "    # reply          0.027488\n",
    "    # like           0.439499\n",
    "    # retwt_cmmnt    0.007742\n",
    "    pos_rate_wanted = POST_RATE_WANTED\n",
    "    n_pos_wanted = int(len_df_wanted*pos_rate_wanted)\n",
    "    print('n_pos_wanted', n_pos_wanted)\n",
    "    np.random.seed(SEED)\n",
    "    lst_df = []\n",
    "    n_pos_ttl = 0\n",
    "    for ichnk,df in enumerate(chnks_trn):\n",
    "        #skip first chunk (it was validate data)\n",
    "        if ichnk==0: continue\n",
    "        print(dtnow(), 'chunk', ichnk)\n",
    "        df = prp_df(df)\n",
    "        n_pos_ttl+= df[tgtcol].sum()\n",
    "        lst_df.append(df)\n",
    "        if n_pos_ttl>=n_pos_wanted: break\n",
    "\n",
    "    df = pd.concat(lst_df)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/questions/28556942/pandas-remove-rows-at-random-without-shuffling-dataset\n",
    "    idx_neg=np.where(df[tgtcol]==0)[0]\n",
    "    n_neg = len(idx_neg)\n",
    "    n_pos = len(df)-len(idx_neg)\n",
    "    n_neg2keep = len_df_wanted-n_pos\n",
    "    n_neg2rmv = n_neg-n_neg2keep\n",
    "    idx_neg2rmv = np.random.choice(idx_neg, n_neg2rmv, replace=False)\n",
    "    dftrvl = df.drop(idx_neg2rmv)\n",
    "    dftrvl = dftrvl.sample(len(dftrvl))\n",
    "    for col in cols_cat:\n",
    "        dftrvl[col]=dftrvl[col].astype('category')\n",
    "    \n",
    "#     display(dftrvl.dtypes)\n",
    "    print('dftrvl.shape:',dftrvl.shape,'dftrvl[tgtcol].mean():',dftrvl[tgtcol].mean())\n",
    "    \n",
    "    pops={\n",
    "        'train_pop':len(dftrvl),\n",
    "        'target_pop':n_pos,\n",
    "        'sampled_train_pop':len_df_wanted,\n",
    "        'sampled_target_pop':n_pos,\n",
    "    }\n",
    "    print(pops)\n",
    "    return dftrvl, pops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params,dtr,dvl):\n",
    "    print(params)\n",
    "    best_params, tuning_history = dict(), list()\n",
    "    evallist = [(dtr, 'train'), (dvl, 'eval')]\n",
    "    bst = lgb.train(params=params, \n",
    "                    train_set=dtr, \n",
    "                    valid_sets=[dtr, dvl],\n",
    "                    best_params=best_params,\n",
    "                    tuning_history=tuning_history,\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=100,\n",
    "                   )\n",
    "                    \n",
    "    return bst,best_params,tuning_history\n",
    "\n",
    "def valid(bst,dftr,dfvl):\n",
    "    prdtr = bst.predict(dftr[cols_feat],num_iteration=bst.best_iteration)\n",
    "    prdvl = bst.predict(dfvl[cols_feat],num_iteration=bst.best_iteration)\n",
    "    return prdtr,prdvl\n",
    "\n",
    "def do_tgt(tgt):\n",
    "    params=tgt2params[tgt]\n",
    "    tgtcol=tgt2col[tgt]\n",
    "    dftrvl, pops=getdftrvl(tgt)\n",
    "    split=int(len(dftrvl)*0.85)\n",
    "    dftr,dfvl=dftrvl[:split],dftrvl[split:]\n",
    "    dtr = lgb.Dataset(dftr[cols_feat], label=dftr[tgtcol])\n",
    "    dvl = lgb.Dataset(dfvl[cols_feat], label=dfvl[tgtcol])\n",
    "    bst,best_params,tuning_history=train(params,dtr,dvl)\n",
    "    prdtr,prdvl=valid(bst,dftr,dfvl)\n",
    "    \n",
    "    tgt2bst[tgt]=bst\n",
    "    tgt2best_params[tgt]=best_params\n",
    "    tgt2tuning_history[tgt]=tuning_history\n",
    "    tgt2ytr[tgt]=dftr[tgtcol]\n",
    "    tgt2yvl[tgt]=dfvl[tgtcol]\n",
    "    tgt2pops[tgt]=pops\n",
    "    tgt2prdtr[tgt]=prdtr\n",
    "    tgt2prdvl[tgt]=prdvl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24 15:38:05 Retweet ********************************************************************************\n",
      "Retweet\n",
      "n_pos_wanted 100\n",
      "2020-03-24 15:38:05 chunk 1\n",
      "2020-03-24 15:38:05 chunk 2\n",
      "dftrvl.shape: (1000, 28) dftrvl[tgtcol].mean(): 0.212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "twttyp                  category\n",
       "lang                    category\n",
       "u1_fllwer_cnt              int64\n",
       "u1_fllwng_cnt              int64\n",
       "u1_vrfed                    bool\n",
       "u2_fllwer_cnt              int64\n",
       "u2_fllwng_cnt              int64\n",
       "u2_vrfed                    bool\n",
       "u1_fllw_u2                  bool\n",
       "len_toks                   int64\n",
       "has_media_Photo             bool\n",
       "has_media_Video             bool\n",
       "has_media_GIF               bool\n",
       "num_hshtgs                 int64\n",
       "num_links                  int64\n",
       "num_domns                  int64\n",
       "twt_age                    int64\n",
       "u1_age                     int64\n",
       "u2_age                     int64\n",
       "tm_dayofweek               int64\n",
       "tm_hour                    int64\n",
       "tmdlta_u2u1                int64\n",
       "u1_fllwer_cnt_by_age     float64\n",
       "u1_fllwng_cnt_by_age     float64\n",
       "retwt                       int8\n",
       "reply                       int8\n",
       "like                        int8\n",
       "retwt_cmmnt                 int8\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_pop': 1000, 'target_pop': 212, 'sampled_train_pop': 1000, 'sampled_target_pop': 212}\n",
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': 0, 'boosting_type': 'gbdt'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/_experimental.py:87: ExperimentalWarning: train is experimental (supported from v0.18.0). The interface can change in the future.\n",
      "  ExperimentalWarning\n",
      "tune_feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0372239\tvalid_1's binary_logloss: 0.676846\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.217313\tvalid_1's binary_logloss: 0.495529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.495529:  14%|#4        | 1/7 [00:02<00:15,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0327378\tvalid_1's binary_logloss: 0.687035\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.322383\tvalid_1's binary_logloss: 0.496011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.495529:  29%|##8       | 2/7 [00:05<00:12,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0294413\tvalid_1's binary_logloss: 0.702776\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.283621\tvalid_1's binary_logloss: 0.509902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.495529:  43%|####2     | 3/7 [00:07<00:10,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0267399\tvalid_1's binary_logloss: 0.688221\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's binary_logloss: 0.219965\tvalid_1's binary_logloss: 0.485437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.485437:  57%|#####7    | 4/7 [00:11<00:08,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0244557\tvalid_1's binary_logloss: 0.717433\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.355337\tvalid_1's binary_logloss: 0.506939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.485437:  71%|#######1  | 5/7 [00:13<00:05,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0235907\tvalid_1's binary_logloss: 0.7071\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.32465\tvalid_1's binary_logloss: 0.49389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.485437:  86%|########5 | 6/7 [00:15<00:02,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.021596\tvalid_1's binary_logloss: 0.731467\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.31415\tvalid_1's binary_logloss: 0.496003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.485437: 100%|##########| 7/7 [00:18<00:00,  2.59s/it]\n",
      "tune_num_leaves, val_score: 0.485437:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:   5%|5         | 1/20 [00:03<00:57,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  10%|#         | 2/20 [00:06<00:54,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  15%|#5        | 3/20 [00:09<00:51,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  20%|##        | 4/20 [00:12<00:49,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  25%|##5       | 5/20 [00:16<00:47,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  30%|###       | 6/20 [00:19<00:43,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  35%|###5      | 7/20 [00:22<00:40,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  40%|####      | 8/20 [00:23<00:33,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  45%|####5     | 9/20 [00:25<00:27,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  50%|#####     | 10/20 [00:28<00:23,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.238082\tvalid_1's binary_logloss: 0.527882\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.325119\tvalid_1's binary_logloss: 0.490359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  55%|#####5    | 11/20 [00:28<00:17,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  60%|######    | 12/20 [00:31<00:16,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  65%|######5   | 13/20 [00:33<00:15,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.0266154\tvalid_1's binary_logloss: 0.698874\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.249204\tvalid_1's binary_logloss: 0.488118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.485437:  70%|#######   | 14/20 [00:36<00:13,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.330625\tvalid_1's binary_logloss: 0.494024\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.38734\tvalid_1's binary_logloss: 0.477118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.477118:  75%|#######5  | 15/20 [00:37<00:09,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.330625\tvalid_1's binary_logloss: 0.494024\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.38734\tvalid_1's binary_logloss: 0.477118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.477118:  80%|########  | 16/20 [00:37<00:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.374678\tvalid_1's binary_logloss: 0.495209\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-992267a83316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtgts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdo_tgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fc700d8dc94a>\u001b[0m in \u001b[0;36mdo_tgt\u001b[0;34m(tgt)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdftr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdftr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtgtcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdvl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfvl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdfvl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtgtcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuning_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdvl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprdtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprdvl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdftr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfvl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fc700d8dc94a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtr, dvl)\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mtuning_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuning_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                    )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/_experimental.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 )\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/__init__.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mauto_booster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightGBMTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_booster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_num_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime_budget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime_budget\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melapsed_secs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mtune_num_leaves\u001b[0;34m(self, n_trials)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;31m# type: (int) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_leaves'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtune_bagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mtune_params\u001b[0;34m(self, target_param_names, n_trials, sampler)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigher_is_better\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'minimize'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             sampler=sampler)\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 self._optimize_sequential(func, n_trials, timeout, catch, callbacks,\n\u001b[0;32m--> 319\u001b[0;31m                                           gc_after_trial, None)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    595\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             message = 'Setting status of trial#{} as {}. {}'.format(trial_number,\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/integration/lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mval_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_booster_best_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params_shared = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": 0,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}\n",
    "tgt2params = {k:params_shared for k in tgts}\n",
    "\n",
    "tgt2bst={}\n",
    "tgt2best_params={}\n",
    "tgt2tuning_history={}\n",
    "tgt2ytr={}\n",
    "tgt2yvl={}\n",
    "tgt2prdtr={}\n",
    "tgt2prdvl={}\n",
    "tgt2pops={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt, '*'*80)\n",
    "    do_tgt(tgt)\n",
    "    \n",
    "pickle.dump(tgt2bst, open(f\"{p_out}/tgt2bst.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tr vl"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for tgt in tgt2evalres:\n",
    "    evalres=tgt2evalres[tgt]\n",
    "    plt.plot(evalres['train']['logloss'][10:])\n",
    "    plt.plot(evalres['eval']['logloss'][10:])\n",
    "    plt.title(f\"{tgt} logloss {len(evalres['train']['logloss'])} rounds\")\n",
    "    plt.show()\n",
    "    plt.plot(evalres['train']['aucpr'])\n",
    "    plt.plot(evalres['eval']['aucpr'])\n",
    "    plt.title(f\"{tgt} aucpr {len(evalres['train']['aucpr'])} rounds\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def show_feat_importance(tgt):\n",
    "    bst=tgt2bst[tgt]\n",
    "    ax = xgb.plot_importance(bst, height=0.8, max_num_features=9)\n",
    "    ax.grid(False, axis=\"y\")\n",
    "    ax.set_title(f'{tgt} Estimated feature importance')\n",
    "    plt.show()\n",
    "    feat2importance=bst.get_fscore()\n",
    "    print(tgt)\n",
    "    display(pd.DataFrame([feat2importance.keys(), \n",
    "                          feat2importance.values()]).T.sort_values(1, ascending=False))\n",
    "\n",
    "for tgt in tgt2bst:\n",
    "    show_feat_importance(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2auc_tr={}\n",
    "tgt2rce_tr={}\n",
    "tgt2auc_vl={}\n",
    "tgt2rce_vl={}\n",
    "for tgt in tgt2bst:\n",
    "    print(tgt)\n",
    "    prdtr_i, prdvl_i = tgt2prdtr[tgt], tgt2prdvl[tgt]\n",
    "    ytr_i, yvl_i = tgt2ytr[tgt], tgt2yvl[tgt]\n",
    "    scr_auc_tr=compute_prauc(prdtr_i, ytr_i)\n",
    "    scr_rce_tr=compute_rce(prdtr_i, ytr_i)\n",
    "    scr_auc_vl=compute_prauc(prdvl_i, yvl_i)\n",
    "    scr_rce_vl=compute_rce(prdvl_i, yvl_i)\n",
    "\n",
    "    tgt2auc_tr[tgt]=scr_auc_tr\n",
    "    tgt2rce_tr[tgt]=scr_rce_tr\n",
    "    tgt2auc_vl[tgt]=scr_auc_vl\n",
    "    tgt2rce_vl[tgt]=scr_rce_vl\n",
    "    \n",
    "    print('tr prauc:', f'{scr_auc_tr:.4f}','tr rce:', f'{scr_rce_tr:.4f}', )\n",
    "    print('vl prauc:', f'{scr_auc_vl:.4f}','vl rce:', f'{scr_rce_vl:.4f}', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsttr=[]\n",
    "lstvl=[]\n",
    "for tgt in ['Retweet','Reply','Like','RTwCmnt',]:\n",
    "    if tgt not in tgt2bst: continue\n",
    "    lsttr+=[(f'PRAUC {tgt}',tgt2auc_tr[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_tr[tgt])]\n",
    "    lstvl+=[(f'PRAUC {tgt}',tgt2auc_vl[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_vl[tgt])]\n",
    "\n",
    "dfscrtr=pd.DataFrame(lsttr)\n",
    "dfscrtr.columns=['metric','scr']\n",
    "dfscrvl=pd.DataFrame(lstvl)\n",
    "dfscrvl.columns=['metric','scr']\n",
    "dfscr = pd.merge(dfscrtr, dfscrvl, on='metric', suffixes=('tr','vl'))\n",
    "dfscr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt=tgts[1]\n",
    "# tgtcol=tgt2col[tgt]\n",
    "# bst=tgt2bst[tgt]\n",
    "\n",
    "# dvalid=xgb.DMatrix(dfvalid[cols_feat], label=dfvalid[tgtcol], feature_names=cols_feat)\n",
    "\n",
    "# prdvalid = bst.predict(dvalid, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "# pops=tgt2pops[tgt]\n",
    "\n",
    "# prdvalid[:10]\n",
    "# # array([0.11734424, 0.09971393, 0.05619054, 0.03059793, 0.07979691,\n",
    "# #        0.01358252, 0.05293725, 0.27954698, 0.05738379, 0.01741553],\n",
    "# #       dtype=float32)\n",
    "\n",
    "\n",
    "# pops\n",
    "# # {'train_pop': 4000000,\n",
    "# #  'target_pop': 109752,\n",
    "# #  'sampled_train_pop': 1000000,\n",
    "# #  'sampled_target_pop': 109752}\n",
    "\n",
    "# prdvalid_calib = calibration(prdvalid, **pops)\n",
    "\n",
    "# prdvalid_calib[:10]\n",
    "# # array([0.02952491, 0.02471944, 0.01344113, 0.00717127, 0.01945818,\n",
    "# #        0.00314114, 0.0126298 , 0.08155248, 0.01373977, 0.00403964],\n",
    "# #       dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_post_valid(tgt):\n",
    "    tgtcol=tgt2col[tgt]\n",
    "    bst=tgt2bst[tgt]\n",
    "    pops=tgt2pops[tgt]\n",
    "    prdvalid = bst.predict(dfvalid[cols_feat])\n",
    "    prdvalid_calib = calibration(prdvalid, **pops)\n",
    "    return prdvalid,prdvalid_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2yvalid={tgt:dfvalid[tgt2col[tgt]] for tgt in tgts}\n",
    "tgt2prdvalid={}\n",
    "tgt2prdvalid_calib={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt)\n",
    "    tgt2prdvalid[tgt],tgt2prdvalid_calib[tgt]=do_post_valid(tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2auc_valid={}\n",
    "tgt2rce_valid={}\n",
    "tgt2auc_valid_calib={}\n",
    "tgt2rce_valid_calib={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt)\n",
    "    prdvalid, prdvalid_calib = tgt2prdvalid[tgt], tgt2prdvalid_calib[tgt]\n",
    "    yvalid = tgt2yvalid[tgt]\n",
    "    scr_auc_valid=compute_prauc(prdvalid, yvalid)\n",
    "    scr_rce_valid=compute_rce(prdvalid, yvalid)\n",
    "    scr_auc_valid_calib=compute_prauc(prdvalid_calib, yvalid)\n",
    "    scr_rce_valid_calib=compute_rce(prdvalid_calib, yvalid)\n",
    "\n",
    "    tgt2auc_valid[tgt]=scr_auc_valid\n",
    "    tgt2rce_valid[tgt]=scr_rce_valid\n",
    "    tgt2auc_valid_calib[tgt]=scr_auc_valid_calib\n",
    "    tgt2rce_valid_calib[tgt]=scr_rce_valid_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tgt in tgts:\n",
    "    print(tgt)\n",
    "    print('tr          prauc:', f'{tgt2auc_tr[tgt]:.4f}','tr rce:', f'{tgt2rce_tr[tgt]:.4f}', )\n",
    "    print('vl          prauc:', f'{tgt2auc_vl[tgt]:.4f}','tr rce:', f'{tgt2rce_vl[tgt]:.4f}', )\n",
    "    print('valid       prauc:', f'{tgt2auc_valid[tgt]:.4f}','tr rce:', f'{tgt2rce_valid[tgt]:.4f}', )\n",
    "    print('valid_calib prauc:', f'{tgt2auc_valid_calib[tgt]:.4f}','tr rce:', f'{tgt2rce_valid_calib[tgt]:.4f}', )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsttr=[]\n",
    "lstvl=[]\n",
    "lstvalid=[]\n",
    "lstvalid_calib=[]\n",
    "for tgt in ['Retweet','Reply','Like','RTwCmnt',]:\n",
    "    if tgt not in tgt2bst: continue\n",
    "    lsttr+=[(f'PRAUC {tgt}',tgt2auc_tr[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_tr[tgt])]\n",
    "    lstvl+=[(f'PRAUC {tgt}',tgt2auc_vl[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_vl[tgt])]\n",
    "    lstvalid+=[(f'PRAUC {tgt}',tgt2auc_valid[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_valid[tgt])]\n",
    "    lstvalid_calib+=[(f'PRAUC {tgt}',tgt2auc_valid_calib[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_valid_calib[tgt])]\n",
    "\n",
    "dfscrtr=pd.DataFrame(lsttr)\n",
    "dfscrtr.columns=['metric','scr']\n",
    "dfscrvl=pd.DataFrame(lstvl)\n",
    "dfscrvl.columns=['metric','scr']\n",
    "dfscrvalid=pd.DataFrame(lstvalid)\n",
    "dfscrvalid.columns=['metric','scr']\n",
    "dfscrvalid_calib=pd.DataFrame(lstvalid_calib)\n",
    "dfscrvalid_calib.columns=['metric','scr']\n",
    "\n",
    "dfscr = reduce(lambda df1,df2: pd.merge(df1,df2,on='metric'), \n",
    "            [dfscrtr,dfscrvl,dfscrvalid,dfscrvalid_calib])\n",
    "\n",
    "dfscr.columns=['scr','tr','vl','valid','valid_calib']\n",
    "dfscr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls -lhS $p_in | grep val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst=pd.read_csv(\n",
    "    f'{p_in}/val_{valtmstmp}.tsv',\n",
    "#     f'{p_in}/val_259A6F6DFD672CB1F883CBEC01B99F2D_1584405047.tsv',\n",
    "    sep='\\x01', header=None, names=cols_val,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst = prp_df(dftst, istrn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtst = xgb.DMatrix(dftst[cols_feat], feature_names=cols_feat)\n",
    "tgt2prdtst={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt)\n",
    "    bst = tgt2bst[tgt]\n",
    "    pops=tgt2pops[tgt]\n",
    "    prdtst = bst.predict(dtst, ntree_limit=bst.best_ntree_limit)\n",
    "    prdtst_calib = calibration(prdtst, **pops)\n",
    "    tgt2prdtst[tgt] = prdtst_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub_ids = dftst[['twtid','u2id',]]\n",
    "\n",
    "tgt2dfsub = {}\n",
    "for tgt,prdtst in tgt2prdtst.items():\n",
    "    dfsub = dfsub_ids.copy()\n",
    "    dfsub['scr'] = prdtst\n",
    "    tgt2dfsub[tgt]=dfsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i,tgt in enumerate(['Retweet','Reply','RTwCmnt','Like',]):\n",
    "    dfsub = tgt2dfsub[tgt]\n",
    "    print(dtnow(), tgt)\n",
    "    dfsub.to_csv(f'{p_out}/{i}_{tgt}__{valtmstmp}__{PRFX}.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
