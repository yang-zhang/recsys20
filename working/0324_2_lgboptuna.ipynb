{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258\n",
    "- https://github.com/optuna/optuna/blob/master/examples/lightgbm_tuner_simple.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-03-17 02:32:24', '2020-03-24 17:09:45']\n",
      "['2020-02-06 00:00:00', '2020-02-13 00:00:00']\n"
     ]
    }
   ],
   "source": [
    "PRFX='0324_2'\n",
    "trntmstmp=1584412344\n",
    "valtmstmp=1585069785\n",
    "import datetime\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (trntmstmp, valtmstmp)])\n",
    "\n",
    "grand_total=1.5e8\n",
    "MIN_TM_TRN=1580947200\n",
    "MIN_TM_TST=1581552000\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (MIN_TM_TRN, MIN_TM_TST)])\n",
    "\n",
    "\n",
    "CHNKSZ=1e6\n",
    "POST_RATE_WANTED=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Retweet': 'retwt',\n",
       " 'Reply': 'reply',\n",
       " 'Like': 'like',\n",
       " 'RTwCmnt': 'retwt_cmmnt'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# import dask\n",
    "# print('dask.__version__', dask.__version__)\n",
    "import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "\n",
    "# optuna.logging.CRITICAL, optuna.logging.FATAL\n",
    "# optuna.logging.ERROR\n",
    "# optuna.logging.WARNING, optuna.logging.WARN\n",
    "# optuna.logging.INFO\n",
    "# optuna.logging.DEBUG\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "# import dask_xgboost\n",
    "# import dask.dataframe as dd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "from dask.distributed import Client\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from functools import reduce\n",
    "import datetime\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "SEED=101\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "p_out=f'{HOME}/output/{PRFX}'\n",
    "Path(p_out).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, log_loss\n",
    "\n",
    "def compute_prauc(pred, gt):\n",
    "    prec, recall, thresh = precision_recall_curve(gt, pred)\n",
    "    prauc = auc(recall, prec)\n",
    "    return prauc\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "    positive = len([x for x in gt if x == 1])\n",
    "    ctr = positive/float(len(gt))\n",
    "    return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "# https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
    "# How to use the function?\n",
    "# Letâ€™s say your goal is to generate a model that shows the credit default probabilities and your original \n",
    "# training data has 50,000 rows with only 500 of them labeled as target class. When you sample your non-target \n",
    "# instances randomly and reduce the total row count to 10,000, while conserving 500 target rows, our calibration\n",
    "# function becomes:\n",
    "# calibration(model_results, 50000, 500, 10000, 500)\n",
    "# Here model_results is your model probability output array. After you train your model and put the results in it, your function is ready to use. \n",
    "\n",
    "def calibration(data, train_pop, target_pop, sampled_train_pop, sampled_target_pop):\n",
    "    calibrated_data = \\\n",
    "    ((data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop)) /\n",
    "    ((\n",
    "        (1 - data) * (1 - target_pop / train_pop) / (1 - sampled_target_pop / sampled_train_pop)\n",
    "     ) +\n",
    "     (\n",
    "        data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop)\n",
    "     )))\n",
    "\n",
    "    return calibrated_data\n",
    "\n",
    "cols=[\n",
    "'toks',\n",
    "'hshtgs',\n",
    "'twtid',\n",
    "'media',\n",
    "'links',\n",
    "'domns',\n",
    "'twttyp',\n",
    "'lang',\n",
    "'tm',\n",
    "\n",
    "'u1id',\n",
    "'u1_fllwer_cnt',\n",
    "'u1_fllwng_cnt',\n",
    "'u1_vrfed',\n",
    "'u1_create_tm',\n",
    "\n",
    "'u2id',\n",
    "'u2_fllwer_cnt',\n",
    "'u2_fllwng_cnt',\n",
    "'u2_vrfed',\n",
    "'u2_create_tm',\n",
    "\n",
    "'u1_fllw_u2',\n",
    "'reply_tm',\n",
    "'retwt_tm',\n",
    "'retwt_cmmnt_tm',\n",
    "'like_tm',\n",
    "]\n",
    "cols_cat = ['twttyp','lang']\n",
    "cols_val = cols[:-4]\n",
    "cols_tgt_tmstmp=[\n",
    "    'retwt_tm',\n",
    "    'reply_tm',\n",
    "    'like_tm',\n",
    "    'retwt_cmmnt_tm',\n",
    "]\n",
    "cols_tgt=[o.split('_tm')[0] for o in cols_tgt_tmstmp]\n",
    "tgts             = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "assert cols_tgt == ['retwt',  'reply','like','retwt_cmmnt',]\n",
    "ntgts=len(tgts)\n",
    "\n",
    "\n",
    "\n",
    "tgt2col=dict(zip(tgts,cols_tgt))\n",
    "tgt2col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chnks_trn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',\n",
    "                    header=None,names=cols, \n",
    "                        chunksize=CHNKSZ)\n",
    "# first chunk as validate data\n",
    "for ichnk,df in enumerate(chnks_trn):\n",
    "    df\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "istrn=True\n",
    "tm_min = MIN_TM_TRN if istrn else MIN_TM_TST\n",
    "df['len_toks'] = df.toks.apply(len)\n",
    "for media in ['Photo', 'Video', 'GIF']:\n",
    "    df[f'has_media_{media}'] = df.media.fillna('').apply(lambda x: media in x)\n",
    "for col in ['hshtgs', 'links', 'domns',]:\n",
    "    df[f'num_{col}'] = df[col].fillna('').apply(lambda x: len(x.split('\\t')) if len(x) else 0)\n",
    "\n",
    "df['twt_age'] = df.tm - tm_min\n",
    "df['u1_age']  = df.tm - df.u1_create_tm\n",
    "df['u2_age']  = df.tm - df.u2_create_tm\n",
    "\n",
    "tm_dt=pd.to_datetime(df.tm, unit='s')\n",
    "df['tm_dayofweek']=tm_dt.dt.dayofweek\n",
    "df['tm_hour']=tm_dt.dt.hour\n",
    "\n",
    "df['tmdlta_u2u1']  = df.u2_create_tm - df.u1_create_tm\n",
    "\n",
    "df['u1_fllwer_cnt_by_age'] = df.u1_fllwer_cnt / df.u1_age\n",
    "df['u1_fllwng_cnt_by_age'] = df.u2_fllwng_cnt / df.u2_age\n",
    "\n",
    "for col in ['twttyp','lang']:\n",
    "    df[col]=df[col].astype('category')\n",
    "\n",
    "if istrn: \n",
    "    df[cols_tgt]=df[cols_tgt_tmstmp].notna().astype('int8')\n",
    "    df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns',  \n",
    "                                   'tm', 'u1_create_tm','u2_create_tm', 'u1id', 'u2id', 'twtid', ]+cols_tgt_tmstmp, )\n",
    "else:\n",
    "    df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns', \n",
    "                                   'tm', 'u1_create_tm','u2_create_tm', 'u1id', ])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twttyp                  category\n",
       "lang                    category\n",
       "u1_fllwer_cnt              int64\n",
       "u1_fllwng_cnt              int64\n",
       "u1_vrfed                    bool\n",
       "u2_fllwer_cnt              int64\n",
       "u2_fllwng_cnt              int64\n",
       "u2_vrfed                    bool\n",
       "u1_fllw_u2                  bool\n",
       "len_toks                   int64\n",
       "has_media_Photo             bool\n",
       "has_media_Video             bool\n",
       "has_media_GIF               bool\n",
       "num_hshtgs                 int64\n",
       "num_links                  int64\n",
       "num_domns                  int64\n",
       "twt_age                    int64\n",
       "u1_age                     int64\n",
       "u2_age                     int64\n",
       "tm_dayofweek               int64\n",
       "tm_hour                    int64\n",
       "tmdlta_u2u1                int64\n",
       "u1_fllwer_cnt_by_age     float64\n",
       "u1_fllwng_cnt_by_age     float64\n",
       "retwt                       int8\n",
       "reply                       int8\n",
       "like                        int8\n",
       "retwt_cmmnt                 int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prp_df(df, istrn=True):\n",
    "    tm_min = MIN_TM_TRN if istrn else MIN_TM_TST\n",
    "    df['len_toks'] = df.toks.apply(len)\n",
    "    for media in ['Photo', 'Video', 'GIF']:\n",
    "        df[f'has_media_{media}'] = df.media.fillna('').apply(lambda x: media in x)\n",
    "    for col in ['hshtgs', 'links', 'domns',]:\n",
    "        df[f'num_{col}'] = df[col].fillna('').apply(lambda x: len(x.split('\\t')) if len(x) else 0)\n",
    "\n",
    "    df['twt_age'] = df.tm - tm_min\n",
    "    df['u1_age']  = df.tm - df.u1_create_tm\n",
    "    df['u2_age']  = df.tm - df.u2_create_tm\n",
    "\n",
    "    tm_dt=pd.to_datetime(df.tm, unit='s')\n",
    "    df['tm_dayofweek']=tm_dt.dt.dayofweek\n",
    "    df['tm_hour']=tm_dt.dt.hour\n",
    "\n",
    "    df['tmdlta_u2u1']  = df.u2_create_tm - df.u1_create_tm\n",
    "\n",
    "    df['u1_fllwer_cnt_by_age'] = df.u1_fllwer_cnt / df.u1_age\n",
    "    df['u1_fllwng_cnt_by_age'] = df.u2_fllwng_cnt / df.u2_age\n",
    "\n",
    "    for col in cols_cat:\n",
    "        df[col]=df[col].astype('category')\n",
    "\n",
    "    if istrn: \n",
    "        df[cols_tgt]=df[cols_tgt_tmstmp].notna().astype('int8')\n",
    "        df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns',  \n",
    "                                       'tm', 'u1_create_tm','u2_create_tm', 'u1id', 'u2id', 'twtid', ]+cols_tgt_tmstmp, )\n",
    "    else:\n",
    "        df.drop(inplace=True, columns=['toks', 'hshtgs', 'media', 'links', 'domns', \n",
    "                                       'tm', 'u1_create_tm','u2_create_tm', 'u1id', ])   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ls -hlS $p_in | grep {trntmstmp} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000000.0, 150.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_total, grand_total/CHNKSZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24 19:54:02 chunk 0\n",
      "dfvalid.shape: (1000000, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "twttyp                  category\n",
       "lang                    category\n",
       "u1_fllwer_cnt              int64\n",
       "u1_fllwng_cnt              int64\n",
       "u1_vrfed                    bool\n",
       "u2_fllwer_cnt              int64\n",
       "u2_fllwng_cnt              int64\n",
       "u2_vrfed                    bool\n",
       "u1_fllw_u2                  bool\n",
       "len_toks                   int64\n",
       "has_media_Photo             bool\n",
       "has_media_Video             bool\n",
       "has_media_GIF               bool\n",
       "num_hshtgs                 int64\n",
       "num_links                  int64\n",
       "num_domns                  int64\n",
       "twt_age                    int64\n",
       "u1_age                     int64\n",
       "u2_age                     int64\n",
       "tm_dayofweek               int64\n",
       "tm_hour                    int64\n",
       "tmdlta_u2u1                int64\n",
       "u1_fllwer_cnt_by_age     float64\n",
       "u1_fllwng_cnt_by_age     float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chnks_trn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',\n",
    "                    header=None,names=cols, \n",
    "                        chunksize=CHNKSZ)\n",
    "# first chunk as validate data\n",
    "for ichnk,df in enumerate(chnks_trn):\n",
    "    print(dtnow(), 'chunk', ichnk)\n",
    "#     print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') \n",
    "#            for o in (df.tm.min(), df.tm.max())])\n",
    "    dfvalid = prp_df(df)\n",
    "    break\n",
    "print('dfvalid.shape:',dfvalid.shape)\n",
    "\n",
    "cols_feat=[o for o in dfvalid.columns if o not in cols_tgt]\n",
    "\n",
    "display(dfvalid[cols_feat].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trnval data func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdftrvl(tgt):\n",
    "    print(tgt)\n",
    "    tgtcol=tgt2col[tgt]\n",
    "    chnks_trn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',\n",
    "                        header=None,names=cols, \n",
    "                            chunksize=CHNKSZ)\n",
    "    len_df_wanted = int(CHNKSZ)\n",
    "    # retwt          0.113031\n",
    "    # reply          0.027488\n",
    "    # like           0.439499\n",
    "    # retwt_cmmnt    0.007742\n",
    "    pos_rate_wanted = POST_RATE_WANTED\n",
    "    n_pos_wanted = int(len_df_wanted*pos_rate_wanted)\n",
    "    print('n_pos_wanted', n_pos_wanted)\n",
    "    np.random.seed(SEED)\n",
    "    lst_df = []\n",
    "    n_pos_ttl = 0\n",
    "    for ichnk,df in enumerate(chnks_trn):\n",
    "        #skip first chunk (it was validate data)\n",
    "        if ichnk==0: continue\n",
    "        print(dtnow(), 'chunk', ichnk)\n",
    "        df = prp_df(df)\n",
    "        n_pos_ttl+= df[tgtcol].sum()\n",
    "        lst_df.append(df)\n",
    "        if n_pos_ttl>=n_pos_wanted: break\n",
    "\n",
    "    df = pd.concat(lst_df)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/questions/28556942/pandas-remove-rows-at-random-without-shuffling-dataset\n",
    "    idx_neg=np.where(df[tgtcol]==0)[0]\n",
    "    n_neg = len(idx_neg)\n",
    "    n_pos = len(df)-len(idx_neg)\n",
    "    n_neg2keep = len_df_wanted-n_pos\n",
    "    n_neg2rmv = n_neg-n_neg2keep\n",
    "    idx_neg2rmv = np.random.choice(idx_neg, n_neg2rmv, replace=False)\n",
    "    dftrvl = df.drop(idx_neg2rmv)\n",
    "    dftrvl = dftrvl.sample(len(dftrvl))\n",
    "    for col in cols_cat:\n",
    "        dftrvl[col]=dftrvl[col].astype('category')\n",
    "    \n",
    "#     display(dftrvl.dtypes)\n",
    "    print('dftrvl.shape:',dftrvl.shape,'dftrvl[tgtcol].mean():',dftrvl[tgtcol].mean())\n",
    "    \n",
    "    pops={\n",
    "        'train_pop':len(df),\n",
    "        'target_pop':n_pos,\n",
    "        'sampled_train_pop':len_df_wanted,\n",
    "        'sampled_target_pop':n_pos,\n",
    "    }\n",
    "    print(pops)\n",
    "    return dftrvl, pops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params,dtr,dvl):\n",
    "    print(params)\n",
    "    best_params, tuning_history = dict(), list()\n",
    "    evallist = [(dtr, 'train'), (dvl, 'eval')]\n",
    "    bst = lgb.train(params=params, \n",
    "                    train_set=dtr, \n",
    "                    valid_sets=[dtr, dvl],\n",
    "                    best_params=best_params,\n",
    "                    tuning_history=tuning_history,\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=100,\n",
    "                   )\n",
    "                    \n",
    "    return bst,best_params,tuning_history\n",
    "\n",
    "def valid(bst,dftr,dfvl):\n",
    "    prdtr = bst.predict(dftr[cols_feat],num_iteration=bst.best_iteration)\n",
    "    prdvl = bst.predict(dfvl[cols_feat],num_iteration=bst.best_iteration)\n",
    "    return prdtr,prdvl\n",
    "\n",
    "def do_tgt(tgt):\n",
    "    params=tgt2params[tgt]\n",
    "    tgtcol=tgt2col[tgt]\n",
    "    dftrvl, pops=getdftrvl(tgt)\n",
    "    split=int(len(dftrvl)*0.85)\n",
    "    dftr,dfvl=dftrvl[:split],dftrvl[split:]\n",
    "    dtr = lgb.Dataset(dftr[cols_feat], label=dftr[tgtcol])\n",
    "    dvl = lgb.Dataset(dfvl[cols_feat], label=dfvl[tgtcol])\n",
    "    bst,best_params,tuning_history=train(params,dtr,dvl)\n",
    "    prdtr,prdvl=valid(bst,dftr,dfvl)\n",
    "    \n",
    "    tgt2bst[tgt]=bst\n",
    "    tgt2best_params[tgt]=best_params\n",
    "    tgt2tuning_history[tgt]=tuning_history\n",
    "    tgt2ytr[tgt]=dftr[tgtcol]\n",
    "    tgt2yvl[tgt]=dfvl[tgtcol]\n",
    "    tgt2pops[tgt]=pops\n",
    "    tgt2prdtr[tgt]=prdtr\n",
    "    tgt2prdvl[tgt]=prdvl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24 19:54:06 Retweet ********************************************************************************\n",
      "Retweet\n",
      "n_pos_wanted 100000\n",
      "2020-03-24 19:54:21 chunk 1\n",
      "dftrvl.shape: (1000000, 28) dftrvl[tgtcol].mean(): 0.112823\n",
      "{'train_pop': 1000000, 'target_pop': 112823, 'sampled_train_pop': 1000000, 'sampled_target_pop': 112823}\n",
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': 0, 'boosting_type': 'gbdt'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/optuna/_experimental.py:87: ExperimentalWarning: train is experimental (supported from v0.18.0). The interface can change in the future.\n",
      "  ExperimentalWarning\n",
      "tune_feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.308012\tvalid_1's binary_logloss: 0.313027\n",
      "[200]\ttraining's binary_logloss: 0.303993\tvalid_1's binary_logloss: 0.311383\n",
      "[300]\ttraining's binary_logloss: 0.301065\tvalid_1's binary_logloss: 0.310641\n",
      "[400]\ttraining's binary_logloss: 0.298286\tvalid_1's binary_logloss: 0.310082\n",
      "[500]\ttraining's binary_logloss: 0.295875\tvalid_1's binary_logloss: 0.309765\n",
      "[600]\ttraining's binary_logloss: 0.293591\tvalid_1's binary_logloss: 0.309462\n",
      "[700]\ttraining's binary_logloss: 0.291297\tvalid_1's binary_logloss: 0.309288\n",
      "[800]\ttraining's binary_logloss: 0.289068\tvalid_1's binary_logloss: 0.309099\n",
      "[900]\ttraining's binary_logloss: 0.286941\tvalid_1's binary_logloss: 0.308958\n",
      "[1000]\ttraining's binary_logloss: 0.284835\tvalid_1's binary_logloss: 0.308855\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.284835\tvalid_1's binary_logloss: 0.308855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308855:  14%|#4        | 1/7 [00:35<03:31, 35.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.307702\tvalid_1's binary_logloss: 0.312816\n",
      "[200]\ttraining's binary_logloss: 0.303753\tvalid_1's binary_logloss: 0.311303\n",
      "[300]\ttraining's binary_logloss: 0.30065\tvalid_1's binary_logloss: 0.31052\n",
      "[400]\ttraining's binary_logloss: 0.298007\tvalid_1's binary_logloss: 0.31009\n",
      "[500]\ttraining's binary_logloss: 0.295328\tvalid_1's binary_logloss: 0.309616\n",
      "[600]\ttraining's binary_logloss: 0.292884\tvalid_1's binary_logloss: 0.309281\n",
      "[700]\ttraining's binary_logloss: 0.290537\tvalid_1's binary_logloss: 0.309197\n",
      "[800]\ttraining's binary_logloss: 0.288311\tvalid_1's binary_logloss: 0.309065\n",
      "[900]\ttraining's binary_logloss: 0.286105\tvalid_1's binary_logloss: 0.308925\n",
      "[1000]\ttraining's binary_logloss: 0.283809\tvalid_1's binary_logloss: 0.308794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.283809\tvalid_1's binary_logloss: 0.308794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308794:  29%|##8       | 2/7 [01:07<02:50, 34.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.307489\tvalid_1's binary_logloss: 0.312715\n",
      "[200]\ttraining's binary_logloss: 0.303578\tvalid_1's binary_logloss: 0.3113\n",
      "[300]\ttraining's binary_logloss: 0.300114\tvalid_1's binary_logloss: 0.310273\n",
      "[400]\ttraining's binary_logloss: 0.297308\tvalid_1's binary_logloss: 0.309924\n",
      "[500]\ttraining's binary_logloss: 0.294562\tvalid_1's binary_logloss: 0.309492\n",
      "[600]\ttraining's binary_logloss: 0.292024\tvalid_1's binary_logloss: 0.309189\n",
      "[700]\ttraining's binary_logloss: 0.289607\tvalid_1's binary_logloss: 0.309059\n",
      "[800]\ttraining's binary_logloss: 0.287282\tvalid_1's binary_logloss: 0.308909\n",
      "[900]\ttraining's binary_logloss: 0.28515\tvalid_1's binary_logloss: 0.308906\n",
      "[1000]\ttraining's binary_logloss: 0.282911\tvalid_1's binary_logloss: 0.30871\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.282911\tvalid_1's binary_logloss: 0.30871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308710:  43%|####2     | 3/7 [01:38<02:13, 33.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.30708\tvalid_1's binary_logloss: 0.312396\n",
      "[200]\ttraining's binary_logloss: 0.303008\tvalid_1's binary_logloss: 0.311003\n",
      "[300]\ttraining's binary_logloss: 0.299788\tvalid_1's binary_logloss: 0.310304\n",
      "[400]\ttraining's binary_logloss: 0.296601\tvalid_1's binary_logloss: 0.309672\n",
      "[500]\ttraining's binary_logloss: 0.293884\tvalid_1's binary_logloss: 0.309344\n",
      "[600]\ttraining's binary_logloss: 0.291264\tvalid_1's binary_logloss: 0.309238\n",
      "[700]\ttraining's binary_logloss: 0.288746\tvalid_1's binary_logloss: 0.309018\n",
      "[800]\ttraining's binary_logloss: 0.286333\tvalid_1's binary_logloss: 0.308918\n",
      "[900]\ttraining's binary_logloss: 0.284074\tvalid_1's binary_logloss: 0.308765\n",
      "[1000]\ttraining's binary_logloss: 0.281654\tvalid_1's binary_logloss: 0.308659\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.281654\tvalid_1's binary_logloss: 0.308659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308659:  57%|#####7    | 4/7 [02:10<01:38, 32.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306864\tvalid_1's binary_logloss: 0.312401\n",
      "[200]\ttraining's binary_logloss: 0.30268\tvalid_1's binary_logloss: 0.310944\n",
      "[300]\ttraining's binary_logloss: 0.299351\tvalid_1's binary_logloss: 0.310256\n",
      "[400]\ttraining's binary_logloss: 0.296272\tvalid_1's binary_logloss: 0.309767\n",
      "[500]\ttraining's binary_logloss: 0.293335\tvalid_1's binary_logloss: 0.309385\n",
      "[600]\ttraining's binary_logloss: 0.290662\tvalid_1's binary_logloss: 0.309134\n",
      "[700]\ttraining's binary_logloss: 0.288201\tvalid_1's binary_logloss: 0.309032\n",
      "[800]\ttraining's binary_logloss: 0.285821\tvalid_1's binary_logloss: 0.308888\n",
      "[900]\ttraining's binary_logloss: 0.283512\tvalid_1's binary_logloss: 0.30883\n",
      "[1000]\ttraining's binary_logloss: 0.281142\tvalid_1's binary_logloss: 0.308813\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.281142\tvalid_1's binary_logloss: 0.308813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308659:  71%|#######1  | 5/7 [03:29<01:33, 46.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306782\tvalid_1's binary_logloss: 0.312464\n",
      "[200]\ttraining's binary_logloss: 0.302507\tvalid_1's binary_logloss: 0.311073\n",
      "[300]\ttraining's binary_logloss: 0.299107\tvalid_1's binary_logloss: 0.310393\n",
      "[400]\ttraining's binary_logloss: 0.295827\tvalid_1's binary_logloss: 0.309898\n",
      "[500]\ttraining's binary_logloss: 0.292975\tvalid_1's binary_logloss: 0.309548\n",
      "[600]\ttraining's binary_logloss: 0.290315\tvalid_1's binary_logloss: 0.309322\n",
      "[700]\ttraining's binary_logloss: 0.287728\tvalid_1's binary_logloss: 0.309176\n",
      "[800]\ttraining's binary_logloss: 0.285346\tvalid_1's binary_logloss: 0.309012\n",
      "[900]\ttraining's binary_logloss: 0.282857\tvalid_1's binary_logloss: 0.308916\n",
      "Early stopping, best iteration is:\n",
      "[871]\ttraining's binary_logloss: 0.283521\tvalid_1's binary_logloss: 0.308877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308659:  86%|########5 | 6/7 [05:03<01:00, 60.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306649\tvalid_1's binary_logloss: 0.312372\n",
      "[200]\ttraining's binary_logloss: 0.302362\tvalid_1's binary_logloss: 0.311063\n",
      "[300]\ttraining's binary_logloss: 0.299057\tvalid_1's binary_logloss: 0.310628\n",
      "[400]\ttraining's binary_logloss: 0.29582\tvalid_1's binary_logloss: 0.310113\n",
      "[500]\ttraining's binary_logloss: 0.292942\tvalid_1's binary_logloss: 0.30986\n",
      "[600]\ttraining's binary_logloss: 0.290189\tvalid_1's binary_logloss: 0.309517\n",
      "[700]\ttraining's binary_logloss: 0.287536\tvalid_1's binary_logloss: 0.309318\n",
      "[800]\ttraining's binary_logloss: 0.284878\tvalid_1's binary_logloss: 0.309167\n",
      "[900]\ttraining's binary_logloss: 0.282427\tvalid_1's binary_logloss: 0.309063\n",
      "[1000]\ttraining's binary_logloss: 0.280069\tvalid_1's binary_logloss: 0.309037\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.280069\tvalid_1's binary_logloss: 0.309037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308659: 100%|##########| 7/7 [06:37<00:00, 56.75s/it]\n",
      "tune_num_leaves, val_score: 0.308659:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.326333\tvalid_1's binary_logloss: 0.32877\n",
      "[200]\ttraining's binary_logloss: 0.323148\tvalid_1's binary_logloss: 0.325791\n",
      "[300]\ttraining's binary_logloss: 0.322005\tvalid_1's binary_logloss: 0.324751\n",
      "[400]\ttraining's binary_logloss: 0.321477\tvalid_1's binary_logloss: 0.324312\n",
      "[500]\ttraining's binary_logloss: 0.321181\tvalid_1's binary_logloss: 0.324071\n",
      "[600]\ttraining's binary_logloss: 0.320983\tvalid_1's binary_logloss: 0.323912\n",
      "[700]\ttraining's binary_logloss: 0.320836\tvalid_1's binary_logloss: 0.323799\n",
      "[800]\ttraining's binary_logloss: 0.320722\tvalid_1's binary_logloss: 0.32371\n",
      "[900]\ttraining's binary_logloss: 0.320631\tvalid_1's binary_logloss: 0.323646\n",
      "[1000]\ttraining's binary_logloss: 0.320556\tvalid_1's binary_logloss: 0.323586\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.320556\tvalid_1's binary_logloss: 0.323586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:   5%|5         | 1/20 [00:49<15:32, 49.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.29555\tvalid_1's binary_logloss: 0.309695\n",
      "[200]\ttraining's binary_logloss: 0.285245\tvalid_1's binary_logloss: 0.309066\n",
      "[300]\ttraining's binary_logloss: 0.27612\tvalid_1's binary_logloss: 0.308844\n",
      "[400]\ttraining's binary_logloss: 0.267575\tvalid_1's binary_logloss: 0.308796\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's binary_logloss: 0.270026\tvalid_1's binary_logloss: 0.308725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  10%|#         | 2/20 [02:38<20:07, 67.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.305846\tvalid_1's binary_logloss: 0.311821\n",
      "[200]\ttraining's binary_logloss: 0.301426\tvalid_1's binary_logloss: 0.310712\n",
      "[300]\ttraining's binary_logloss: 0.297701\tvalid_1's binary_logloss: 0.310154\n",
      "[400]\ttraining's binary_logloss: 0.294221\tvalid_1's binary_logloss: 0.309621\n",
      "[500]\ttraining's binary_logloss: 0.291021\tvalid_1's binary_logloss: 0.309264\n",
      "[600]\ttraining's binary_logloss: 0.287869\tvalid_1's binary_logloss: 0.309015\n",
      "[700]\ttraining's binary_logloss: 0.284848\tvalid_1's binary_logloss: 0.308827\n",
      "[800]\ttraining's binary_logloss: 0.282058\tvalid_1's binary_logloss: 0.308806\n",
      "[900]\ttraining's binary_logloss: 0.279439\tvalid_1's binary_logloss: 0.308733\n",
      "[1000]\ttraining's binary_logloss: 0.276792\tvalid_1's binary_logloss: 0.308708\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.276792\tvalid_1's binary_logloss: 0.308708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  15%|#5        | 3/20 [04:26<22:28, 79.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.299515\tvalid_1's binary_logloss: 0.31034\n",
      "[200]\ttraining's binary_logloss: 0.291451\tvalid_1's binary_logloss: 0.309445\n",
      "[300]\ttraining's binary_logloss: 0.284346\tvalid_1's binary_logloss: 0.309264\n",
      "[400]\ttraining's binary_logloss: 0.278135\tvalid_1's binary_logloss: 0.309129\n",
      "Early stopping, best iteration is:\n",
      "[364]\ttraining's binary_logloss: 0.280177\tvalid_1's binary_logloss: 0.309085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  20%|##        | 4/20 [05:30<19:59, 74.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.299034\tvalid_1's binary_logloss: 0.310272\n",
      "[200]\ttraining's binary_logloss: 0.290627\tvalid_1's binary_logloss: 0.309383\n",
      "[300]\ttraining's binary_logloss: 0.283319\tvalid_1's binary_logloss: 0.309008\n",
      "[400]\ttraining's binary_logloss: 0.277068\tvalid_1's binary_logloss: 0.308886\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's binary_logloss: 0.27744\tvalid_1's binary_logloss: 0.308882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  25%|##5       | 5/20 [06:43<18:32, 74.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.294655\tvalid_1's binary_logloss: 0.309791\n",
      "[200]\ttraining's binary_logloss: 0.283266\tvalid_1's binary_logloss: 0.309091\n",
      "[300]\ttraining's binary_logloss: 0.273819\tvalid_1's binary_logloss: 0.309079\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttraining's binary_logloss: 0.277502\tvalid_1's binary_logloss: 0.308966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  30%|###       | 6/20 [08:02<17:40, 75.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.295727\tvalid_1's binary_logloss: 0.309806\n",
      "[200]\ttraining's binary_logloss: 0.284817\tvalid_1's binary_logloss: 0.309108\n",
      "[300]\ttraining's binary_logloss: 0.27593\tvalid_1's binary_logloss: 0.309107\n",
      "[400]\ttraining's binary_logloss: 0.268347\tvalid_1's binary_logloss: 0.30919\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttraining's binary_logloss: 0.274408\tvalid_1's binary_logloss: 0.309068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  35%|###5      | 7/20 [09:35<17:32, 80.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.28361\tvalid_1's binary_logloss: 0.309134\n",
      "[200]\ttraining's binary_logloss: 0.26718\tvalid_1's binary_logloss: 0.308927\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's binary_logloss: 0.267749\tvalid_1's binary_logloss: 0.308881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  40%|####      | 8/20 [12:10<20:36, 103.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.301165\tvalid_1's binary_logloss: 0.310472\n",
      "[200]\ttraining's binary_logloss: 0.29404\tvalid_1's binary_logloss: 0.309737\n",
      "[300]\ttraining's binary_logloss: 0.287767\tvalid_1's binary_logloss: 0.309148\n",
      "[400]\ttraining's binary_logloss: 0.282063\tvalid_1's binary_logloss: 0.309001\n",
      "[500]\ttraining's binary_logloss: 0.277086\tvalid_1's binary_logloss: 0.308973\n",
      "[600]\ttraining's binary_logloss: 0.271719\tvalid_1's binary_logloss: 0.308808\n",
      "Early stopping, best iteration is:\n",
      "[578]\ttraining's binary_logloss: 0.272782\tvalid_1's binary_logloss: 0.308772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  45%|####5     | 9/20 [13:52<18:48, 102.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.289948\tvalid_1's binary_logloss: 0.30954\n",
      "[200]\ttraining's binary_logloss: 0.276344\tvalid_1's binary_logloss: 0.309216\n",
      "[300]\ttraining's binary_logloss: 0.264569\tvalid_1's binary_logloss: 0.309121\n",
      "Early stopping, best iteration is:\n",
      "[287]\ttraining's binary_logloss: 0.265894\tvalid_1's binary_logloss: 0.309069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  50%|#####     | 10/20 [17:15<22:09, 132.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.326333\tvalid_1's binary_logloss: 0.32877\n",
      "[200]\ttraining's binary_logloss: 0.323148\tvalid_1's binary_logloss: 0.325791\n",
      "[300]\ttraining's binary_logloss: 0.322005\tvalid_1's binary_logloss: 0.324751\n",
      "[400]\ttraining's binary_logloss: 0.321477\tvalid_1's binary_logloss: 0.324312\n",
      "[500]\ttraining's binary_logloss: 0.321181\tvalid_1's binary_logloss: 0.324071\n",
      "[600]\ttraining's binary_logloss: 0.320983\tvalid_1's binary_logloss: 0.323912\n",
      "[700]\ttraining's binary_logloss: 0.320836\tvalid_1's binary_logloss: 0.323799\n",
      "[800]\ttraining's binary_logloss: 0.320722\tvalid_1's binary_logloss: 0.32371\n",
      "[900]\ttraining's binary_logloss: 0.320631\tvalid_1's binary_logloss: 0.323646\n",
      "[1000]\ttraining's binary_logloss: 0.320556\tvalid_1's binary_logloss: 0.323586\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.320556\tvalid_1's binary_logloss: 0.323586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  55%|#####5    | 11/20 [17:57<15:49, 105.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.304998\tvalid_1's binary_logloss: 0.311488\n",
      "[200]\ttraining's binary_logloss: 0.299938\tvalid_1's binary_logloss: 0.310222\n",
      "[300]\ttraining's binary_logloss: 0.295835\tvalid_1's binary_logloss: 0.309663\n",
      "[400]\ttraining's binary_logloss: 0.292063\tvalid_1's binary_logloss: 0.30944\n",
      "[500]\ttraining's binary_logloss: 0.288476\tvalid_1's binary_logloss: 0.309161\n",
      "[600]\ttraining's binary_logloss: 0.285081\tvalid_1's binary_logloss: 0.308974\n",
      "[700]\ttraining's binary_logloss: 0.281918\tvalid_1's binary_logloss: 0.308869\n",
      "[800]\ttraining's binary_logloss: 0.278636\tvalid_1's binary_logloss: 0.308753\n",
      "[900]\ttraining's binary_logloss: 0.275674\tvalid_1's binary_logloss: 0.308744\n",
      "[1000]\ttraining's binary_logloss: 0.273005\tvalid_1's binary_logloss: 0.308694\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.273005\tvalid_1's binary_logloss: 0.308694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308659:  60%|######    | 12/20 [18:52<12:02, 90.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306796\tvalid_1's binary_logloss: 0.312325\n",
      "[200]\ttraining's binary_logloss: 0.302463\tvalid_1's binary_logloss: 0.310841\n",
      "[300]\ttraining's binary_logloss: 0.299153\tvalid_1's binary_logloss: 0.310254\n",
      "[400]\ttraining's binary_logloss: 0.295927\tvalid_1's binary_logloss: 0.30976\n",
      "[500]\ttraining's binary_logloss: 0.293061\tvalid_1's binary_logloss: 0.309407\n",
      "[600]\ttraining's binary_logloss: 0.290205\tvalid_1's binary_logloss: 0.30907\n",
      "[700]\ttraining's binary_logloss: 0.287577\tvalid_1's binary_logloss: 0.308863\n",
      "[800]\ttraining's binary_logloss: 0.285078\tvalid_1's binary_logloss: 0.308727\n",
      "[900]\ttraining's binary_logloss: 0.282752\tvalid_1's binary_logloss: 0.308609\n",
      "[1000]\ttraining's binary_logloss: 0.280377\tvalid_1's binary_logloss: 0.30855\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.280377\tvalid_1's binary_logloss: 0.30855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308550:  65%|######5   | 13/20 [20:17<10:21, 88.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306623\tvalid_1's binary_logloss: 0.312228\n",
      "[200]\ttraining's binary_logloss: 0.302283\tvalid_1's binary_logloss: 0.310735\n",
      "[300]\ttraining's binary_logloss: 0.298811\tvalid_1's binary_logloss: 0.310097\n",
      "[400]\ttraining's binary_logloss: 0.295651\tvalid_1's binary_logloss: 0.309667\n",
      "[500]\ttraining's binary_logloss: 0.292736\tvalid_1's binary_logloss: 0.309441\n",
      "[600]\ttraining's binary_logloss: 0.289962\tvalid_1's binary_logloss: 0.309187\n",
      "[700]\ttraining's binary_logloss: 0.287244\tvalid_1's binary_logloss: 0.308961\n",
      "[800]\ttraining's binary_logloss: 0.284612\tvalid_1's binary_logloss: 0.308843\n",
      "[900]\ttraining's binary_logloss: 0.282226\tvalid_1's binary_logloss: 0.308773\n",
      "[1000]\ttraining's binary_logloss: 0.279819\tvalid_1's binary_logloss: 0.30866\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279819\tvalid_1's binary_logloss: 0.30866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308550:  70%|#######   | 14/20 [21:58<09:14, 92.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306338\tvalid_1's binary_logloss: 0.312187\n",
      "[200]\ttraining's binary_logloss: 0.30196\tvalid_1's binary_logloss: 0.310974\n",
      "[300]\ttraining's binary_logloss: 0.298331\tvalid_1's binary_logloss: 0.310195\n",
      "[400]\ttraining's binary_logloss: 0.29501\tvalid_1's binary_logloss: 0.309742\n",
      "[500]\ttraining's binary_logloss: 0.291886\tvalid_1's binary_logloss: 0.309473\n",
      "[600]\ttraining's binary_logloss: 0.288918\tvalid_1's binary_logloss: 0.309316\n",
      "[700]\ttraining's binary_logloss: 0.286122\tvalid_1's binary_logloss: 0.309118\n",
      "[800]\ttraining's binary_logloss: 0.283426\tvalid_1's binary_logloss: 0.309\n",
      "Early stopping, best iteration is:\n",
      "[785]\ttraining's binary_logloss: 0.283804\tvalid_1's binary_logloss: 0.308973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308550:  75%|#######5  | 15/20 [23:36<07:50, 94.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.318889\tvalid_1's binary_logloss: 0.321769\n",
      "[200]\ttraining's binary_logloss: 0.31583\tvalid_1's binary_logloss: 0.318994\n",
      "[300]\ttraining's binary_logloss: 0.314055\tvalid_1's binary_logloss: 0.317448\n",
      "[400]\ttraining's binary_logloss: 0.312791\tvalid_1's binary_logloss: 0.316371\n",
      "[500]\ttraining's binary_logloss: 0.311838\tvalid_1's binary_logloss: 0.315591\n",
      "[600]\ttraining's binary_logloss: 0.311038\tvalid_1's binary_logloss: 0.314926\n",
      "[700]\ttraining's binary_logloss: 0.310367\tvalid_1's binary_logloss: 0.314473\n",
      "[800]\ttraining's binary_logloss: 0.309785\tvalid_1's binary_logloss: 0.314022\n",
      "[900]\ttraining's binary_logloss: 0.309257\tvalid_1's binary_logloss: 0.31365\n",
      "[1000]\ttraining's binary_logloss: 0.308576\tvalid_1's binary_logloss: 0.313097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.308576\tvalid_1's binary_logloss: 0.313097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308550:  80%|########  | 16/20 [24:23<05:19, 79.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.302762\tvalid_1's binary_logloss: 0.310932\n",
      "[200]\ttraining's binary_logloss: 0.296375\tvalid_1's binary_logloss: 0.309694\n",
      "[300]\ttraining's binary_logloss: 0.29097\tvalid_1's binary_logloss: 0.30923\n",
      "[400]\ttraining's binary_logloss: 0.286067\tvalid_1's binary_logloss: 0.30913\n",
      "[500]\ttraining's binary_logloss: 0.281475\tvalid_1's binary_logloss: 0.309023\n",
      "[600]\ttraining's binary_logloss: 0.276955\tvalid_1's binary_logloss: 0.308872\n",
      "[700]\ttraining's binary_logloss: 0.27259\tvalid_1's binary_logloss: 0.308847\n",
      "Early stopping, best iteration is:\n",
      "[688]\ttraining's binary_logloss: 0.27312\tvalid_1's binary_logloss: 0.308836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308550:  85%|########5 | 17/20 [25:05<03:26, 68.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.290367\tvalid_1's binary_logloss: 0.309446\n",
      "[200]\ttraining's binary_logloss: 0.277245\tvalid_1's binary_logloss: 0.309208\n",
      "[300]\ttraining's binary_logloss: 0.265966\tvalid_1's binary_logloss: 0.309211\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttraining's binary_logloss: 0.27503\tvalid_1's binary_logloss: 0.30916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308550:  90%|######### | 18/20 [25:33<01:52, 56.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.309104\tvalid_1's binary_logloss: 0.313549\n",
      "[200]\ttraining's binary_logloss: 0.30552\tvalid_1's binary_logloss: 0.311752\n",
      "[300]\ttraining's binary_logloss: 0.302998\tvalid_1's binary_logloss: 0.310887\n",
      "[400]\ttraining's binary_logloss: 0.30071\tvalid_1's binary_logloss: 0.310317\n",
      "[500]\ttraining's binary_logloss: 0.298597\tvalid_1's binary_logloss: 0.309839\n",
      "[600]\ttraining's binary_logloss: 0.296588\tvalid_1's binary_logloss: 0.309577\n",
      "[700]\ttraining's binary_logloss: 0.294823\tvalid_1's binary_logloss: 0.309382\n",
      "[800]\ttraining's binary_logloss: 0.293036\tvalid_1's binary_logloss: 0.309178\n",
      "[900]\ttraining's binary_logloss: 0.291379\tvalid_1's binary_logloss: 0.309066\n",
      "[1000]\ttraining's binary_logloss: 0.289771\tvalid_1's binary_logloss: 0.308981\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.289771\tvalid_1's binary_logloss: 0.308981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308550:  95%|#########5| 19/20 [26:14<00:51, 51.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.303129\tvalid_1's binary_logloss: 0.310925\n",
      "[200]\ttraining's binary_logloss: 0.296931\tvalid_1's binary_logloss: 0.309818\n",
      "[300]\ttraining's binary_logloss: 0.291592\tvalid_1's binary_logloss: 0.309304\n",
      "[400]\ttraining's binary_logloss: 0.286956\tvalid_1's binary_logloss: 0.309142\n",
      "[500]\ttraining's binary_logloss: 0.282687\tvalid_1's binary_logloss: 0.309075\n",
      "[600]\ttraining's binary_logloss: 0.278479\tvalid_1's binary_logloss: 0.308952\n",
      "[700]\ttraining's binary_logloss: 0.274601\tvalid_1's binary_logloss: 0.308917\n",
      "Early stopping, best iteration is:\n",
      "[660]\ttraining's binary_logloss: 0.27607\tvalid_1's binary_logloss: 0.308848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.308550: 100%|##########| 20/20 [26:55<00:00, 80.79s/it]\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308550:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306789\tvalid_1's binary_logloss: 0.312344\n",
      "[200]\ttraining's binary_logloss: 0.302375\tvalid_1's binary_logloss: 0.310746\n",
      "[300]\ttraining's binary_logloss: 0.298846\tvalid_1's binary_logloss: 0.309967\n",
      "[400]\ttraining's binary_logloss: 0.295693\tvalid_1's binary_logloss: 0.309536\n",
      "[500]\ttraining's binary_logloss: 0.292741\tvalid_1's binary_logloss: 0.309163\n",
      "[600]\ttraining's binary_logloss: 0.289971\tvalid_1's binary_logloss: 0.308898\n",
      "[700]\ttraining's binary_logloss: 0.28726\tvalid_1's binary_logloss: 0.308782\n",
      "[800]\ttraining's binary_logloss: 0.284746\tvalid_1's binary_logloss: 0.308611\n",
      "[900]\ttraining's binary_logloss: 0.282222\tvalid_1's binary_logloss: 0.308502\n",
      "[1000]\ttraining's binary_logloss: 0.279829\tvalid_1's binary_logloss: 0.308544\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279829\tvalid_1's binary_logloss: 0.308544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544:  10%|#         | 1/10 [00:55<08:20, 55.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306899\tvalid_1's binary_logloss: 0.312572\n",
      "[200]\ttraining's binary_logloss: 0.302382\tvalid_1's binary_logloss: 0.311142\n",
      "[300]\ttraining's binary_logloss: 0.299084\tvalid_1's binary_logloss: 0.310568\n",
      "[400]\ttraining's binary_logloss: 0.296157\tvalid_1's binary_logloss: 0.310439\n",
      "[500]\ttraining's binary_logloss: 0.293464\tvalid_1's binary_logloss: 0.310317\n",
      "[600]\ttraining's binary_logloss: 0.290701\tvalid_1's binary_logloss: 0.310268\n",
      "[700]\ttraining's binary_logloss: 0.288131\tvalid_1's binary_logloss: 0.310212\n",
      "[800]\ttraining's binary_logloss: 0.285708\tvalid_1's binary_logloss: 0.310197\n",
      "[900]\ttraining's binary_logloss: 0.283328\tvalid_1's binary_logloss: 0.310231\n",
      "Early stopping, best iteration is:\n",
      "[867]\ttraining's binary_logloss: 0.284088\tvalid_1's binary_logloss: 0.31018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544:  20%|##        | 2/10 [01:53<07:30, 56.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306703\tvalid_1's binary_logloss: 0.312204\n",
      "[200]\ttraining's binary_logloss: 0.302622\tvalid_1's binary_logloss: 0.310995\n",
      "[300]\ttraining's binary_logloss: 0.299073\tvalid_1's binary_logloss: 0.310259\n",
      "[400]\ttraining's binary_logloss: 0.29582\tvalid_1's binary_logloss: 0.309807\n",
      "[500]\ttraining's binary_logloss: 0.292852\tvalid_1's binary_logloss: 0.309512\n",
      "[600]\ttraining's binary_logloss: 0.290058\tvalid_1's binary_logloss: 0.309269\n",
      "[700]\ttraining's binary_logloss: 0.287303\tvalid_1's binary_logloss: 0.30915\n",
      "[800]\ttraining's binary_logloss: 0.284746\tvalid_1's binary_logloss: 0.309131\n",
      "[900]\ttraining's binary_logloss: 0.282275\tvalid_1's binary_logloss: 0.309053\n",
      "[1000]\ttraining's binary_logloss: 0.279855\tvalid_1's binary_logloss: 0.308972\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279855\tvalid_1's binary_logloss: 0.308972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544:  30%|###       | 3/10 [04:31<10:07, 86.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306806\tvalid_1's binary_logloss: 0.312394\n",
      "[200]\ttraining's binary_logloss: 0.302418\tvalid_1's binary_logloss: 0.310908\n",
      "[300]\ttraining's binary_logloss: 0.298963\tvalid_1's binary_logloss: 0.310242\n",
      "[400]\ttraining's binary_logloss: 0.295683\tvalid_1's binary_logloss: 0.30979\n",
      "[500]\ttraining's binary_logloss: 0.29275\tvalid_1's binary_logloss: 0.309409\n",
      "[600]\ttraining's binary_logloss: 0.289888\tvalid_1's binary_logloss: 0.309156\n",
      "[700]\ttraining's binary_logloss: 0.287157\tvalid_1's binary_logloss: 0.308951\n",
      "[800]\ttraining's binary_logloss: 0.284595\tvalid_1's binary_logloss: 0.308885\n",
      "Early stopping, best iteration is:\n",
      "[750]\ttraining's binary_logloss: 0.285854\tvalid_1's binary_logloss: 0.308864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544:  40%|####      | 4/10 [06:51<10:15, 102.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.307046\tvalid_1's binary_logloss: 0.312628\n",
      "[200]\ttraining's binary_logloss: 0.302552\tvalid_1's binary_logloss: 0.311191\n",
      "[300]\ttraining's binary_logloss: 0.299214\tvalid_1's binary_logloss: 0.310684\n",
      "[400]\ttraining's binary_logloss: 0.296381\tvalid_1's binary_logloss: 0.310492\n",
      "[500]\ttraining's binary_logloss: 0.293554\tvalid_1's binary_logloss: 0.310211\n",
      "[600]\ttraining's binary_logloss: 0.290748\tvalid_1's binary_logloss: 0.310156\n",
      "[700]\ttraining's binary_logloss: 0.288205\tvalid_1's binary_logloss: 0.310097\n",
      "[800]\ttraining's binary_logloss: 0.285732\tvalid_1's binary_logloss: 0.310109\n",
      "Early stopping, best iteration is:\n",
      "[780]\ttraining's binary_logloss: 0.28624\tvalid_1's binary_logloss: 0.310031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544:  50%|#####     | 5/10 [08:16<08:08, 97.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306859\tvalid_1's binary_logloss: 0.312374\n",
      "[200]\ttraining's binary_logloss: 0.302268\tvalid_1's binary_logloss: 0.310662\n",
      "[300]\ttraining's binary_logloss: 0.298682\tvalid_1's binary_logloss: 0.30988\n",
      "[400]\ttraining's binary_logloss: 0.295512\tvalid_1's binary_logloss: 0.309468\n",
      "[500]\ttraining's binary_logloss: 0.292593\tvalid_1's binary_logloss: 0.309179\n",
      "[600]\ttraining's binary_logloss: 0.289869\tvalid_1's binary_logloss: 0.308997\n",
      "[700]\ttraining's binary_logloss: 0.287149\tvalid_1's binary_logloss: 0.308838\n",
      "[800]\ttraining's binary_logloss: 0.284582\tvalid_1's binary_logloss: 0.308762\n",
      "[900]\ttraining's binary_logloss: 0.282048\tvalid_1's binary_logloss: 0.308713\n",
      "[1000]\ttraining's binary_logloss: 0.279587\tvalid_1's binary_logloss: 0.308733\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279587\tvalid_1's binary_logloss: 0.308733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544:  60%|######    | 6/10 [10:05<06:43, 100.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306898\tvalid_1's binary_logloss: 0.312403\n",
      "[200]\ttraining's binary_logloss: 0.302358\tvalid_1's binary_logloss: 0.310926\n",
      "[300]\ttraining's binary_logloss: 0.299033\tvalid_1's binary_logloss: 0.310351\n",
      "[400]\ttraining's binary_logloss: 0.295868\tvalid_1's binary_logloss: 0.309942\n",
      "[500]\ttraining's binary_logloss: 0.29308\tvalid_1's binary_logloss: 0.309843\n",
      "[600]\ttraining's binary_logloss: 0.290446\tvalid_1's binary_logloss: 0.309594\n",
      "[700]\ttraining's binary_logloss: 0.287802\tvalid_1's binary_logloss: 0.309519\n",
      "Early stopping, best iteration is:\n",
      "[690]\ttraining's binary_logloss: 0.288038\tvalid_1's binary_logloss: 0.30949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544:  70%|#######   | 7/10 [11:29<04:47, 95.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306649\tvalid_1's binary_logloss: 0.312251\n",
      "[200]\ttraining's binary_logloss: 0.302301\tvalid_1's binary_logloss: 0.310852\n",
      "[300]\ttraining's binary_logloss: 0.298705\tvalid_1's binary_logloss: 0.310094\n",
      "[400]\ttraining's binary_logloss: 0.295514\tvalid_1's binary_logloss: 0.309686\n",
      "[500]\ttraining's binary_logloss: 0.292619\tvalid_1's binary_logloss: 0.309339\n",
      "[600]\ttraining's binary_logloss: 0.289888\tvalid_1's binary_logloss: 0.309197\n",
      "[700]\ttraining's binary_logloss: 0.287148\tvalid_1's binary_logloss: 0.308974\n",
      "[800]\ttraining's binary_logloss: 0.284644\tvalid_1's binary_logloss: 0.308942\n",
      "[900]\ttraining's binary_logloss: 0.282191\tvalid_1's binary_logloss: 0.308813\n",
      "[1000]\ttraining's binary_logloss: 0.279679\tvalid_1's binary_logloss: 0.308686\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279679\tvalid_1's binary_logloss: 0.308686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544:  80%|########  | 8/10 [13:31<03:27, 103.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306699\tvalid_1's binary_logloss: 0.312213\n",
      "[200]\ttraining's binary_logloss: 0.302544\tvalid_1's binary_logloss: 0.310985\n",
      "[300]\ttraining's binary_logloss: 0.299019\tvalid_1's binary_logloss: 0.310266\n",
      "[400]\ttraining's binary_logloss: 0.296092\tvalid_1's binary_logloss: 0.310047\n",
      "[500]\ttraining's binary_logloss: 0.2932\tvalid_1's binary_logloss: 0.309791\n",
      "[600]\ttraining's binary_logloss: 0.290431\tvalid_1's binary_logloss: 0.309524\n",
      "[700]\ttraining's binary_logloss: 0.287791\tvalid_1's binary_logloss: 0.309361\n",
      "[800]\ttraining's binary_logloss: 0.285372\tvalid_1's binary_logloss: 0.30931\n",
      "[900]\ttraining's binary_logloss: 0.282891\tvalid_1's binary_logloss: 0.30925\n",
      "[1000]\ttraining's binary_logloss: 0.280528\tvalid_1's binary_logloss: 0.309236\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.280528\tvalid_1's binary_logloss: 0.309236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544:  90%|######### | 9/10 [16:16<02:02, 122.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.30686\tvalid_1's binary_logloss: 0.3125\n",
      "[200]\ttraining's binary_logloss: 0.302402\tvalid_1's binary_logloss: 0.310971\n",
      "[300]\ttraining's binary_logloss: 0.298919\tvalid_1's binary_logloss: 0.310334\n",
      "[400]\ttraining's binary_logloss: 0.295894\tvalid_1's binary_logloss: 0.310002\n",
      "[500]\ttraining's binary_logloss: 0.292952\tvalid_1's binary_logloss: 0.309826\n",
      "[600]\ttraining's binary_logloss: 0.290233\tvalid_1's binary_logloss: 0.309691\n",
      "[700]\ttraining's binary_logloss: 0.287688\tvalid_1's binary_logloss: 0.309671\n",
      "[800]\ttraining's binary_logloss: 0.285172\tvalid_1's binary_logloss: 0.309666\n",
      "Early stopping, best iteration is:\n",
      "[733]\ttraining's binary_logloss: 0.28687\tvalid_1's binary_logloss: 0.309587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.308544: 100%|##########| 10/10 [16:59<00:00, 101.91s/it]\n",
      "tune_feature_fraction, val_score: 0.308544:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.307042\tvalid_1's binary_logloss: 0.312415\n",
      "[200]\ttraining's binary_logloss: 0.302708\tvalid_1's binary_logloss: 0.310897\n",
      "[300]\ttraining's binary_logloss: 0.299332\tvalid_1's binary_logloss: 0.310161\n",
      "[400]\ttraining's binary_logloss: 0.296142\tvalid_1's binary_logloss: 0.309687\n",
      "[500]\ttraining's binary_logloss: 0.293246\tvalid_1's binary_logloss: 0.309286\n",
      "[600]\ttraining's binary_logloss: 0.290494\tvalid_1's binary_logloss: 0.308997\n",
      "[700]\ttraining's binary_logloss: 0.287818\tvalid_1's binary_logloss: 0.308771\n",
      "[800]\ttraining's binary_logloss: 0.285149\tvalid_1's binary_logloss: 0.308648\n",
      "[900]\ttraining's binary_logloss: 0.282596\tvalid_1's binary_logloss: 0.308474\n",
      "Early stopping, best iteration is:\n",
      "[874]\ttraining's binary_logloss: 0.283253\tvalid_1's binary_logloss: 0.308441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308441:  17%|#6        | 1/6 [01:00<05:00, 60.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306837\tvalid_1's binary_logloss: 0.312247\n",
      "[200]\ttraining's binary_logloss: 0.302326\tvalid_1's binary_logloss: 0.31061\n",
      "[300]\ttraining's binary_logloss: 0.29891\tvalid_1's binary_logloss: 0.309984\n",
      "[400]\ttraining's binary_logloss: 0.295792\tvalid_1's binary_logloss: 0.309558\n",
      "[500]\ttraining's binary_logloss: 0.292884\tvalid_1's binary_logloss: 0.309173\n",
      "[600]\ttraining's binary_logloss: 0.290046\tvalid_1's binary_logloss: 0.308894\n",
      "[700]\ttraining's binary_logloss: 0.287323\tvalid_1's binary_logloss: 0.308701\n",
      "[800]\ttraining's binary_logloss: 0.284764\tvalid_1's binary_logloss: 0.308512\n",
      "[900]\ttraining's binary_logloss: 0.282251\tvalid_1's binary_logloss: 0.308461\n",
      "[1000]\ttraining's binary_logloss: 0.279979\tvalid_1's binary_logloss: 0.308437\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279979\tvalid_1's binary_logloss: 0.308437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308437:  33%|###3      | 2/6 [02:02<04:02, 60.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306837\tvalid_1's binary_logloss: 0.312247\n",
      "[200]\ttraining's binary_logloss: 0.302326\tvalid_1's binary_logloss: 0.31061\n",
      "[300]\ttraining's binary_logloss: 0.29891\tvalid_1's binary_logloss: 0.309984\n",
      "[400]\ttraining's binary_logloss: 0.295792\tvalid_1's binary_logloss: 0.309558\n",
      "[500]\ttraining's binary_logloss: 0.292884\tvalid_1's binary_logloss: 0.309173\n",
      "[600]\ttraining's binary_logloss: 0.290046\tvalid_1's binary_logloss: 0.308894\n",
      "[700]\ttraining's binary_logloss: 0.287323\tvalid_1's binary_logloss: 0.308701\n",
      "[800]\ttraining's binary_logloss: 0.284764\tvalid_1's binary_logloss: 0.308512\n",
      "[900]\ttraining's binary_logloss: 0.282251\tvalid_1's binary_logloss: 0.308461\n",
      "[1000]\ttraining's binary_logloss: 0.279979\tvalid_1's binary_logloss: 0.308437\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279979\tvalid_1's binary_logloss: 0.308437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308437:  50%|#####     | 3/6 [03:36<03:32, 70.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306789\tvalid_1's binary_logloss: 0.312344\n",
      "[200]\ttraining's binary_logloss: 0.302375\tvalid_1's binary_logloss: 0.310746\n",
      "[300]\ttraining's binary_logloss: 0.298846\tvalid_1's binary_logloss: 0.309967\n",
      "[400]\ttraining's binary_logloss: 0.295693\tvalid_1's binary_logloss: 0.309536\n",
      "[500]\ttraining's binary_logloss: 0.292741\tvalid_1's binary_logloss: 0.309163\n",
      "[600]\ttraining's binary_logloss: 0.289971\tvalid_1's binary_logloss: 0.308898\n",
      "[700]\ttraining's binary_logloss: 0.28726\tvalid_1's binary_logloss: 0.308782\n",
      "[800]\ttraining's binary_logloss: 0.284746\tvalid_1's binary_logloss: 0.308611\n",
      "[900]\ttraining's binary_logloss: 0.282222\tvalid_1's binary_logloss: 0.308502\n",
      "[1000]\ttraining's binary_logloss: 0.279829\tvalid_1's binary_logloss: 0.308544\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279829\tvalid_1's binary_logloss: 0.308544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308437:  67%|######6   | 4/6 [05:39<02:52, 86.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306611\tvalid_1's binary_logloss: 0.312141\n",
      "[200]\ttraining's binary_logloss: 0.302237\tvalid_1's binary_logloss: 0.310683\n",
      "[300]\ttraining's binary_logloss: 0.298664\tvalid_1's binary_logloss: 0.309983\n",
      "[400]\ttraining's binary_logloss: 0.29544\tvalid_1's binary_logloss: 0.309666\n",
      "[500]\ttraining's binary_logloss: 0.29238\tvalid_1's binary_logloss: 0.309376\n",
      "[600]\ttraining's binary_logloss: 0.289495\tvalid_1's binary_logloss: 0.309111\n",
      "[700]\ttraining's binary_logloss: 0.286775\tvalid_1's binary_logloss: 0.309046\n",
      "[800]\ttraining's binary_logloss: 0.284092\tvalid_1's binary_logloss: 0.308977\n",
      "[900]\ttraining's binary_logloss: 0.281529\tvalid_1's binary_logloss: 0.308849\n",
      "[1000]\ttraining's binary_logloss: 0.279116\tvalid_1's binary_logloss: 0.308797\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279116\tvalid_1's binary_logloss: 0.308797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308437:  83%|########3 | 5/6 [07:57<01:41, 101.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306574\tvalid_1's binary_logloss: 0.312263\n",
      "[200]\ttraining's binary_logloss: 0.30221\tvalid_1's binary_logloss: 0.310835\n",
      "[300]\ttraining's binary_logloss: 0.298506\tvalid_1's binary_logloss: 0.310023\n",
      "[400]\ttraining's binary_logloss: 0.295283\tvalid_1's binary_logloss: 0.309673\n",
      "[500]\ttraining's binary_logloss: 0.292215\tvalid_1's binary_logloss: 0.309293\n",
      "[600]\ttraining's binary_logloss: 0.289385\tvalid_1's binary_logloss: 0.309092\n",
      "[700]\ttraining's binary_logloss: 0.286618\tvalid_1's binary_logloss: 0.308942\n",
      "[800]\ttraining's binary_logloss: 0.284051\tvalid_1's binary_logloss: 0.308804\n",
      "[900]\ttraining's binary_logloss: 0.281383\tvalid_1's binary_logloss: 0.308733\n",
      "Early stopping, best iteration is:\n",
      "[870]\ttraining's binary_logloss: 0.28219\tvalid_1's binary_logloss: 0.3087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.308437: 100%|##########| 6/6 [10:13<00:00, 102.25s/it]\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.308437:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306837\tvalid_1's binary_logloss: 0.312247\n",
      "[200]\ttraining's binary_logloss: 0.302326\tvalid_1's binary_logloss: 0.31061\n",
      "[300]\ttraining's binary_logloss: 0.29891\tvalid_1's binary_logloss: 0.309984\n",
      "[400]\ttraining's binary_logloss: 0.295792\tvalid_1's binary_logloss: 0.309558\n",
      "[500]\ttraining's binary_logloss: 0.292884\tvalid_1's binary_logloss: 0.309173\n",
      "[600]\ttraining's binary_logloss: 0.290046\tvalid_1's binary_logloss: 0.308894\n",
      "[700]\ttraining's binary_logloss: 0.287323\tvalid_1's binary_logloss: 0.308701\n",
      "[800]\ttraining's binary_logloss: 0.284764\tvalid_1's binary_logloss: 0.308512\n",
      "[900]\ttraining's binary_logloss: 0.282252\tvalid_1's binary_logloss: 0.308461\n",
      "[1000]\ttraining's binary_logloss: 0.279982\tvalid_1's binary_logloss: 0.308423\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.279982\tvalid_1's binary_logloss: 0.308423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.308423:   5%|5         | 1/20 [02:17<43:36, 137.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.306893\tvalid_1's binary_logloss: 0.312326\n",
      "[200]\ttraining's binary_logloss: 0.302626\tvalid_1's binary_logloss: 0.310714\n",
      "[300]\ttraining's binary_logloss: 0.299372\tvalid_1's binary_logloss: 0.309964\n",
      "[400]\ttraining's binary_logloss: 0.296336\tvalid_1's binary_logloss: 0.309462\n",
      "[500]\ttraining's binary_logloss: 0.293546\tvalid_1's binary_logloss: 0.309169\n",
      "[600]\ttraining's binary_logloss: 0.290843\tvalid_1's binary_logloss: 0.308881\n",
      "[700]\ttraining's binary_logloss: 0.288272\tvalid_1's binary_logloss: 0.308772\n",
      "[800]\ttraining's binary_logloss: 0.285837\tvalid_1's binary_logloss: 0.308597\n",
      "[900]\ttraining's binary_logloss: 0.283532\tvalid_1's binary_logloss: 0.308528\n"
     ]
    }
   ],
   "source": [
    "params_shared = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": 0,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}\n",
    "tgt2params = {k:params_shared for k in tgts}\n",
    "\n",
    "tgt2bst={}\n",
    "tgt2best_params={}\n",
    "tgt2tuning_history={}\n",
    "tgt2ytr={}\n",
    "tgt2yvl={}\n",
    "tgt2prdtr={}\n",
    "tgt2prdvl={}\n",
    "tgt2pops={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt, '*'*80)\n",
    "    do_tgt(tgt)\n",
    "    \n",
    "pickle.dump(tgt2bst, open(f\"{p_out}/tgt2bst.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tr vl"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for tgt in tgt2evalres:\n",
    "    evalres=tgt2evalres[tgt]\n",
    "    plt.plot(evalres['train']['logloss'][10:])\n",
    "    plt.plot(evalres['eval']['logloss'][10:])\n",
    "    plt.title(f\"{tgt} logloss {len(evalres['train']['logloss'])} rounds\")\n",
    "    plt.show()\n",
    "    plt.plot(evalres['train']['aucpr'])\n",
    "    plt.plot(evalres['eval']['aucpr'])\n",
    "    plt.title(f\"{tgt} aucpr {len(evalres['train']['aucpr'])} rounds\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def show_feat_importance(tgt):\n",
    "    bst=tgt2bst[tgt]\n",
    "    ax = xgb.plot_importance(bst, height=0.8, max_num_features=9)\n",
    "    ax.grid(False, axis=\"y\")\n",
    "    ax.set_title(f'{tgt} Estimated feature importance')\n",
    "    plt.show()\n",
    "    feat2importance=bst.get_fscore()\n",
    "    print(tgt)\n",
    "    display(pd.DataFrame([feat2importance.keys(), \n",
    "                          feat2importance.values()]).T.sort_values(1, ascending=False))\n",
    "\n",
    "for tgt in tgt2bst:\n",
    "    show_feat_importance(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2auc_tr={}\n",
    "tgt2rce_tr={}\n",
    "tgt2auc_vl={}\n",
    "tgt2rce_vl={}\n",
    "for tgt in tgt2bst:\n",
    "    print(tgt)\n",
    "    prdtr_i, prdvl_i = tgt2prdtr[tgt], tgt2prdvl[tgt]\n",
    "    ytr_i, yvl_i = tgt2ytr[tgt], tgt2yvl[tgt]\n",
    "    scr_auc_tr=compute_prauc(prdtr_i, ytr_i)\n",
    "    scr_rce_tr=compute_rce(prdtr_i, ytr_i)\n",
    "    scr_auc_vl=compute_prauc(prdvl_i, yvl_i)\n",
    "    scr_rce_vl=compute_rce(prdvl_i, yvl_i)\n",
    "\n",
    "    tgt2auc_tr[tgt]=scr_auc_tr\n",
    "    tgt2rce_tr[tgt]=scr_rce_tr\n",
    "    tgt2auc_vl[tgt]=scr_auc_vl\n",
    "    tgt2rce_vl[tgt]=scr_rce_vl\n",
    "    \n",
    "    print('tr prauc:', f'{scr_auc_tr:.4f}','tr rce:', f'{scr_rce_tr:.4f}', )\n",
    "    print('vl prauc:', f'{scr_auc_vl:.4f}','vl rce:', f'{scr_rce_vl:.4f}', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsttr=[]\n",
    "lstvl=[]\n",
    "for tgt in ['Retweet','Reply','Like','RTwCmnt',]:\n",
    "    if tgt not in tgt2bst: continue\n",
    "    lsttr+=[(f'PRAUC {tgt}',tgt2auc_tr[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_tr[tgt])]\n",
    "    lstvl+=[(f'PRAUC {tgt}',tgt2auc_vl[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_vl[tgt])]\n",
    "\n",
    "dfscrtr=pd.DataFrame(lsttr)\n",
    "dfscrtr.columns=['metric','scr']\n",
    "dfscrvl=pd.DataFrame(lstvl)\n",
    "dfscrvl.columns=['metric','scr']\n",
    "dfscr = pd.merge(dfscrtr, dfscrvl, on='metric', suffixes=('tr','vl'))\n",
    "dfscr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt=tgts[1]\n",
    "# tgtcol=tgt2col[tgt]\n",
    "# bst=tgt2bst[tgt]\n",
    "\n",
    "# dvalid=xgb.DMatrix(dfvalid[cols_feat], label=dfvalid[tgtcol], feature_names=cols_feat)\n",
    "\n",
    "# prdvalid = bst.predict(dvalid, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "# pops=tgt2pops[tgt]\n",
    "\n",
    "# prdvalid[:10]\n",
    "# # array([0.11734424, 0.09971393, 0.05619054, 0.03059793, 0.07979691,\n",
    "# #        0.01358252, 0.05293725, 0.27954698, 0.05738379, 0.01741553],\n",
    "# #       dtype=float32)\n",
    "\n",
    "\n",
    "# pops\n",
    "# # {'train_pop': 4000000,\n",
    "# #  'target_pop': 109752,\n",
    "# #  'sampled_train_pop': 1000000,\n",
    "# #  'sampled_target_pop': 109752}\n",
    "\n",
    "# prdvalid_calib = calibration(prdvalid, **pops)\n",
    "\n",
    "# prdvalid_calib[:10]\n",
    "# # array([0.02952491, 0.02471944, 0.01344113, 0.00717127, 0.01945818,\n",
    "# #        0.00314114, 0.0126298 , 0.08155248, 0.01373977, 0.00403964],\n",
    "# #       dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_post_valid(tgt):\n",
    "    tgtcol=tgt2col[tgt]\n",
    "    bst=tgt2bst[tgt]\n",
    "    pops=tgt2pops[tgt]\n",
    "    prdvalid = bst.predict(dfvalid[cols_feat],num_iteration=bst.best_iteration)\n",
    "    prdvalid_calib = calibration(prdvalid, **pops)\n",
    "    return prdvalid,prdvalid_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2yvalid={tgt:dfvalid[tgt2col[tgt]] for tgt in tgts}\n",
    "tgt2prdvalid={}\n",
    "tgt2prdvalid_calib={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt)\n",
    "    tgt2prdvalid[tgt],tgt2prdvalid_calib[tgt]=do_post_valid(tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2auc_valid={}\n",
    "tgt2rce_valid={}\n",
    "tgt2auc_valid_calib={}\n",
    "tgt2rce_valid_calib={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt)\n",
    "    prdvalid, prdvalid_calib = tgt2prdvalid[tgt], tgt2prdvalid_calib[tgt]\n",
    "    yvalid = tgt2yvalid[tgt]\n",
    "    scr_auc_valid=compute_prauc(prdvalid, yvalid)\n",
    "    scr_rce_valid=compute_rce(prdvalid, yvalid)\n",
    "    scr_auc_valid_calib=compute_prauc(prdvalid_calib, yvalid)\n",
    "    scr_rce_valid_calib=compute_rce(prdvalid_calib, yvalid)\n",
    "\n",
    "    tgt2auc_valid[tgt]=scr_auc_valid\n",
    "    tgt2rce_valid[tgt]=scr_rce_valid\n",
    "    tgt2auc_valid_calib[tgt]=scr_auc_valid_calib\n",
    "    tgt2rce_valid_calib[tgt]=scr_rce_valid_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tgt in tgts:\n",
    "    print(tgt)\n",
    "    print('tr          prauc:', f'{tgt2auc_tr[tgt]:.4f}','tr rce:', f'{tgt2rce_tr[tgt]:.4f}', )\n",
    "    print('vl          prauc:', f'{tgt2auc_vl[tgt]:.4f}','tr rce:', f'{tgt2rce_vl[tgt]:.4f}', )\n",
    "    print('valid       prauc:', f'{tgt2auc_valid[tgt]:.4f}','tr rce:', f'{tgt2rce_valid[tgt]:.4f}', )\n",
    "    print('valid_calib prauc:', f'{tgt2auc_valid_calib[tgt]:.4f}','tr rce:', f'{tgt2rce_valid_calib[tgt]:.4f}', )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsttr=[]\n",
    "lstvl=[]\n",
    "lstvalid=[]\n",
    "lstvalid_calib=[]\n",
    "for tgt in ['Retweet','Reply','Like','RTwCmnt',]:\n",
    "    if tgt not in tgt2bst: continue\n",
    "    lsttr+=[(f'PRAUC {tgt}',tgt2auc_tr[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_tr[tgt])]\n",
    "    lstvl+=[(f'PRAUC {tgt}',tgt2auc_vl[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_vl[tgt])]\n",
    "    lstvalid+=[(f'PRAUC {tgt}',tgt2auc_valid[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_valid[tgt])]\n",
    "    lstvalid_calib+=[(f'PRAUC {tgt}',tgt2auc_valid_calib[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_valid_calib[tgt])]\n",
    "\n",
    "dfscrtr=pd.DataFrame(lsttr)\n",
    "dfscrtr.columns=['metric','scr']\n",
    "dfscrvl=pd.DataFrame(lstvl)\n",
    "dfscrvl.columns=['metric','scr']\n",
    "dfscrvalid=pd.DataFrame(lstvalid)\n",
    "dfscrvalid.columns=['metric','scr']\n",
    "dfscrvalid_calib=pd.DataFrame(lstvalid_calib)\n",
    "dfscrvalid_calib.columns=['metric','scr']\n",
    "\n",
    "dfscr = reduce(lambda df1,df2: pd.merge(df1,df2,on='metric'), \n",
    "            [dfscrtr,dfscrvl,dfscrvalid,dfscrvalid_calib])\n",
    "\n",
    "dfscr.columns=['scr','tr','vl','valid','valid_calib']\n",
    "dfscr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tgt2bst, open(f\"{p_out}/tgt2bst.p\", \"wb\"))\n",
    "pickle.dump(tgt2best_params, open(f\"{p_out}/tgt2best_params.p\", \"wb\"))\n",
    "pickle.dump(tgt2tuning_history, open(f\"{p_out}/tgt2tuning_history.p\", \"wb\"))\n",
    "pickle.dump(tgt2ytr, open(f\"{p_out}/tgt2ytr.p\", \"wb\"))\n",
    "pickle.dump(tgt2yvl, open(f\"{p_out}/tgt2yvl.p\", \"wb\"))\n",
    "pickle.dump(tgt2prdtr, open(f\"{p_out}/tgt2prdtr.p\", \"wb\"))\n",
    "pickle.dump(tgt2prdvl, open(f\"{p_out}/tgt2prdvl.p\", \"wb\"))\n",
    "pickle.dump(tgt2pops, open(f\"{p_out}/tgt2pops.p\", \"wb\"))\n",
    "pickle.dump(tgt2prdvalid, open(f\"{p_out}/tgt2prdvalid.p\", \"wb\"))\n",
    "pickle.dump(tgt2prdvalid_calib, open(f\"{p_out}/tgt2prdvalid_calib.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls -lhS $p_in | grep val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst=pd.read_csv(\n",
    "    f'{p_in}/val_{valtmstmp}.tsv',\n",
    "#     f'{p_in}/val_259A6F6DFD672CB1F883CBEC01B99F2D_1584405047.tsv',\n",
    "    sep='\\x01', header=None, names=cols_val,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst = prp_df(dftst, istrn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tgt2prdtst={}\n",
    "for tgt in tgts:\n",
    "    print(dtnow(), tgt)\n",
    "    bst = tgt2bst[tgt]\n",
    "    pops=tgt2pops[tgt]\n",
    "    prdtst = bst.predict(dftst[cols_feat], num_iteration=bst.best_iteration)\n",
    "    prdtst_calib = calibration(prdtst, **pops)\n",
    "    tgt2prdtst[tgt] = prdtst_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub_ids = dftst[['twtid','u2id',]]\n",
    "\n",
    "tgt2dfsub = {}\n",
    "for tgt,prdtst in tgt2prdtst.items():\n",
    "    dfsub = dfsub_ids.copy()\n",
    "    dfsub['scr'] = prdtst\n",
    "    tgt2dfsub[tgt]=dfsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i,tgt in enumerate(['Retweet','Reply','RTwCmnt','Like',]):\n",
    "    dfsub = tgt2dfsub[tgt]\n",
    "    print(dtnow(), tgt)\n",
    "    dfsub.to_csv(f'{p_out}/{i}_{tgt}__{valtmstmp}__{PRFX}.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
