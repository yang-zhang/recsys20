{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://localhost:8081/notebooks/git/recsys20/working/0324_6_3_lgb_feat_engr-1e7.ipynb\n",
    "- http://localhost:8081/notebooks/git/recsys20/working/mdl0404_1__xgb_mean_encode.ipynb\n",
    "- http://localhost:8081/notebooks/git/recsys20/working/eda_0404_1.ipynb#v.s.-target\n",
    "- https://www.kaggle.com/discdiver/category-encoders-examples\n",
    "- https://www.kaggle.com/snakayama/lightgbm-using-optuna-optuna-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_total 148,075,238, test_total 14,000,000\n",
      "['2020-03-17 02:32:24', '2020-04-06 00:35:47']\n",
      "['2020-02-06 00:00:00', '2020-02-12 23:59:59']\n",
      "['2020-02-13 00:00:00', '2020-02-19 23:59:59']\n"
     ]
    }
   ],
   "source": [
    "TGT='Reply'\n",
    "PRFX='Reply0412_1'\n",
    "\n",
    "trntmstmp=1584412344\n",
    "tsttmstmp=1586133347\n",
    "\n",
    "tm_trn_min,tm_trn_max=(1580947200, 1581551999)\n",
    "tm_tst_min,tm_tst_max=(1581552000, 1582156799)\n",
    "\n",
    "SEED=101\n",
    "\n",
    "valsz = int(5e5)#int(1e5)\n",
    "trnsz = int(5e5)#int(5e5)\n",
    "\n",
    "train_total=148075238\n",
    "test_total=int(1.4e7)\n",
    "print(f'train_total {train_total:,}, test_total {test_total:,}')\n",
    "\n",
    "\n",
    "import datetime\n",
    "def showtm(tm): return datetime.datetime.fromtimestamp(tm).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print([showtm(tm) for tm in (trntmstmp, tsttmstmp)])\n",
    "print([showtm(tm) for tm in (tm_trn_min,tm_trn_max)])\n",
    "print([showtm(tm) for tm in (tm_tst_min,tm_tst_max)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39885199.459459454"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_total-valsz)/3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCOL reply\n",
      "{'Retweet': 'retwt', 'Reply': 'reply', 'Like': 'like', 'RTwCmnt': 'retwt_cmmnt'}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter,defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "import pickle\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "import gc\n",
    "\n",
    "import optuna\n",
    "# optuna.logging.CRITICAL, optuna.logging.FATAL\n",
    "# optuna.logging.ERROR\n",
    "# optuna.logging.WARNING, optuna.logging.WARN\n",
    "# optuna.logging.INFO\n",
    "# optuna.logging.DEBUG\n",
    "# optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "import optuna.integration.lightgbm as lgb\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "import datetime\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def iou(s1,s2):\n",
    "    return len(s1&s2) / len(s1|s2)\n",
    "\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "p_out=f'{HOME}/output/{PRFX}'\n",
    "Path(p_out).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, log_loss\n",
    "\n",
    "def compute_prauc(pred, gt):\n",
    "    prec, recall, thresh = precision_recall_curve(gt, pred)\n",
    "    prauc = auc(recall, prec)\n",
    "    return prauc\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "    positive = len([x for x in gt if x == 1])\n",
    "    ctr = positive/float(len(gt))\n",
    "    return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "# https://towardsdatascience.com/how-to-calibrate-undersampled-model-scores-8f3319c1ea5b\n",
    "# How to use the function?\n",
    "# Letâ€™s say your goal is to generate a model that shows the credit default probabilities and your original \n",
    "# training data has 50,000 rows with only 500 of them labeled as target class. When you sample your non-target \n",
    "# instances randomly and reduce the total row count to 10,000, while conserving 500 target rows, our calibration\n",
    "# function becomes:\n",
    "# calibration(model_results, 50000, 500, 10000, 500)\n",
    "# Here model_results is your model probability output array. After you train your model and put the results in it, your function is ready to use. \n",
    "def calibration(data, train_pop, target_pop, sampled_train_pop, sampled_target_pop):\n",
    "    calibrated_data = ((data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop)) /\n",
    "    (((1 - data) * (1 - target_pop / train_pop) / (1 - sampled_target_pop / sampled_train_pop)) +\n",
    "     (data * (target_pop / train_pop) / (sampled_target_pop / sampled_train_pop))))\n",
    "    return calibrated_data\n",
    "\n",
    "\n",
    "cols=['toks','hshtgs','twtid','media','links','domns','twttyp','lang','tm','u1id','u1_fllwer_cnt','u1_fllwing_cnt','u1_vrfed','u1_create_tm','u2id','u2_fllwer_cnt','u2_fllwng_cnt','u2_vrfed','u2_create_tm','u1_fllw_u2','reply_tm','retwt_tm','retwt_cmmnt_tm','like_tm',]\n",
    "\n",
    "cols_val = cols[:-4]\n",
    "cols_tgt_tmstmp=[ 'retwt_tm', 'reply_tm', 'like_tm', 'retwt_cmmnt_tm',]\n",
    "cols_tgt=[o.split('_tm')[0] for o in cols_tgt_tmstmp]\n",
    "tgts             = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "assert cols_tgt == ['retwt',  'reply','like','retwt_cmmnt',]\n",
    "tgt2col = dict(zip(tgts, cols_tgt))\n",
    "TCOL=tgt2col[TGT]\n",
    "print('TCOL', TCOL)\n",
    "print(tgt2col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prp_tgt(df):\n",
    "    df[cols_tgt]=df[cols_tgt_tmstmp].notna()\n",
    "    df.drop(columns=cols_tgt_tmstmp, inplace=True)\n",
    "    display(df[cols_tgt].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "retwt          0.112638\n",
       "reply          0.027980\n",
       "like           0.439010\n",
       "retwt_cmmnt    0.007676\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.9 s, sys: 175 ms, total: 4.07 s\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfval = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,nrows=valsz)\n",
    "print(dfval.shape)\n",
    "prp_tgt(dfval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maybe oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,nrows=5)\n",
    "# dfval = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,nrows=2)\n",
    "# dftrn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,skiprows=2,nrows=3)\n",
    "# display(df.twtid)\n",
    "# display(dfval.twtid)\n",
    "# display(dftrn.twtid)\n",
    "\n",
    "# 0    D4D1EBDE74F74C5DA529959AF979625C\n",
    "# 1    BFB529DAB6D384EB83E899A72AB3830D\n",
    "# 2    519078C7834E9642508F72A6C2D0F3B7\n",
    "# 3    52AAE9E33EFAC8C478C57B31A9E31ED1\n",
    "# 4    89C1298C55EB3D68E2784F0BFB69E6F8\n",
    "# Name: twtid, dtype: object\n",
    "# 0    D4D1EBDE74F74C5DA529959AF979625C\n",
    "# 1    BFB529DAB6D384EB83E899A72AB3830D\n",
    "# Name: twtid, dtype: object\n",
    "# 0    519078C7834E9642508F72A6C2D0F3B7\n",
    "# 1    52AAE9E33EFAC8C478C57B31A9E31ED1\n",
    "# 2    89C1298C55EB3D68E2784F0BFB69E6F8\n",
    "# Name: twtid, dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1850000, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "retwt          0.112795\n",
       "reply          0.027393\n",
       "like           0.439040\n",
       "retwt_cmmnt    0.007702\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 1.54 s, total: 15.3 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if TGT in ('Retweet','Like'): trnpop=trnsz\n",
    "if TGT=='Reply': trnpop=trnsz*3.7\n",
    "if TGT=='RTwCmnt': trnpop=trnsz*11.5\n",
    "assert trnpop<train_total\n",
    "\n",
    "dftrn = pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,names=cols,\n",
    "                     skiprows=valsz, nrows=trnpop)\n",
    "print(dftrn.shape)\n",
    "prp_tgt(dftrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 24) 0.101354\n",
      "1850000 50677 500000 50677\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toks</th>\n",
       "      <th>hshtgs</th>\n",
       "      <th>twtid</th>\n",
       "      <th>media</th>\n",
       "      <th>links</th>\n",
       "      <th>domns</th>\n",
       "      <th>twttyp</th>\n",
       "      <th>lang</th>\n",
       "      <th>tm</th>\n",
       "      <th>u1id</th>\n",
       "      <th>u1_fllwer_cnt</th>\n",
       "      <th>u1_fllwing_cnt</th>\n",
       "      <th>u1_vrfed</th>\n",
       "      <th>u1_create_tm</th>\n",
       "      <th>u2id</th>\n",
       "      <th>u2_fllwer_cnt</th>\n",
       "      <th>u2_fllwng_cnt</th>\n",
       "      <th>u2_vrfed</th>\n",
       "      <th>u2_create_tm</th>\n",
       "      <th>u1_fllw_u2</th>\n",
       "      <th>retwt</th>\n",
       "      <th>reply</th>\n",
       "      <th>like</th>\n",
       "      <th>retwt_cmmnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101\\t137\\t48201\\t10133\\t44026\\t10884\\t11305\\t9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24669C0DADEA57A75F6BE24CAC0ACCB9</td>\n",
       "      <td>Photo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TopLevel</td>\n",
       "      <td>22C448FF81263D4BAF2A176145EE9EAD</td>\n",
       "      <td>1580948734</td>\n",
       "      <td>A6E0653718DB85566D3E6D1E2989AC6D</td>\n",
       "      <td>145</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>1522591408</td>\n",
       "      <td>06E9B9E30FB6A7F37CA6B42264C30103</td>\n",
       "      <td>407</td>\n",
       "      <td>385</td>\n",
       "      <td>False</td>\n",
       "      <td>1274938010</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101\\t2341\\t7911\\t121\\t12236\\t7596\\t7431\\t12290...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E15A666B6A975581F5CE3F2286CDB408</td>\n",
       "      <td>Photo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TopLevel</td>\n",
       "      <td>22C448FF81263D4BAF2A176145EE9EAD</td>\n",
       "      <td>1581344753</td>\n",
       "      <td>74BD974C794C3C2D604E92F9402AB810</td>\n",
       "      <td>318</td>\n",
       "      <td>252</td>\n",
       "      <td>False</td>\n",
       "      <td>1464834037</td>\n",
       "      <td>06E9B9E30FB6A7F37CA6B42264C30103</td>\n",
       "      <td>407</td>\n",
       "      <td>385</td>\n",
       "      <td>False</td>\n",
       "      <td>1274938010</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>101\\t144\\t87051\\t10354\\t16874\\t196\\t10117\\t172...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D8334D0798821B6A99A9C7A4C9E4E3E1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8FBB6E6890E2ED0F608F83345CB5EA2F</td>\n",
       "      <td>FFA7BC68DEEFEE9FE34F150D60FEA189</td>\n",
       "      <td>TopLevel</td>\n",
       "      <td>D3164C7FBCF2565DDF915B1B3AEFB1DC</td>\n",
       "      <td>1581149159</td>\n",
       "      <td>4CA2E59BBCCB899954E82B01D61C8DF1</td>\n",
       "      <td>16974</td>\n",
       "      <td>612</td>\n",
       "      <td>False</td>\n",
       "      <td>1397475686</td>\n",
       "      <td>06E9CB2FE3EE244FC5D3E2A7E0B7A460</td>\n",
       "      <td>66</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>1498734232</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>101\\t11589\\t39520\\t18487\\t58136\\t10121\\t10911\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0C55DCB7494C90953ACE5E70A46B8AA9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TopLevel</td>\n",
       "      <td>06D61DCBBE938971E1EA0C38BD9B5446</td>\n",
       "      <td>1581470640</td>\n",
       "      <td>58867654CB709C6FBA4F332ED479EF1A</td>\n",
       "      <td>418</td>\n",
       "      <td>554</td>\n",
       "      <td>False</td>\n",
       "      <td>1354395470</td>\n",
       "      <td>06E9F8C1FB619A5AE34B3BE57632DB16</td>\n",
       "      <td>178</td>\n",
       "      <td>339</td>\n",
       "      <td>False</td>\n",
       "      <td>1538938782</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>101\\t65000\\t112\\t188\\t19556\\t12172\\t10133\\t218...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3058691BBE196B9A3702A8E7584944E9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TopLevel</td>\n",
       "      <td>D3164C7FBCF2565DDF915B1B3AEFB1DC</td>\n",
       "      <td>1580980182</td>\n",
       "      <td>B31DCBBAE66B1E22B1531F77538E88E7</td>\n",
       "      <td>19</td>\n",
       "      <td>440</td>\n",
       "      <td>False</td>\n",
       "      <td>1476507467</td>\n",
       "      <td>06EADF03A34F162DE8051C27C439F6BB</td>\n",
       "      <td>172</td>\n",
       "      <td>167</td>\n",
       "      <td>False</td>\n",
       "      <td>1418024844</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  toks hshtgs  \\\n",
       "9    101\\t137\\t48201\\t10133\\t44026\\t10884\\t11305\\t9...    NaN   \n",
       "11   101\\t2341\\t7911\\t121\\t12236\\t7596\\t7431\\t12290...    NaN   \n",
       "26   101\\t144\\t87051\\t10354\\t16874\\t196\\t10117\\t172...    NaN   \n",
       "96   101\\t11589\\t39520\\t18487\\t58136\\t10121\\t10911\\...    NaN   \n",
       "303  101\\t65000\\t112\\t188\\t19556\\t12172\\t10133\\t218...    NaN   \n",
       "\n",
       "                                twtid  media  \\\n",
       "9    24669C0DADEA57A75F6BE24CAC0ACCB9  Photo   \n",
       "11   E15A666B6A975581F5CE3F2286CDB408  Photo   \n",
       "26   D8334D0798821B6A99A9C7A4C9E4E3E1    NaN   \n",
       "96   0C55DCB7494C90953ACE5E70A46B8AA9    NaN   \n",
       "303  3058691BBE196B9A3702A8E7584944E9    NaN   \n",
       "\n",
       "                                links                             domns  \\\n",
       "9                                 NaN                               NaN   \n",
       "11                                NaN                               NaN   \n",
       "26   8FBB6E6890E2ED0F608F83345CB5EA2F  FFA7BC68DEEFEE9FE34F150D60FEA189   \n",
       "96                                NaN                               NaN   \n",
       "303                               NaN                               NaN   \n",
       "\n",
       "       twttyp                              lang          tm  \\\n",
       "9    TopLevel  22C448FF81263D4BAF2A176145EE9EAD  1580948734   \n",
       "11   TopLevel  22C448FF81263D4BAF2A176145EE9EAD  1581344753   \n",
       "26   TopLevel  D3164C7FBCF2565DDF915B1B3AEFB1DC  1581149159   \n",
       "96   TopLevel  06D61DCBBE938971E1EA0C38BD9B5446  1581470640   \n",
       "303  TopLevel  D3164C7FBCF2565DDF915B1B3AEFB1DC  1580980182   \n",
       "\n",
       "                                 u1id  u1_fllwer_cnt  u1_fllwing_cnt  \\\n",
       "9    A6E0653718DB85566D3E6D1E2989AC6D            145              61   \n",
       "11   74BD974C794C3C2D604E92F9402AB810            318             252   \n",
       "26   4CA2E59BBCCB899954E82B01D61C8DF1          16974             612   \n",
       "96   58867654CB709C6FBA4F332ED479EF1A            418             554   \n",
       "303  B31DCBBAE66B1E22B1531F77538E88E7             19             440   \n",
       "\n",
       "     u1_vrfed  u1_create_tm                              u2id  u2_fllwer_cnt  \\\n",
       "9       False    1522591408  06E9B9E30FB6A7F37CA6B42264C30103            407   \n",
       "11      False    1464834037  06E9B9E30FB6A7F37CA6B42264C30103            407   \n",
       "26      False    1397475686  06E9CB2FE3EE244FC5D3E2A7E0B7A460             66   \n",
       "96      False    1354395470  06E9F8C1FB619A5AE34B3BE57632DB16            178   \n",
       "303     False    1476507467  06EADF03A34F162DE8051C27C439F6BB            172   \n",
       "\n",
       "     u2_fllwng_cnt  u2_vrfed  u2_create_tm  u1_fllw_u2  retwt  reply   like  \\\n",
       "9              385     False    1274938010        True  False   True  False   \n",
       "11             385     False    1274938010        True  False   True  False   \n",
       "26             512     False    1498734232       False  False   True  False   \n",
       "96             339     False    1538938782        True  False   True   True   \n",
       "303            167     False    1418024844        True  False   True  False   \n",
       "\n",
       "     retwt_cmmnt  \n",
       "9          False  \n",
       "11         False  \n",
       "26         False  \n",
       "96         False  \n",
       "303        False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['toks', 'hshtgs', 'twtid', 'media', 'links', 'domns', 'twttyp', 'lang',\n",
       "       'tm', 'u1id', 'u1_fllwer_cnt', 'u1_fllwing_cnt', 'u1_vrfed',\n",
       "       'u1_create_tm', 'u2id', 'u2_fllwer_cnt', 'u2_fllwng_cnt', 'u2_vrfed',\n",
       "       'u2_create_tm', 'u1_fllw_u2', 'retwt', 'reply', 'like', 'retwt_cmmnt'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pop=len(dftrn)\n",
    "sampled_train_pop=trnsz\n",
    "idx_pos = np.where(dftrn[TCOL])[0]\n",
    "target_pop=sampled_target_pop=len(idx_pos)\n",
    "if TGT in ('Reply','RTwCmnt'):\n",
    "    idx_neg0 = np.where(~dftrn[TCOL])[0]\n",
    "    idx_neg = np.random.choice(idx_neg0, trnsz-len(idx_pos), replace=False)\n",
    "    idx = np.concatenate([idx_pos,idx_neg])\n",
    "    dftrn = dftrn.iloc[idx].copy()\n",
    "print(dftrn.shape, dftrn[TCOL].mean())\n",
    "print(train_pop, target_pop, sampled_train_pop, sampled_target_pop)\n",
    "\n",
    "display(dftrn.head())\n",
    "display(dftrn.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prp_df(df, tm_max):\n",
    "    '''\n",
    "    tm_max = tm_trn_max for train tm_tst_max for test\n",
    "    '''\n",
    "    lendf = len(df)\n",
    "    print(dtnow(), 'start')\n",
    "    set_u1 = set(df.u1id)\n",
    "    set_u2 = set(df.u2id)\n",
    "    df['u1inu2']=df.u1id.isin(set_u2)\n",
    "    df['u2inu1']=df.u2id.isin(set_u1)\n",
    "\n",
    "    #counts\n",
    "    df['len_toks'] = df.toks.apply(lambda x: len(x.split('\\t')))\n",
    "    df.drop(columns=['toks'], inplace=True)    \n",
    "    for m in ['Photo', 'Video', 'GIF']:\n",
    "        df[f'n_media_{m}'] = df['media'].fillna('').apply(lambda x: x.split('\\t').count(m))\n",
    "    tgnms = ['hshtgs','media', 'links', 'domns',]\n",
    "    for tgnm in tgnms:\n",
    "        df[f'has_{tgnm}']=df[tgnm].notna()\n",
    "        df[f'lst_{tgnm}'] = df[tgnm].fillna('').apply(lambda x: x.split('\\t') if len(x) else [])\n",
    "        df[f'n_{tgnm}'] = df[f'lst_{tgnm}'].apply(len)  \n",
    "    df.drop(columns=['has_links','n_links'], inplace=True) #duplicates has_domns,n_domns \n",
    "    \n",
    "    #time\n",
    "    dt = pd.to_datetime(df.tm, unit='s')\n",
    "    df['dayofweek'] = dt.dt.dayofweek\n",
    "    df['hour'] = dt.dt.hour\n",
    "    \n",
    "    df['tmdlta_u2u1']  = df.u2_create_tm - df.u1_create_tm\n",
    "    df['tmdlta_twtu1'] = df.tm - df.u1_create_tm\n",
    "    df['tmdlta_twtu2'] = df.tm - df.u2_create_tm\n",
    "\n",
    "    df['twt_age']   = tm_max-df.tm\n",
    "    df['u1_age']    = tm_max-df.u1_create_tm\n",
    "    df['u2_age']    = tm_max-df.u2_create_tm\n",
    "    df.drop(columns=['tm', 'u1_create_tm', 'u2_create_tm'], inplace=True)\n",
    "\n",
    "    #time derived\n",
    "    df['u1_fllwer_cnt_by_age'] = df.u1_fllwer_cnt / df.u1_age\n",
    "    df['u1_fllwng_cnt_by_age'] = df.u2_fllwng_cnt / df.u2_age\n",
    "    \n",
    "    #interaction\n",
    "    df['u1u2']=df.u1id+'_'+df.u2id\n",
    "    df['langhour']=df.lang+'_'+df.hour.astype(str)\n",
    "    \n",
    "\n",
    "    #freq of feature values\n",
    "    print(dtnow(), 'freq of columns using CountEncoder')\n",
    "    encoder = ce.CountEncoder()\n",
    "    encoded = encoder.fit_transform(\n",
    "    df[['twtid', 'twttyp', 'lang', 'u1id', 'u1_fllwing_cnt', 'u1_vrfed', 'u2id', 'u2_fllwer_cnt', 'u2_vrfed', 'u1_fllw_u2', \n",
    "       'n_media_Photo', 'n_media_Video', 'n_media_GIF', \n",
    "       'has_hshtgs', 'n_hshtgs', 'has_media', 'n_media','has_domns', 'n_domns', \n",
    "       'dayofweek', 'hour', 'u1u2', 'langhour']].astype(object))\n",
    "    encoded = encoded.astype(int)/lendf\n",
    "    encoded.columns = [f'frq_{col}' for col in encoded.columns]\n",
    "    df = pd.concat([df,encoded],1)\n",
    "    \n",
    "    #freq of tgnm values\n",
    "    print(dtnow(), 'freq of tags')\n",
    "    for tgnm in tgnms:\n",
    "        vs = [j for i in df[f'lst_{tgnm}'] for j in i]\n",
    "        cnt = Counter(vs)\n",
    "        frq = {k:v/lendf for k,v in cnt.items()}\n",
    "        df[f'sumfrq_{tgnm}']=df[f'lst_{tgnm}'].apply(lambda x: sum([frq.get(o,0) for o in x]))\n",
    "        df[f'maxfrq_{tgnm}']=df[f'lst_{tgnm}'].apply(lambda x: max([frq.get(o,0) for o in x]) if len(x) else 0)\n",
    "#     df.drop(columns=tgnms+[f'lst_{tgnm}' for tgnm in tgnms],inplace=True)\n",
    "    df.drop(columns=tgnms,inplace=True)\n",
    "\n",
    "    print(dtnow(), 'done')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-12 15:46:11 start\n",
      "2020-04-12 15:46:22 freq of columns using CountEncoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/category_encoders/count.py:255: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  X.loc[:, self.cols] = X.fillna(value=pd.np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-12 15:46:37 freq of tags\n",
      "2020-04-12 15:46:41 done\n",
      "CPU times: user 27.3 s, sys: 3.52 s, total: 30.8 s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dftrn=prp_df(dftrn, tm_max=tm_trn_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-12 15:46:42 start\n",
      "2020-04-12 15:46:50 freq of columns using CountEncoder\n",
      "2020-04-12 15:47:02 freq of tags\n",
      "2020-04-12 15:47:06 done\n",
      "CPU times: user 22.8 s, sys: 2.12 s, total: 24.9 s\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfval=prp_df(dfval, tm_max=tm_trn_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tr vl split and target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk_vl=np.random.rand(len(dftrn))<0.15\n",
    "idxvl=np.where( msk_vl)[0]\n",
    "idxtr=np.where(~msk_vl)[0]\n",
    "\n",
    "dftr = dftrn.iloc[idxtr].copy()\n",
    "dfvl = dftrn.iloc[idxvl].copy()\n",
    "del dftrn\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['twtid', 'twttyp', 'lang', 'u1id', 'u1_fllwer_cnt', 'u1_fllwing_cnt',\n",
       "       'u1_vrfed', 'u2id', 'u2_fllwer_cnt', 'u2_fllwng_cnt', 'u2_vrfed',\n",
       "       'u1_fllw_u2', 'retwt', 'reply', 'like', 'retwt_cmmnt', 'u1inu2',\n",
       "       'u2inu1', 'len_toks', 'n_media_Photo', 'n_media_Video', 'n_media_GIF',\n",
       "       'has_hshtgs', 'lst_hshtgs', 'n_hshtgs', 'has_media', 'lst_media',\n",
       "       'n_media', 'lst_links', 'has_domns', 'lst_domns', 'n_domns',\n",
       "       'dayofweek', 'hour', 'tmdlta_u2u1', 'tmdlta_twtu1', 'tmdlta_twtu2',\n",
       "       'twt_age', 'u1_age', 'u2_age', 'u1_fllwer_cnt_by_age',\n",
       "       'u1_fllwng_cnt_by_age', 'u1u2', 'langhour', 'frq_twtid', 'frq_twttyp',\n",
       "       'frq_lang', 'frq_u1id', 'frq_u1_fllwing_cnt', 'frq_u1_vrfed',\n",
       "       'frq_u2id', 'frq_u2_fllwer_cnt', 'frq_u2_vrfed', 'frq_u1_fllw_u2',\n",
       "       'frq_n_media_Photo', 'frq_n_media_Video', 'frq_n_media_GIF',\n",
       "       'frq_has_hshtgs', 'frq_n_hshtgs', 'frq_has_media', 'frq_n_media',\n",
       "       'frq_has_domns', 'frq_n_domns', 'frq_dayofweek', 'frq_hour', 'frq_u1u2',\n",
       "       'frq_langhour', 'sumfrq_hshtgs', 'maxfrq_hshtgs', 'sumfrq_media',\n",
       "       'maxfrq_media', 'sumfrq_links', 'maxfrq_links', 'sumfrq_domns',\n",
       "       'maxfrq_domns'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tgtenc for ordinary cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.7 s, sys: 1.87 s, total: 28.5 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "col2tgtenc=['twtid', 'twttyp', 'lang', 'u1id', 'u1_fllwing_cnt', 'u1_vrfed', 'u2id', 'u2_fllwer_cnt', 'u2_vrfed', 'u1_fllw_u2', \n",
    "   'n_media_Photo', 'n_media_Video', 'n_media_GIF', \n",
    "   'has_hshtgs', 'n_hshtgs', 'has_media', 'n_media','has_domns', 'n_domns', \n",
    "   'dayofweek', 'hour', 'u1u2', 'langhour']\n",
    "tgt_encoder = ce.TargetEncoder()\n",
    "encoded_tr = tgt_encoder.fit_transform(dftr[col2tgtenc].astype(object), dftr[TCOL])\n",
    "encoded_vl = tgt_encoder.transform(dfvl[col2tgtenc].astype(object))\n",
    "encoded_val = tgt_encoder.transform(dfval[col2tgtenc].astype(object))\n",
    "\n",
    "tgtenc_columns = [f'tgtenc_{col}' for col in encoded_tr.columns]\n",
    "encoded_tr.columns = tgtenc_columns\n",
    "encoded_vl.columns = tgtenc_columns\n",
    "encoded_val.columns = tgtenc_columns\n",
    "\n",
    "dftr = pd.concat([dftr, encoded_tr], 1)\n",
    "dfvl = pd.concat([dfvl, encoded_vl], 1)\n",
    "dfval = pd.concat([dfval, encoded_val], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_category=['twttyp', 'lang', 'langhour']\n",
    "for df in dftr,dfvl,dfval:\n",
    "    df.drop(columns=['twtid','u1id','u2id','u1u2'], inplace=True)\n",
    "    df[cols_category]=df[cols_category].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tgtenc for hshtg and domn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag='hshtgs'\n",
    "lsttag=f'lst_{tag}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr_has_tag = dftr[dftr[lsttag].apply(len)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2lbl_nested = [[(oo,o[1]) for oo in o[0]] for o in zip(dftr_has_tag[lsttag], dftr_has_tag[TCOL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2lbl = [j for i in tag2lbl_nested for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags, lbls = list(zip(*tag2lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tgt_encoder = ce.TargetEncoder()\n",
    "encoded_tr = tgt_encoder.fit(np.array(tags), lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70750"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_tags = np.array(list(set(tags)))\n",
    "len(set_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70750"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgtenc_vs = encoded_tr.transform(set_tags)\n",
    "len(tgtenc_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70750"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2vtgtenc=dict(zip(set_tags,tgtenc_vs.values[:,0]))\n",
    "len(v2vtgtenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-12 16:06:01 hshtgs\n",
      "2020-04-12 16:06:02 domns\n"
     ]
    }
   ],
   "source": [
    "tag2v2vtgtenc={}\n",
    "for tag in ('hshtgs','domns'):\n",
    "    print(dtnow(), tag)\n",
    "    lsttag=f'lst_{tag}'\n",
    "    dftr_has_tag = dftr[dftr[lsttag].apply(len)>0]\n",
    "    tag2lbl_nested = [[(oo,o[1]) for oo in o[0]] for o in zip(dftr_has_tag[lsttag], dftr_has_tag[TCOL])]\n",
    "    tag2lbl = [j for i in tag2lbl_nested for j in i]\n",
    "    tags, lbls = list(zip(*tag2lbl))\n",
    "    tgt_encoder = ce.TargetEncoder()\n",
    "    encoded_tr = tgt_encoder.fit(np.array(tags), lbls)\n",
    "    set_tags = np.array(list(set(tags)))\n",
    "    tgtenc_vs = encoded_tr.transform(set_tags)\n",
    "    v2vtgtenc=dict(zip(set_tags,tgtenc_vs.values[:,0]))\n",
    "    tag2v2vtgtenc[tag]=v2vtgtenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70750, 12357]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(o) for o in tag2v2vtgtenc.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply tag2v2vtenc to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in ('hshtgs','domns'):\n",
    "for tgnm in tgnms:\n",
    "    vs = [j for i in df[f'lst_{tgnm}'] for j in i]\n",
    "    cnt = Counter(vs)\n",
    "    frq = {k:v/lendf for k,v in cnt.items()}\n",
    "    df[f'sumfrq_{tgnm}']=df[f'lst_{tgnm}'].apply(lambda x: sum([frq.get(o,0) for o in x]))\n",
    "    df[f'maxfrq_{tgnm}']=df[f'lst_{tgnm}'].apply(lambda x: max([frq.get(o,0) for o in x]) if len(x) else 0)\n",
    "#     df.drop(columns=tgnms+[f'lst_{tgnm}' for tgnm in tgnms],inplace=True)\n",
    "df.drop(columns=tgnms,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_feat = [col for col in dftr.columns if col not in cols_tgt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cols_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cols_feat))\n",
    "cols_feat=['twttyp',\n",
    " 'lang',\n",
    " 'u1_fllwer_cnt',\n",
    " 'u1_fllwing_cnt',\n",
    " 'u1_vrfed',\n",
    " 'u2_fllwer_cnt',\n",
    " 'u2_fllwng_cnt',\n",
    " 'u2_vrfed',\n",
    " 'u1_fllw_u2',\n",
    " 'u1inu2',\n",
    " 'u2inu1',\n",
    " 'len_toks',\n",
    " 'n_media_Photo',\n",
    " 'n_media_Video',\n",
    " 'n_media_GIF',\n",
    "#  'has_hshtgs',\n",
    " 'n_hshtgs',\n",
    "#  'has_media',\n",
    " 'n_media',\n",
    "#  'has_domns',\n",
    " 'n_domns',\n",
    " 'dayofweek',\n",
    " 'hour',\n",
    " 'tmdlta_u2u1',\n",
    " 'tmdlta_twtu1',\n",
    " 'tmdlta_twtu2',\n",
    " 'twt_age',\n",
    " 'u1_age',\n",
    " 'u2_age',\n",
    " 'u1_fllwer_cnt_by_age',\n",
    " 'u1_fllwng_cnt_by_age',\n",
    " 'langhour',\n",
    " 'frq_twtid',\n",
    "#  'frq_twttyp',\n",
    "#  'frq_lang',\n",
    " 'frq_u1id',\n",
    "#  'frq_u1_fllwing_cnt',\n",
    "#  'frq_u1_vrfed',\n",
    " 'frq_u2id',\n",
    "#  'frq_u2_fllwer_cnt',\n",
    "#  'frq_u2_vrfed',\n",
    "#  'frq_u1_fllw_u2',\n",
    "#  'frq_n_media_Photo',\n",
    "#  'frq_n_media_Video',\n",
    "#  'frq_n_media_GIF',\n",
    "#  'frq_has_hshtgs',\n",
    "#  'frq_n_hshtgs',\n",
    "#  'frq_has_media',\n",
    "#  'frq_n_media',\n",
    "#  'frq_has_domns',\n",
    "#  'frq_n_domns',\n",
    "#  'frq_dayofweek',\n",
    "#  'frq_hour',\n",
    " 'frq_u1u2',\n",
    "#  'frq_langhour',\n",
    " 'sumfrq_hshtgs',\n",
    "#  'maxfrq_hshtgs',\n",
    "#  'sumfrq_media',\n",
    "#  'maxfrq_media',\n",
    "#  'sumfrq_links',\n",
    "#  'maxfrq_links',\n",
    " 'sumfrq_domns',\n",
    "#  'maxfrq_domns',\n",
    "#  'tgtenc_twtid',\n",
    "#  'tgtenc_twttyp',\n",
    " 'tgtenc_lang',\n",
    "#  'tgtenc_u1id',\n",
    "#  'tgtenc_u1_fllwing_cnt',\n",
    "#  'tgtenc_u1_vrfed',\n",
    "#  'tgtenc_u2id',\n",
    "#  'tgtenc_u2_fllwer_cnt',\n",
    "#  'tgtenc_u2_vrfed',\n",
    "#  'tgtenc_u1_fllw_u2',\n",
    "#  'tgtenc_n_media_Photo',\n",
    "#  'tgtenc_n_media_Video',\n",
    "#  'tgtenc_n_media_GIF',\n",
    "#  'tgtenc_has_hshtgs',\n",
    "#  'tgtenc_n_hshtgs',\n",
    "#  'tgtenc_has_media',\n",
    "#  'tgtenc_n_media',\n",
    "#  'tgtenc_has_domns',\n",
    "#  'tgtenc_n_domns',\n",
    "#  'tgtenc_dayofweek',\n",
    "#  'tgtenc_hour',\n",
    "#  'tgtenc_u1u2',\n",
    "#  'tgtenc_langhour'\n",
    "          ]\n",
    "print(len(cols_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['PRFX'] = PRFX\n",
    "results['TGT'] = TGT\n",
    "results['cols_feat'] = cols_feat\n",
    "results['tgt_encoder'] = tgt_encoder\n",
    "results['col2tgtenc'] = col2tgtenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': 0,    \n",
    "}\n",
    "results['params'] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dtr = lgb.Dataset(dftr[cols_feat], label=dftr[TCOL])\n",
    "dvl = lgb.Dataset(dfvl[cols_feat], label=dfvl[TCOL])\n",
    "best_params, tuning_history = {}, []\n",
    "evalres = {}\n",
    "evallist = [(dtr, 'train'), (dvl, 'eval')]\n",
    "bst = lgb.train(params=params, \n",
    "                train_set=dtr, \n",
    "                num_boost_round=50000,\n",
    "                valid_sets=[dtr, dvl],\n",
    "                valid_names=['tr','vl'],\n",
    "                best_params=best_params,\n",
    "                tuning_history=tuning_history,\n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds=100,\n",
    "                evals_result=evalres,\n",
    "               )\n",
    "results['bst'] = bst\n",
    "results['evalres'] = evalres\n",
    "results['best_params']=best_params\n",
    "results['tuning_history']=tuning_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tr vl trajec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(evalres['tr']['binary_logloss'])\n",
    "plt.plot(evalres['vl']['binary_logloss'])\n",
    "plt.title(f\"logloss; best_iteration {bst.best_iteration}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lgb.plot_importance(bst, height=0.8, max_num_features=50, figsize=(10,15))\n",
    "ax.grid(False, axis=\"y\")\n",
    "ax.set_title(f'Estimated feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([bst.feature_name(), bst.feature_importance()]).T.sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2imp = dict(zip(bst.feature_name(), bst.feature_importance()))\n",
    "sorted(col2imp.items(), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[o[0] for o in sorted(col2imp.items(), key=lambda x: -x[1]) if o[1]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prdtr = bst.predict(dftr[cols_feat],num_iteration=bst.best_iteration)\n",
    "prdvl = bst.predict(dfvl[cols_feat],num_iteration=bst.best_iteration)\n",
    "prdval0 = bst.predict(dfval[cols_feat],num_iteration=bst.best_iteration)\n",
    "prdval = calibration(prdval0, train_pop, target_pop, sampled_train_pop, sampled_target_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ytr,yvl,yval=[df[TCOL].values for df in (dftr,dfvl,dfval)]\n",
    "\n",
    "auc_tr=compute_prauc(prdtr, ytr)\n",
    "rce_tr=compute_rce(prdtr, ytr)\n",
    "auc_vl=compute_prauc(prdvl, yvl)\n",
    "rce_vl=compute_rce(prdvl, yvl)\n",
    "auc_val=compute_prauc(prdval, yval)\n",
    "rce_val=compute_rce(prdval, yval)\n",
    "\n",
    "results['scrs'] = {}\n",
    "results['scrs']['auc_tr']=auc_tr\n",
    "results['scrs']['rce_tr']=rce_tr\n",
    "results['scrs']['auc_vl']=auc_vl\n",
    "results['scrs']['rce_vl']=rce_vl\n",
    "results['scrs']['auc_val']=auc_val\n",
    "results['scrs']['rce_val']=rce_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'auc_tr:  {auc_tr:.4f}')\n",
    "print(f'auc_vl:  {auc_vl:.4f}')\n",
    "print(f'auc_val: {auc_val:.4f}')\n",
    "print()\n",
    "print(f'rce_tr:  {rce_tr:.4f}')\n",
    "print(f'rce_vl:  {rce_vl:.4f}')\n",
    "print(f'rce_val: {rce_val:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'-{auc_val:.4f}-{rce_val:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results, open(f'{p_out}/results_{PRFX}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load( open(f'{p_out}/results_{PRFX}.p', 'rb'))\n",
    "bst = results['bst']\n",
    "col2tgtenc = results['col2tgtenc']\n",
    "cols_feat = results['cols_feat']\n",
    "tgt_encoder = results['tgt_encoder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst=pd.read_csv(\n",
    "    f'{p_in}/val_{tsttmstmp}.tsv',\n",
    "    sep='\\x01', header=None, names=cols_val, \n",
    "    nrows=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dftst=prp_df(dftst, tm_max=tm_tst_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_tst = tgt_encoder.transform(dftst[col2tgtenc].astype(object))\n",
    "tgtenc_columns = [f'tgtenc_{col}' for col in encoded_tst.columns]\n",
    "encoded_tst.columns = tgtenc_columns\n",
    "dftst = pd.concat([dftst, encoded_tst], 1)\n",
    "dftst.drop(columns=['u1id','u1u2'], inplace=True)\n",
    "cols_category=['twttyp', 'lang', 'langhour']\n",
    "dftst[cols_category]=dftst[cols_category].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prdtst0 = bst.predict(dftst[cols_feat],num_iteration=bst.best_iteration)\n",
    "prdtst = calibration(prdtst0, train_pop, target_pop, sampled_train_pop, sampled_target_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub_ids = dftst[['twtid','u2id',]]\n",
    "dfsub = dfsub_ids.copy()\n",
    "dfsub['scr'] = prdtst\n",
    "dfsub.to_csv(f'{p_out}/{TGT}__{PRFX}.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
