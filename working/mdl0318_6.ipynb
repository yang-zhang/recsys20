{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-03-17 02:32:24', '2020-03-17 00:30:47']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRFX='0318_6'\n",
    "# http://localhost:8081/notebooks/git/recsys20/working/prep0318_1.ipynb\n",
    "PRFX_PRP = 'prep0318_1' \n",
    "langs = ['22C448FF81263D4BAF2A176145EE9EAD',]\n",
    "trntmstmp=1584412344\n",
    "import datetime\n",
    "[datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (trntmstmp, valtmstmp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.__version__ 2.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/rcss20/lib/python3.7/site-packages/dask/array/random.py:27: FutureWarning: dask.array.random.doc_wraps is deprecated and will be removed in a future version\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import dask\n",
    "print('dask.__version__', dask.__version__)\n",
    "import xgboost\n",
    "import dask_xgboost\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "from dask.distributed import Client\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "import datetime\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "SEED=101\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "p_prp=f'{HOME}/output/{PRFX_PRP}'\n",
    "p_out=f'{HOME}/output/{PRFX}'\n",
    "Path(p_out).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, log_loss\n",
    "\n",
    "def compute_prauc(pred, gt):\n",
    "    prec, recall, thresh = precision_recall_curve(gt, pred)\n",
    "    prauc = auc(recall, prec)\n",
    "    return prauc\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "    positive = len([x for x in gt if x == 1])\n",
    "    ctr = positive/float(len(gt))\n",
    "    return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "cols=[\n",
    "'toks',\n",
    "'hshtgs',\n",
    "'twtid',\n",
    "'media',\n",
    "'links',\n",
    "'domns',\n",
    "'twttyp',\n",
    "'lang',\n",
    "'tm',\n",
    "\n",
    "'u1id',\n",
    "'u1_fllwer_cnt',\n",
    "'u1_fllwing_cnt',\n",
    "'u1_vrfed',\n",
    "'u1_create_tm',\n",
    "\n",
    "'u2id',\n",
    "'u2_follower_cnt',\n",
    "'u2_following_cnt',\n",
    "'u2_vrfed',\n",
    "'u2_create_tm',\n",
    "\n",
    "'u1_fllw_u2',\n",
    "'reply_tm',\n",
    "'retwt_tm',\n",
    "'retwt_cmmnt_tm',\n",
    "'like_tm',\n",
    "]\n",
    "\n",
    "cols_val = cols[:-4]\n",
    "\n",
    "tgts     = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "cols_tgt = ['retwt',  'reply','like','retwt_cmmnt',]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu  15G Mar 18 20:45 dftrn_22C448FF81263D4BAF2A176145EE9EAD_1584412344__prep0318_1.tsv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  35M Mar 18 13:41 dftrn_3A85BCEC571C3F5AB1069E4924189177_1584412344__prep0318_1.tsv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  34M Mar 18 13:41 dftrn_69C4A33B9AD29AF883D60BA61CC08702_1584412344__prep0318_1.tsv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  30M Mar 18 13:41 dftrn_CB11E9CF42BD0A1BAD5E27BF3422D99D_1584412344__prep0318_1.tsv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  26M Mar 18 13:41 dftrn_E7BB61D2A87C1E72DF1C7BC292B86A1C_1584412344__prep0318_1.tsv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  23M Mar 18 13:41 dftrn_FF7EABB5A382356D54D9C41BA0125E09_1584412344__prep0318_1.tsv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  20M Mar 18 13:42 dftrn_54208B51D44E7D91DC2F3DD02ADEDEC2_1584412344__prep0318_1.tsv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  19M Mar 18 13:42 dftrn_B6D90127A09AB1229731898AEF9D4D7C_1584412344__prep0318_1.tsv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  17M Mar 18 13:41 dftrn_F4FD40A716F1572C9A28E9CAA58BE3A5_1584412344__prep0318_1.tsv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  15M Mar 18 13:42 dftrn_6431A618DCF7F4CB7F62A95A39BAB77A_1584412344__prep0318_1.tsv\r\n"
     ]
    }
   ],
   "source": [
    "ls -hlS $p_prp | grep dftrn | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.concat([dd.read_csv(f'{p_prp}/dftrn_{lang}_{trntmstmp}__{PRFX_PRP}.tsv',sep='\\x01') for lang in langs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 3s, sys: 40.7 s, total: 6min 44s\n",
      "Wall time: 2min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23652265, 20104426, 3547839)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# https://stackoverflow.com/questions/40376425/dask-dataframe-equivalent-of-pandas-dataframe-sort-values\n",
    "lendf = df.shape[0].compute()\n",
    "valsz = int(lendf*0.15)\n",
    "trnsz = lendf-valsz\n",
    "lendf, trnsz, valsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dftr=df.nsmallest(trnsz,'tm')\n",
    "dfvl=df.nlargest(valsz,'tm')\n",
    "\n",
    "# assert dfvl.tm.min().compute() >= dftr.tm.max().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_feat=[\n",
    "       'tm', 'u1_fllwer_cnt', 'u1_fllwing_cnt', 'u1_vrfed',\n",
    "       'u1_create_tm', 'u2_follower_cnt', 'u2_following_cnt',\n",
    "       'u2_vrfed', 'u2_create_tm', 'u1_fllw_u2', 'len_toks', 'has_media_Photo',\n",
    "       'has_media_Video', 'has_media_GIF', 'num_hshtgs', 'num_links',\n",
    "       'num_domns', 'twttyp_TopLevel', 'twttyp_Retweet', 'twttyp_Quote',\n",
    "       'tmdlta_u2u1', 'tmdlta_twtu1', 'tmdlta_twtu2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X, ys = (df[cols].to_dask_array(lengths=True) for cols in (cols_feat,cols_tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xtrn, Xval, ystrn, ysval = train_test_split(X, ys, test_size=0.15, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2params = {\n",
    "        'Retweet': {\n",
    "            'objective': 'binary:logistic',\n",
    "#             'max_depth':5,\n",
    "#             'min_child_weight':2,\n",
    "#             'gamma':1,\n",
    "        }, \n",
    "        'Reply': {\n",
    "            'objective': 'binary:logistic',\n",
    "#             'max_depth':5,\n",
    "#             'min_child_weight':2,\n",
    "            'gamma':1,\n",
    "        }, \n",
    "        'Like': {\n",
    "            'objective': 'binary:logistic',\n",
    "#             'max_depth':5,\n",
    "#             'min_child_weight':2,\n",
    "#             'gamma':1,\n",
    "        }, \n",
    "        'RTwCmnt': {\n",
    "            'objective': 'binary:logistic',\n",
    "#             'max_depth':5,\n",
    "#             'min_child_weight':2,\n",
    "#             'gamma':1,\n",
    "        }, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2bst={}\n",
    "tgt2col2fscr={}\n",
    "for i,tgt in enumerate(tgts):\n",
    "    params = tgt2params[tgt]\n",
    "    bst = dask_xgboost.train(client, params,\n",
    "                             Xtrn, ystrn[:,i],\n",
    "                             num_boost_round=10)\n",
    "    tgt2bst[tgt]=bst\n",
    "    print(dtnow(), tgt)\n",
    "    \n",
    "    fi2col=dict(zip(bst.feature_names, cols_feat))\n",
    "    col2fi=dict(zip(cols_feat, bst.feature_names))\n",
    "    fi2fscr=bst.get_fscore()\n",
    "    col2fscr={col:fi2fscr.get(fi,0) for col,fi in col2fi.items()}\n",
    "    tgt2col2fscr[tgt]=col2fscr\n",
    "\n",
    "pickle.dump(tgt2bst, open(f\"{p_out}/tgt2bst.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2bst=pickle.load(open(f\"{p_out}/tgt2bst.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_feat_importance(bst):\n",
    "    ax = xgboost.plot_importance(bst, height=0.8, max_num_features=9)\n",
    "    ax.grid(False, axis=\"y\")\n",
    "    ax.set_title('Estimated feature importance')\n",
    "    plt.show()\n",
    "\n",
    "for i,tgt in enumerate(tgts):\n",
    "    print(tgt)\n",
    "    show_feat_importance(tgt2bst[tgt])\n",
    "    col2fscr=tgt2col2fscr[tgt]\n",
    "    display(pd.DataFrame(col2fscr.items()).sort_values(1, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2ytrn={}\n",
    "tgt2yval={}\n",
    "tgt2prdtrn={}\n",
    "tgt2prdval={}\n",
    "for i,tgt in enumerate(tgts):\n",
    "    print(dtnow(), tgt)\n",
    "    prdtrn = dask_xgboost.predict(client, tgt2bst[tgt], Xtrn).persist()\n",
    "    prdval = dask_xgboost.predict(client, tgt2bst[tgt], Xval).persist()\n",
    "    ytrn, prdtrn = dask.compute(ystrn[:,i], prdtrn)\n",
    "    yval, prdval = dask.compute(ysval[:,i], prdval)\n",
    "    tgt2ytrn[tgt],tgt2yval[tgt]=ytrn,yval\n",
    "    tgt2prdtrn[tgt],tgt2prdval[tgt]=prdtrn,prdval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_roc_auc(prd,y):\n",
    "    fpr, tpr, _ = roc_curve(y,prd)\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.plot(fpr, tpr, lw=3,\n",
    "            label='ROC Curve (area = {:.2f})'.format(auc(fpr, tpr)))\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    ax.set(\n",
    "        xlim=(0, 1),\n",
    "        ylim=(0, 1),\n",
    "        title=\"ROC Curve\",\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "    )\n",
    "    ax.legend();\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tgt2auc_trn={}\n",
    "tgt2rce_trn={}\n",
    "tgt2auc_val={}\n",
    "tgt2rce_val={}\n",
    "for i,tgt in enumerate(tgts):\n",
    "    print(tgt)\n",
    "    ytrn,yval = tgt2ytrn[tgt],tgt2yval[tgt]\n",
    "    prdtrn,prdval = tgt2prdtrn[tgt],tgt2prdval[tgt]\n",
    "    scr_rocauc_trn = roc_auc_score(ytrn, prdtrn)\n",
    "    scr_rocauc_val = roc_auc_score(yval, prdval)\n",
    "    scr_auc_trn=compute_prauc(prdtrn, ytrn)\n",
    "    scr_rce_trn=compute_rce(prdtrn, ytrn)\n",
    "    scr_auc_val=compute_prauc(prdval, yval)\n",
    "    scr_rce_val=compute_rce(prdval, yval)\n",
    "    tgt2auc_trn[tgt]=scr_auc_trn\n",
    "    tgt2rce_trn[tgt]=scr_rce_trn\n",
    "    tgt2auc_val[tgt]=scr_auc_val\n",
    "    tgt2rce_val[tgt]=scr_rce_val\n",
    "    print('train rocauc:', f'{scr_rocauc_trn:.4f}', 'valid auc:', f'{scr_rocauc_val:.4f}', )\n",
    "    print('train prauc:', f'{scr_auc_trn:.4f}', 'valid auc:', f'{scr_auc_val:.4f}', )\n",
    "    print('train rce:', f'{scr_rce_trn:.4f}', 'valid rce:', f'{scr_rce_val:.4f}', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsttrn=[]\n",
    "lstval=[]\n",
    "for tgt in ['Retweet','Reply','Like','RTwCmnt',]:\n",
    "    lsttrn+=[(f'PRAUC {tgt}',tgt2auc_trn[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_trn[tgt])]\n",
    "    lstval+=[(f'PRAUC {tgt}',tgt2auc_val[tgt]),\n",
    "          (f'RCE {tgt}',tgt2rce_val[tgt])]\n",
    "\n",
    "dfscrtrn=pd.DataFrame(lsttrn)\n",
    "dfscrtrn.columns=['metric','scr']\n",
    "dfscrval=pd.DataFrame(lstval)\n",
    "dfscrval.columns=['metric','scr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscr = pd.merge(dfscrtrn, dfscrval, on='metric', suffixes=('trn','val'))\n",
    "dfscr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRFX_PRP_TST = 'prep0318_2' \n",
    "valtmstmp="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {p_prp} | grep {valtmstmp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftst=dd.read_csv(\n",
    "    f'{p_prp}/dfval_{valtmstmp}__{PRFX_PRP_TST}.tsv',\n",
    "    sep='\\x01',\n",
    "    encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtst = dftst[cols_feat].to_dask_array(lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tgt2prdtst={}\n",
    "for i,tgt in enumerate(tgts):\n",
    "    prdtst = dask_xgboost.predict(client, tgt2bst[tgt], Xtst)\n",
    "    prdtst = prdtst\n",
    "    tgt2prdtst[tgt]=prdtst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub_ids = dftst[['twtid','u2id',]]\n",
    "\n",
    "tgt2dfsub = {}\n",
    "for tgt,prdtst in tgt2prdtst.items():\n",
    "    dfsub = dfsub_ids.copy()\n",
    "    dfsub['scr'] = prdtst\n",
    "    tgt2dfsub[tgt]=dfsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for tgt, dfsub in tgt2dfsub.items():\n",
    "    print(dtnow(), tgt)\n",
    "    dfsub.to_csv(f'{p_out}/{tgt}__{valtmstmp}__{PRFX}.csv',index=False,header=False,single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for tgt in tgts:\n",
    "#     print(dtnow(), tgt)\n",
    "#     dfsub = pd.concat(pd.read_csv(o, header=None) for o in sorted(glob.glob(f'{p_out}/{tgt}__{PRFX}_*.csv')))\n",
    "#     dfsub.to_csv(f'{p_out}/{tgt}__{PRFX}.csv', \n",
    "#                           index=False, \n",
    "#                           header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head -n 2 {p_prp}/val_{valtmstmp}.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tgt in tgts:\n",
    "    !head -n 2 {p_out}/{tgt}__{valtmstmp}__{PRFX}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
