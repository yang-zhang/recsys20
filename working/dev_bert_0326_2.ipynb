{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:8889/notebooks/git/google-quest-challenge/working/QstBertBase0113_1.ipynb\n",
    "\n",
    "no freezing of bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-03-17 02:32:24', '2020-03-24 17:09:45']\n",
      "['2020-02-06 00:00:00', '2020-02-13 00:00:00']\n"
     ]
    }
   ],
   "source": [
    "trntmstmp=1584412344\n",
    "valtmstmp=1585069785\n",
    "import datetime\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (trntmstmp, valtmstmp)])\n",
    "\n",
    "grand_total=1.5e8\n",
    "MIN_TM_TRN=1580947200\n",
    "MIN_TM_TST=1581552000\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (MIN_TM_TRN, MIN_TM_TST)])\n",
    "\n",
    "\n",
    "CHNKSZ=1e6\n",
    "POST_RATE_WANTED=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 26 20:47:23 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   78C    P0    76W / 149W |      0MiB / 11441MiB |     97%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import datetime\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "SEED=101\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "import torch\n",
    "device=torch.device('cuda')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "pretrained_weights='bert-base-multilingual-cased'\n",
    "bertmodel = BertModel.from_pretrained(pretrained_weights, output_hidden_states=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights, do_lower_case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Retweet': 'retwt',\n",
       " 'Reply': 'reply',\n",
       " 'Like': 'like',\n",
       " 'RTwCmnt': 'retwt_cmmnt'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=[\n",
    "'toks',\n",
    "'hshtgs',\n",
    "'twtid',\n",
    "'media',\n",
    "'links',\n",
    "'domns',\n",
    "'twttyp',\n",
    "'lang',\n",
    "'tm',\n",
    "\n",
    "'u1id',\n",
    "'u1_fllwer_cnt',\n",
    "'u1_fllwng_cnt',\n",
    "'u1_vrfed',\n",
    "'u1_create_tm',\n",
    "\n",
    "'u2id',\n",
    "'u2_fllwer_cnt',\n",
    "'u2_fllwng_cnt',\n",
    "'u2_vrfed',\n",
    "'u2_create_tm',\n",
    "\n",
    "'u1_fllw_u2',\n",
    "'reply_tm',\n",
    "'retwt_tm',\n",
    "'retwt_cmmnt_tm',\n",
    "'like_tm',\n",
    "]\n",
    "cols_cat = ['twttyp','lang']\n",
    "cols_val = cols[:-4]\n",
    "cols_tgt_tmstmp=[\n",
    "    'retwt_tm',\n",
    "    'reply_tm',\n",
    "    'like_tm',\n",
    "    'retwt_cmmnt_tm',\n",
    "]\n",
    "cols_tgt=[o.split('_tm')[0] for o in cols_tgt_tmstmp]\n",
    "tgts             = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "assert cols_tgt == ['retwt',  'reply','like','retwt_cmmnt',]\n",
    "ntgts=len(tgts)\n",
    "\n",
    "\n",
    "tgt2col=dict(zip(tgts,cols_tgt))\n",
    "tgt2col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 657 ms, sys: 63.9 ms, total: 721 ms\n",
      "Wall time: 720 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dftrn=pd.read_csv(\n",
    "    f'{p_in}/trn_{trntmstmp}.tsv',\n",
    "    sep='\\x01', header=None, \n",
    "    encoding='utf-8', \n",
    "    names=cols, \n",
    "    nrows=1e5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.pad_token, tokenizer.pad_token_id\n",
    "# ('[PAD]', 0)\n",
    "\n",
    "# tokenizer.sep_token, tokenizer.sep_token_id\n",
    "# ('[SEP]', 102)\n",
    "maxlen=512\n",
    "def mkids(x):\n",
    "    tokids=list(map(int, x.split('\\t')))\n",
    "    l=len(tokids) \n",
    "    if l<=maxlen: \n",
    "        return tokids + [0]*(maxlen-len(tokids))\n",
    "    else: \n",
    "        return tokids[:maxlen-1]+[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_tensors(df, istrn=True):\n",
    "    tokids=dftrn.toks.apply(lambda x: mkids(x))\n",
    "    Xarr=np.array(list(tokids))\n",
    "    X=torch.tensor(Xarr,dtype=torch.long)\n",
    "    if not istrn: return X\n",
    "    ys=dftrn[cols_tgt_tmstmp].notna().values\n",
    "    ys=torch.tensor(ys,dtype=torch.float)\n",
    "    return X,ys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X,ys = mk_tensors(dftrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512]) torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "BS=8\n",
    "ds = TensorDataset(X,ys)\n",
    "dl = DataLoader(ds, batch_size=BS, shuffle=True)\n",
    "for step, batch in enumerate(dl):\n",
    "    X_b,ys_b = (o.to(device) for o in batch)\n",
    "    print(X_b.shape,ys_b.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=2\n",
    "WD=0.01\n",
    "LR=1e-5\n",
    "SCHDLR_FUNC = get_cosine_schedule_with_warmup \n",
    "WARMUP_RATE = 0.05\n",
    "N_CYCLS = .5\n",
    "EPS = 1e-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 512]) torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "BS=6\n",
    "ds = TensorDataset(X,ys)\n",
    "dl = DataLoader(ds, batch_size=BS, shuffle=True)\n",
    "for step, batch in enumerate(dl):\n",
    "    X_b,ys_b = (o.to(device) for o in batch)\n",
    "    print(X_b.shape,ys_b.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 512, 768]),\n",
       " torch.Size([6, 768]),\n",
       " 13,\n",
       " torch.Size([6, 768]),\n",
       " torch.Size([6, 768]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "bertmodel=bertmodel.eval()\n",
    "bertmodel.to(device)\n",
    "with torch.no_grad():\n",
    "    last_hidden_state, pooler_output, hidden_states = bertmodel(X_b,)\n",
    "    avg_pool = torch.mean(last_hidden_state,1)\n",
    "    max_pool,_ = torch.max(last_hidden_state,1)\n",
    "last_hidden_state.shape,pooler_output.shape, len(hidden_states), avg_pool.shape, max_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see RobertaClassificationHead in transformers/modeling_roberta.py\n",
    "N_HIDDEN = 768 \n",
    "class TwtModel(nn.Module):\n",
    "    def __init__(self, bertmodel, num_labels=4):\n",
    "        super(TwtModel, self).__init__()\n",
    "        self.bertmodel = bertmodel\n",
    "#         for param in self.bertmodel.parameters():\n",
    "#             param.requires_grad=False\n",
    "        \n",
    "        dense_size = 64\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        nx = N_HIDDEN*2\n",
    "        self.dense = nn.Linear(nx, nx)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_proj = nn.Linear(nx, num_labels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_msk = (x!=tokenizer.pad_token_id).float().to(device)\n",
    "        segments = torch.zeros(x.shape, dtype=torch.long).to(device)\n",
    "        last_hidden_state, pooler_output, hidden_states = self.bertmodel(x, \n",
    "                                                                         attention_mask=attn_msk,\n",
    "                                         token_type_ids=segments)\n",
    "        avg_pool = torch.mean(last_hidden_state,1)\n",
    "        max_pool,_ = torch.max(last_hidden_state,1)\n",
    "        x = torch.cat([avg_pool,max_pool],1) \n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=TwtModel(bertmodel)\n",
    "model = model.to(device)\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': WD},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=LR, eps=EPS)\n",
    "t_total = int(EPOCHS*len(dl))\n",
    "scheduler = SCHDLR_FUNC(\n",
    "    optimizer, \n",
    "    num_warmup_steps=int(WARMUP_RATE*t_total), \n",
    "    num_training_steps=t_total,\n",
    "    num_cycles=N_CYCLS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 20:47:40 epoch 0 starts\n",
      "0 0.714836597442627\n",
      "100 0.5785242915153503\n",
      "200 0.37898576259613037\n",
      "300 0.3492462635040283\n",
      "400 0.3777930438518524\n",
      "500 0.2081422209739685\n",
      "600 0.22332069277763367\n",
      "700 0.19154012203216553\n",
      "800 0.20531690120697021\n",
      "900 0.3143617808818817\n",
      "1000 0.1878468096256256\n",
      "1100 0.16255980730056763\n",
      "1200 0.2713010907173157\n",
      "1300 0.40963882207870483\n",
      "1400 0.36319470405578613\n",
      "1500 0.34884780645370483\n",
      "1600 0.21671830117702484\n",
      "1700 0.2313794493675232\n",
      "1800 0.1792050451040268\n",
      "1900 0.2604365348815918\n",
      "2000 0.17257142066955566\n",
      "2100 0.1810152232646942\n",
      "2200 0.3823032081127167\n",
      "2300 0.3344581127166748\n",
      "2400 0.23860672116279602\n",
      "2500 0.27880141139030457\n",
      "2600 0.28563255071640015\n",
      "2700 0.18617449700832367\n",
      "2800 0.3656902313232422\n",
      "2900 0.37608739733695984\n",
      "3000 0.3149733245372772\n",
      "3100 0.3387591242790222\n",
      "3200 0.195344015955925\n",
      "3300 0.3260330259799957\n",
      "3400 0.2826628088951111\n",
      "3500 0.18479816615581512\n",
      "3600 0.19104349613189697\n",
      "3700 0.27274203300476074\n",
      "3800 0.22895443439483643\n",
      "3900 0.21390706300735474\n",
      "4000 0.3014048933982849\n",
      "4100 0.30673837661743164\n",
      "4200 0.1255146861076355\n",
      "4300 0.31386029720306396\n",
      "4400 0.5773439407348633\n",
      "4500 0.28621411323547363\n",
      "4600 0.16128215193748474\n",
      "4700 0.17123615741729736\n",
      "4800 0.25497424602508545\n",
      "4900 0.2166123390197754\n",
      "5000 0.3060474395751953\n",
      "5100 0.18684756755828857\n",
      "5200 0.27723705768585205\n",
      "5300 0.22310630977153778\n",
      "5400 0.20540408790111542\n",
      "5500 0.16008564829826355\n",
      "5600 0.3207803964614868\n",
      "5700 0.19721196591854095\n",
      "5800 0.17699210345745087\n",
      "5900 0.29363083839416504\n",
      "6000 0.19361233711242676\n",
      "6100 0.16844937205314636\n",
      "6200 0.17401039600372314\n",
      "6300 0.20640525221824646\n",
      "6400 0.3561798930168152\n",
      "6500 0.19860342144966125\n",
      "6600 0.22251996397972107\n",
      "6700 0.36510562896728516\n",
      "6800 0.38851046562194824\n",
      "6900 0.3724437654018402\n",
      "7000 0.3106101155281067\n",
      "7100 0.4999668598175049\n",
      "7200 0.49723944067955017\n",
      "7300 0.31832653284072876\n",
      "7400 0.52610182762146\n",
      "7500 0.1730729192495346\n",
      "7600 0.22248326241970062\n",
      "7700 0.4304412007331848\n",
      "7800 0.2654880881309509\n",
      "7900 0.2530617415904999\n",
      "8000 0.29892784357070923\n",
      "8100 0.3738291263580322\n",
      "8200 0.3013821244239807\n",
      "8300 0.22367751598358154\n",
      "8400 0.20595628023147583\n",
      "8500 0.3992089629173279\n",
      "8600 0.1630590409040451\n",
      "8700 0.1880950629711151\n",
      "8800 0.42768368124961853\n",
      "8900 0.18522891402244568\n",
      "9000 0.21270525455474854\n",
      "9100 0.3753097653388977\n",
      "9200 0.3056109547615051\n",
      "9300 0.1379280835390091\n",
      "9400 0.28816908597946167\n",
      "9500 0.4176214635372162\n",
      "9600 0.1844836175441742\n",
      "9700 0.4207548499107361\n",
      "9800 0.17747431993484497\n",
      "9900 0.41947945952415466\n",
      "10000 0.18360576033592224\n",
      "10100 0.3030446469783783\n",
      "10200 0.3779637813568115\n",
      "10300 0.1767595261335373\n",
      "10400 0.1239112839102745\n",
      "10500 0.12940222024917603\n",
      "10600 0.13889920711517334\n",
      "10700 0.19880691170692444\n",
      "10800 0.3062722384929657\n",
      "10900 0.1902751922607422\n",
      "11000 0.3467366099357605\n",
      "11100 0.4791244864463806\n",
      "11200 0.22583329677581787\n",
      "11300 0.21454660594463348\n",
      "11400 0.43822145462036133\n",
      "11500 0.4444297254085541\n",
      "11600 0.21011540293693542\n",
      "11700 0.4539639949798584\n",
      "11800 0.2577172517776489\n",
      "11900 0.2539847493171692\n",
      "12000 0.22854575514793396\n",
      "12100 0.32930922508239746\n",
      "12200 0.33661895990371704\n",
      "12300 0.3593445420265198\n",
      "12400 0.1270139068365097\n",
      "12500 0.45178812742233276\n",
      "12600 0.2517138123512268\n",
      "12700 0.3066686987876892\n",
      "12800 0.19627639651298523\n",
      "12900 0.19299006462097168\n",
      "13000 0.2069050520658493\n",
      "13100 0.18081125617027283\n",
      "13200 0.5004842281341553\n",
      "13300 0.2052605152130127\n",
      "13400 0.4004842936992645\n",
      "13500 0.200185164809227\n",
      "13600 0.2421712875366211\n",
      "13700 0.4193437099456787\n",
      "13800 0.17892715334892273\n",
      "13900 0.2161279320716858\n",
      "14000 0.18815265595912933\n",
      "14100 0.13980525732040405\n",
      "14200 0.3531671464443207\n",
      "14300 0.28592848777770996\n",
      "14400 0.18378698825836182\n",
      "14500 0.1662183254957199\n",
      "14600 0.2100570648908615\n",
      "14700 0.19917502999305725\n",
      "14800 0.16426557302474976\n",
      "14900 0.19016051292419434\n",
      "15000 0.24809524416923523\n",
      "15100 0.34506747126579285\n",
      "15200 0.2266407012939453\n",
      "15300 0.4880363941192627\n",
      "15400 0.314713716506958\n",
      "15500 0.20311683416366577\n",
      "15600 0.2977180480957031\n",
      "15700 0.4383278787136078\n",
      "15800 0.29627639055252075\n",
      "15900 0.21942119300365448\n",
      "16000 0.5094054937362671\n",
      "16100 0.385577917098999\n",
      "16200 0.4059779644012451\n",
      "16300 0.27543219923973083\n",
      "16400 0.36899805068969727\n",
      "16500 0.2849214971065521\n",
      "16600 0.38546985387802124\n",
      "2020-03-27 01:59:59 epoch 1 starts\n",
      "0 0.3469926118850708\n",
      "100 0.21707475185394287\n",
      "200 0.21729633212089539\n",
      "300 0.4037775993347168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7849020ebb92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update learning rate schedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rcss20/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rcss20/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(dtnow(), f'epoch {epoch} starts')\n",
    "    y_tr_epoch = []\n",
    "    y_pred_tr_epoch = []\n",
    "    for step, batch in enumerate(dl):\n",
    "        model.train()\n",
    "        x_b,ys_b = (o.to(device) for o in batch)\n",
    "        yb_pred = model(x_b)\n",
    "\n",
    "        loss =  F.binary_cross_entropy_with_logits(yb_pred,ys_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        model.zero_grad()\n",
    "        if step%100==0: print(step, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
