{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:8889/notebooks/git/google-quest-challenge/working/QstBertBase0113_1.ipynb\n",
    "\n",
    "no freezing of bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRFX='b0326_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-03-17 02:32:24', '2020-03-24 17:09:45']\n",
      "['2020-02-06 00:00:00', '2020-02-13 00:00:00']\n"
     ]
    }
   ],
   "source": [
    "trntmstmp=1584412344\n",
    "valtmstmp=1585069785\n",
    "\n",
    "import datetime\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (trntmstmp, valtmstmp)])\n",
    "\n",
    "grand_total=1.5e8\n",
    "MIN_TM_TRN=1580947200\n",
    "MIN_TM_TST=1581552000\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (MIN_TM_TRN, MIN_TM_TST)])\n",
    "\n",
    "\n",
    "SEED=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 27 03:29:37 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   65C    P0    73W / 149W |      0MiB / 11441MiB |     95%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import datetime\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "SEED=101\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "p_out = f'{HOME}/output/{PRFX}'\n",
    "from pathlib import Path\n",
    "Path(p_out).mkdir(exist_ok=True)\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "import torch\n",
    "device=torch.device('cuda')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pretrained_weights='bert-base-multilingual-cased'\n",
    "bertmodel = BertModel.from_pretrained(pretrained_weights, output_hidden_states=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights, do_lower_case=False)\n",
    "\n",
    "import random\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Retweet': 'retwt',\n",
       " 'Reply': 'reply',\n",
       " 'Like': 'like',\n",
       " 'RTwCmnt': 'retwt_cmmnt'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=[\n",
    "'toks',\n",
    "'hshtgs',\n",
    "'twtid',\n",
    "'media',\n",
    "'links',\n",
    "'domns',\n",
    "'twttyp',\n",
    "'lang',\n",
    "'tm',\n",
    "\n",
    "'u1id',\n",
    "'u1_fllwer_cnt',\n",
    "'u1_fllwng_cnt',\n",
    "'u1_vrfed',\n",
    "'u1_create_tm',\n",
    "\n",
    "'u2id',\n",
    "'u2_fllwer_cnt',\n",
    "'u2_fllwng_cnt',\n",
    "'u2_vrfed',\n",
    "'u2_create_tm',\n",
    "\n",
    "'u1_fllw_u2',\n",
    "'reply_tm',\n",
    "'retwt_tm',\n",
    "'retwt_cmmnt_tm',\n",
    "'like_tm',\n",
    "]\n",
    "cols_cat = ['twttyp','lang']\n",
    "cols_val = cols[:-4]\n",
    "cols_tgt_tmstmp=[\n",
    "    'retwt_tm',\n",
    "    'reply_tm',\n",
    "    'like_tm',\n",
    "    'retwt_cmmnt_tm',\n",
    "]\n",
    "cols_tgt=[o.split('_tm')[0] for o in cols_tgt_tmstmp]\n",
    "tgts             = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "assert cols_tgt == ['retwt',  'reply','like','retwt_cmmnt',]\n",
    "ntgts=len(tgts)\n",
    "\n",
    "\n",
    "tgt2col=dict(zip(tgts,cols_tgt))\n",
    "tgt2col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.76 s, sys: 637 ms, total: 8.39 s\n",
      "Wall time: 8.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dftrn=pd.read_csv(\n",
    "    f'{p_in}/trn_{trntmstmp}.tsv',\n",
    "    sep='\\x01', header=None, \n",
    "    encoding='utf-8', \n",
    "    names=cols, \n",
    "    nrows=1e6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = dftrn.toks.apply(lambda x: len(x.split('\\t')))\n",
    "# lens.mean(), np.percentile(lens, 50), np.percentile(lens, 95), np.percentile(lens, 99)\n",
    "# (46.754583, 41.0, 106.0, 135.0)\n",
    "\n",
    "\n",
    "# tokenizer.pad_token, tokenizer.pad_token_id\n",
    "# ('[PAD]', 0)\n",
    "\n",
    "# tokenizer.sep_token, tokenizer.sep_token_id\n",
    "# ('[SEP]', 102)\n",
    "maxlen=128\n",
    "def mkids(x):\n",
    "    tokids=list(map(int, x.split('\\t')))\n",
    "    l=len(tokids) \n",
    "    if l<=maxlen: \n",
    "        return tokids + [0]*(maxlen-len(tokids))\n",
    "    else: \n",
    "        return tokids[:maxlen-1]+[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_tensors(df, istrn=True):\n",
    "    tokids=dftrn.toks.apply(lambda x: mkids(x))\n",
    "    Xarr=np.array(list(tokids))\n",
    "    X=torch.tensor(Xarr,dtype=torch.long)\n",
    "    if not istrn: return X\n",
    "    ys=dftrn[cols_tgt_tmstmp].notna().values\n",
    "    ys=torch.tensor(ys,dtype=torch.float)\n",
    "    return X,ys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X,ys = mk_tensors(dftrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BS=2\n",
    "# ds = TensorDataset(X,ys)\n",
    "# dl = DataLoader(ds, batch_size=BS, shuffle=True)\n",
    "# for step, batch in enumerate(dl):\n",
    "#     X_b,ys_b = (o.to(device) for o in batch)\n",
    "#     print(X_b.shape,ys_b.shape)\n",
    "#     break\n",
    "# torch.Size([2, 128]) torch.Size([2, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS=8\n",
    "EPOCHS=4\n",
    "WD=0.01\n",
    "LR=1e-5\n",
    "SCHDLR_FUNC = get_cosine_schedule_with_warmup \n",
    "WARMUP_RATE = 0.05\n",
    "N_CYCLS = .5\n",
    "EPS = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = TensorDataset(X,ys)\n",
    "# dl = DataLoader(ds, batch_size=BS, shuffle=True)\n",
    "# for step, batch in enumerate(dl):\n",
    "#     X_b,ys_b = (o.to(device) for o in batch)\n",
    "#     print(X_b.shape,ys_b.shape)\n",
    "#     break\n",
    "\n",
    "# # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "# bertmodel=bertmodel.eval()\n",
    "# bertmodel.to(device)\n",
    "# with torch.no_grad():\n",
    "#     last_hidden_state, pooler_output, hidden_states = bertmodel(X_b,)\n",
    "#     avg_pool = torch.mean(last_hidden_state,1)\n",
    "#     max_pool,_ = torch.max(last_hidden_state,1)\n",
    "# last_hidden_state.shape,pooler_output.shape, len(hidden_states), avg_pool.shape, max_pool.shape\n",
    "# (torch.Size([2, 128, 768]),\n",
    "#  torch.Size([2, 768]),\n",
    "#  13,\n",
    "#  torch.Size([2, 768]),\n",
    "#  torch.Size([2, 768]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see RobertaClassificationHead in transformers/modeling_roberta.py\n",
    "N_HIDDEN = 768 \n",
    "class TwtModel(nn.Module):\n",
    "    def __init__(self, bertmodel, num_labels=4):\n",
    "        super(TwtModel, self).__init__()\n",
    "        self.bertmodel = bertmodel        \n",
    "        dense_size = 64\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        nx = N_HIDDEN*2\n",
    "        self.dense = nn.Linear(nx, nx)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_proj = nn.Linear(nx, num_labels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_msk = (x!=tokenizer.pad_token_id).float().to(device)\n",
    "        segments = torch.zeros(x.shape, dtype=torch.long).to(device)\n",
    "        bert_output=self.bertmodel(x,attention_mask=attn_msk,token_type_ids=segments)\n",
    "        last_hidden_state,pooler_output,hidden_states = bert_output\n",
    "        avg_pool = torch.mean(last_hidden_state,1)\n",
    "        max_pool,_ = torch.max(last_hidden_state,1)\n",
    "        x = torch.cat([avg_pool,max_pool],1) \n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_vl = np.random.rand(len(X))<0.15\n",
    "tr = np.where(~msk_vl)[0]\n",
    "vl = np.where( msk_vl)[0]\n",
    "Xtr,Xvl = X[tr],X[vl]\n",
    "ys_tr, ys_vl = ys[tr], ys[vl]\n",
    "ds_tr = TensorDataset(Xtr,ys_tr)\n",
    "ds_vl = TensorDataset(Xvl,ys_vl)\n",
    "dl_tr = DataLoader(ds_tr, batch_size=BS,   pin_memory=True, shuffle=True)\n",
    "dl_vl = DataLoader(ds_vl, batch_size=BS, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwtModel(bertmodel)\n",
    "model = model.to(device)\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': WD},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=LR, eps=EPS)\n",
    "t_total = int(EPOCHS*len(dl_tr))\n",
    "scheduler = SCHDLR_FUNC(\n",
    "    optimizer, \n",
    "    num_warmup_steps=int(WARMUP_RATE*t_total), \n",
    "    num_training_steps=t_total,\n",
    "    num_cycles=N_CYCLS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl):\n",
    "    prd = []\n",
    "    ys = []\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    for step, dat_b in enumerate(dl):\n",
    "        model.eval()\n",
    "        x_b,ys_b = (o.to(device) for o in dat_b)\n",
    "        prd_b = model(x_b)\n",
    "\n",
    "        ys.append(ys_b.cpu().detach().numpy())\n",
    "        prd.append(prd_b.cpu().detach().numpy())\n",
    "\n",
    "        loss_ =  F.binary_cross_entropy_with_logits(prd_b,ys_b)\n",
    "        losses.append(loss_.item())\n",
    "\n",
    "    prd = np.concatenate(prd)\n",
    "    ys = np.concatenate(ys)\n",
    "    scrs = [roc_auc_score(ys[:,i], prd[:,i]) for i in range(4)]\n",
    "    scr  = roc_auc_score(ys, prd)\n",
    "    loss = np.mean(losses)\n",
    "    return prd, ys, scrs, scr, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-27 03:30:28 epoch 0 starts\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6e6acb4545cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rcss20/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rcss20/lib/python3.7/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "set_seed(SEED)\n",
    "\n",
    "epc2loss_tr = []\n",
    "epc2loss_vl = []\n",
    "epc2scrs_tr = []\n",
    "epc2scrs_vl = []\n",
    "best_scr = float('-inf')\n",
    "save_p = f'{p_out}/mdl.p'\n",
    "for epoch in range(EPOCHS):\n",
    "    print(dtnow(), f'epoch {epoch} starts')\n",
    "    ys_tr_ep = []\n",
    "    prd_tr_ep = []\n",
    "    for step, dat_b in enumerate(dl_tr):\n",
    "        model.train()\n",
    "        x_b,ys_b = (o.to(device) for o in dat_b)\n",
    "        prd_b = model(x_b)\n",
    "        loss =  F.binary_cross_entropy_with_logits(prd_b,ys_b)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        ys_tr_ep.append(ys_b.cpu().detach().numpy())\n",
    "        prd_tr_ep.append(prd_b.cpu().detach().numpy())\n",
    "\n",
    "    prd_tr_ep = np.concatenate(prd_tr_ep)\n",
    "    ys_tr_ep = np.concatenate(ys_tr_ep)\n",
    "    scrs_tr = [roc_auc_score(ys_tr_ep[:,i], prd_tr_ep[:,i]) for i in range(4)]\n",
    "    scr_tr  = roc_auc_score(ys_tr_ep, prd_tr_ep)\n",
    "    loss_tr = loss.item()\n",
    "    \n",
    "    prd_vl_ep,ys_vl_ep,scrs_vl,scr_vl,loss_vl = evaluate(model, dl_vl)\n",
    "    print(f'lss_tr: {loss_tr: .4f}; scr_tr: {scr_tr: .4f}; {scrs_tr}')\n",
    "    print(f'lss_vl: {loss_vl: .4f}; scr_vl: {scr_vl: .4f}; {scrs_vl}')\n",
    "    if scr_vl>best_scr: \n",
    "        best_scr = scr_vl\n",
    "        best_prd_vl = prd_vl_ep\n",
    "        print(f'found better scr, saving model...')\n",
    "        torch.save(model.state_dict(),save_p)\n",
    "    \n",
    "    epc2loss_tr.append(loss_tr)\n",
    "    epc2loss_vl.append(loss_vl)\n",
    "    epc2scrs_tr.append(scrs_tr)\n",
    "    epc2scrs_vl.append(scrs_vl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73985, 106285)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step, len(dl_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
