{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRFX='b0327_2_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-03-17 02:32:24', '2020-03-24 17:09:45']\n",
      "['2020-02-06 00:00:00', '2020-02-13 00:00:00']\n"
     ]
    }
   ],
   "source": [
    "trntmstmp=1584412344\n",
    "valtmstmp=1585069785\n",
    "\n",
    "import datetime\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (trntmstmp, valtmstmp)])\n",
    "\n",
    "grand_total=1.5e8\n",
    "MIN_TM_TRN=1580947200\n",
    "MIN_TM_TST=1581552000\n",
    "print([datetime.datetime.fromtimestamp(o).strftime('%Y-%m-%d %H:%M:%S') for o in (MIN_TM_TRN, MIN_TM_TST)])\n",
    "\n",
    "\n",
    "SEED=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 27 16:41:24 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   60C    P0    45W / 300W |      0MiB / 16130MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import datetime\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "SEED=101\n",
    "HOME='/data/git/recsys20'\n",
    "p_in=f'{HOME}/input'\n",
    "p_out = f'{HOME}/output/{PRFX}'\n",
    "from pathlib import Path\n",
    "Path(p_out).mkdir(exist_ok=True)\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "import torch\n",
    "device=torch.device('cuda')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pretrained_weights='bert-base-multilingual-cased'\n",
    "bertmodel = BertModel.from_pretrained(pretrained_weights, output_hidden_states=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights, do_lower_case=False)\n",
    "\n",
    "import random\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Retweet': 'retwt',\n",
       " 'Reply': 'reply',\n",
       " 'Like': 'like',\n",
       " 'RTwCmnt': 'retwt_cmmnt'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=[\n",
    "'toks','hshtgs','twtid','media','links','domns','twttyp','lang','tm',\n",
    "'u1id','u1_fllwer_cnt','u1_fllwng_cnt','u1_vrfed','u1_create_tm',\n",
    "'u2id','u2_fllwer_cnt','u2_fllwng_cnt','u2_vrfed','u2_create_tm',\n",
    "'u1_fllw_u2','reply_tm','retwt_tm','retwt_cmmnt_tm','like_tm',]\n",
    "cols_cat = ['twttyp','lang']\n",
    "cols_val = cols[:-4]\n",
    "cols_tgt_tmstmp=[\n",
    "    'retwt_tm',\n",
    "    'reply_tm',\n",
    "    'like_tm',\n",
    "    'retwt_cmmnt_tm',\n",
    "]\n",
    "cols_tgt=[o.split('_tm')[0] for o in cols_tgt_tmstmp]\n",
    "tgts             = ['Retweet','Reply','Like','RTwCmnt',]\n",
    "assert cols_tgt == ['retwt',  'reply','like','retwt_cmmnt',]\n",
    "ntgts=len(tgts)\n",
    "\n",
    "\n",
    "tgt2col=dict(zip(tgts,cols_tgt))\n",
    "tgt2col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 616 ms, sys: 91.8 ms, total: 707 ms\n",
      "Wall time: 707 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dftrn=pd.read_csv(f'{p_in}/trn_{trntmstmp}.tsv',sep='\\x01',header=None,encoding='utf-8',names=cols, \n",
    "    nrows=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = dftrn.toks.apply(lambda x: len(x.split('\\t')))\n",
    "# lens.mean(), np.percentile(lens, 50), np.percentile(lens, 95), np.percentile(lens, 99)\n",
    "# (46.754583, 41.0, 106.0, 135.0)\n",
    "\n",
    "\n",
    "# tokenizer.pad_token, tokenizer.pad_token_id\n",
    "# ('[PAD]', 0)\n",
    "\n",
    "# tokenizer.sep_token, tokenizer.sep_token_id\n",
    "# ('[SEP]', 102)\n",
    "maxlen=128\n",
    "def mkids(x):\n",
    "    tokids=list(map(int, x.split('\\t')))\n",
    "    l=len(tokids) \n",
    "    if l<=maxlen: \n",
    "        return tokids + [0]*(maxlen-len(tokids))\n",
    "    else: \n",
    "        return tokids[:maxlen-1]+[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_tensors(df, istrn=True):\n",
    "    tokids=dftrn.toks.apply(lambda x: mkids(x))\n",
    "    Xarr=np.array(list(tokids))\n",
    "    X=torch.tensor(Xarr,dtype=torch.long)\n",
    "    if not istrn: return X\n",
    "    ys=dftrn[cols_tgt_tmstmp].notna().values\n",
    "    ys=torch.tensor(ys,dtype=torch.float)\n",
    "    return X,ys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X,ys = mk_tensors(dftrn)\n",
    "\n",
    "# BS=2\n",
    "# ds = TensorDataset(X,ys)\n",
    "# dl = DataLoader(ds, batch_size=BS, shuffle=True)\n",
    "# for step, batch in enumerate(dl):\n",
    "#     X_b,ys_b = (o.to(device) for o in batch)\n",
    "#     print(X_b.shape,ys_b.shape)\n",
    "#     break\n",
    "# torch.Size([2, 128]) torch.Size([2, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = TensorDataset(X,ys)\n",
    "# dl = DataLoader(ds, batch_size=BS, shuffle=True)\n",
    "# for step, batch in enumerate(dl):\n",
    "#     X_b,ys_b = (o.to(device) for o in batch)\n",
    "#     print(X_b.shape,ys_b.shape)\n",
    "#     break\n",
    "\n",
    "# # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "# bertmodel=bertmodel.eval()\n",
    "# bertmodel.to(device)\n",
    "# with torch.no_grad():\n",
    "#     last_hidden_state, pooler_output, hidden_states = bertmodel(X_b,)\n",
    "#     avg_pool = torch.mean(last_hidden_state,1)\n",
    "#     max_pool,_ = torch.max(last_hidden_state,1)\n",
    "# last_hidden_state.shape,pooler_output.shape, len(hidden_states), avg_pool.shape, max_pool.shape\n",
    "# (torch.Size([2, 128, 768]),\n",
    "#  torch.Size([2, 768]),\n",
    "#  13,\n",
    "#  torch.Size([2, 768]),\n",
    "#  torch.Size([2, 768]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see RobertaClassificationHead in transformers/modeling_roberta.py\n",
    "N_HIDDEN = 768 \n",
    "class TwtModel(nn.Module):\n",
    "    def __init__(self, bertmodel, num_labels=4):\n",
    "        super(TwtModel, self).__init__()\n",
    "        self.bertmodel = bertmodel        \n",
    "        dense_size = 64\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        nx = N_HIDDEN*2\n",
    "        self.dense = nn.Linear(nx, nx)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_proj = nn.Linear(nx, num_labels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_msk = (x!=tokenizer.pad_token_id).float().to(device)\n",
    "        segments = torch.zeros(x.shape, dtype=torch.long).to(device)\n",
    "        bert_output=self.bertmodel(x,attention_mask=attn_msk,token_type_ids=segments)\n",
    "        last_hidden_state,pooler_output,hidden_states = bert_output\n",
    "        avg_pool = torch.mean(last_hidden_state,1)\n",
    "        max_pool,_ = torch.max(last_hidden_state,1)\n",
    "        x = torch.cat([avg_pool,max_pool],1) \n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS=104\n",
    "EPOCHS=4\n",
    "WD=0.01\n",
    "LR=1e-5\n",
    "SCHDLR_FUNC = get_cosine_schedule_with_warmup \n",
    "WARMUP_RATE = 0.05\n",
    "N_CYCLS = .5\n",
    "EPS = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X,ys = mk_tensors(dftrn)\n",
    "\n",
    "msk_vl = np.random.rand(len(X))<0.15\n",
    "tr = np.where(~msk_vl)[0]\n",
    "vl = np.where( msk_vl)[0]\n",
    "Xtr,Xvl = X[tr],X[vl]\n",
    "ys_tr, ys_vl = ys[tr], ys[vl]\n",
    "ds_tr = TensorDataset(Xtr,ys_tr)\n",
    "ds_vl = TensorDataset(Xvl,ys_vl)\n",
    "dl_tr = DataLoader(ds_tr, batch_size=BS,   pin_memory=True, shuffle=True)\n",
    "dl_vl = DataLoader(ds_vl, batch_size=BS, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwtModel(bertmodel)\n",
    "model = model.to(device)\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': WD},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=LR, eps=EPS)\n",
    "t_total = int(EPOCHS*len(dl_tr))\n",
    "scheduler = SCHDLR_FUNC(\n",
    "    optimizer, \n",
    "    num_warmup_steps=int(WARMUP_RATE*t_total), \n",
    "    num_training_steps=t_total,\n",
    "    num_cycles=N_CYCLS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl):\n",
    "    prd = []\n",
    "    ys = []\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    for step, dat_b in enumerate(dl):\n",
    "        model.eval()\n",
    "        x_b,ys_b = (o.to(device) for o in dat_b)\n",
    "        with torch.no_grad(): \n",
    "            prd_b = model(x_b)\n",
    "            loss_ =  F.binary_cross_entropy_with_logits(prd_b,ys_b)\n",
    "\n",
    "        ys.append(ys_b.cpu().detach().numpy())\n",
    "        prd.append(prd_b.cpu().detach().numpy())\n",
    "        losses.append(loss_.item())\n",
    "\n",
    "    prd = np.concatenate(prd)\n",
    "    ys = np.concatenate(ys)\n",
    "    scrs = [roc_auc_score(ys[:,i], prd[:,i]) for i in range(4)]\n",
    "    scr  = roc_auc_score(ys, prd)\n",
    "    loss = np.mean(losses)\n",
    "    return prd, ys, scrs, scr, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-27 16:41:39 epoch 0 starts\n",
      "2020-03-27 16:41:39 step 0/819 loss 0.6493\n",
      "2020-03-27 16:42:46 step 100/819 loss 0.2942\n",
      "2020-03-27 16:43:53 step 200/819 loss 0.2597\n",
      "2020-03-27 16:45:01 step 300/819 loss 0.2455\n",
      "2020-03-27 16:46:08 step 400/819 loss 0.2860\n",
      "2020-03-27 16:47:15 step 500/819 loss 0.2828\n",
      "2020-03-27 16:48:23 step 600/819 loss 0.2684\n",
      "2020-03-27 16:49:30 step 700/819 loss 0.2592\n",
      "2020-03-27 16:50:38 step 800/819 loss 0.2865\n",
      "lss_tr:  0.2199; scr_tr:  0.6062; [0.6196330233299571, 0.6405234923567255, 0.6558320242349607, 0.5086409276991417]\n",
      "lss_vl:  0.2809; scr_vl:  0.6621; [0.676166159541905, 0.6965482908924066, 0.6874724164238168, 0.5882806684374365]\n",
      "found better scr, saving model...\n",
      "2020-03-27 16:51:20 epoch 1 starts\n",
      "2020-03-27 16:51:21 step 0/819 loss 0.2768\n",
      "2020-03-27 16:52:28 step 100/819 loss 0.2743\n",
      "2020-03-27 16:53:36 step 200/819 loss 0.2996\n",
      "2020-03-27 16:54:43 step 300/819 loss 0.2965\n",
      "2020-03-27 16:55:50 step 400/819 loss 0.2879\n",
      "2020-03-27 16:56:58 step 500/819 loss 0.2569\n",
      "2020-03-27 16:58:05 step 600/819 loss 0.2858\n",
      "2020-03-27 16:59:13 step 700/819 loss 0.2809\n",
      "2020-03-27 17:00:20 step 800/819 loss 0.2727\n",
      "lss_tr:  0.2764; scr_tr:  0.6788; [0.6941224838852312, 0.7181277440479577, 0.6995434390822011, 0.6033898264513702]\n",
      "lss_vl:  0.2796; scr_vl:  0.6787; [0.6890968176215622, 0.7108150493232392, 0.6944935062413783, 0.620241496497936]\n",
      "found better scr, saving model...\n",
      "2020-03-27 17:01:05 epoch 2 starts\n",
      "2020-03-27 17:01:06 step 0/819 loss 0.2878\n",
      "2020-03-27 17:02:13 step 100/819 loss 0.2698\n",
      "2020-03-27 17:03:21 step 200/819 loss 0.2638\n",
      "2020-03-27 17:04:28 step 300/819 loss 0.2636\n",
      "2020-03-27 17:05:36 step 400/819 loss 0.2608\n",
      "2020-03-27 17:06:43 step 500/819 loss 0.3447\n",
      "2020-03-27 17:07:50 step 600/819 loss 0.2606\n",
      "2020-03-27 17:08:58 step 700/819 loss 0.2626\n",
      "2020-03-27 17:10:05 step 800/819 loss 0.2778\n",
      "lss_tr:  0.1921; scr_tr:  0.7159; [0.729934946956979, 0.7495416054743884, 0.7269165487372284, 0.6572696961486523]\n",
      "lss_vl:  0.2810; scr_vl:  0.6779; [0.6909516207525459, 0.7150750172057811, 0.6940056414092401, 0.6116578974081344]\n",
      "2020-03-27 17:10:47 epoch 3 starts\n",
      "2020-03-27 17:10:48 step 0/819 loss 0.2684\n",
      "2020-03-27 17:11:55 step 100/819 loss 0.2997\n",
      "2020-03-27 17:13:03 step 200/819 loss 0.2639\n",
      "2020-03-27 17:14:10 step 300/819 loss 0.2374\n",
      "2020-03-27 17:15:18 step 400/819 loss 0.2131\n",
      "2020-03-27 17:16:25 step 500/819 loss 0.2378\n",
      "2020-03-27 17:17:32 step 600/819 loss 0.3181\n",
      "2020-03-27 17:18:40 step 700/819 loss 0.2731\n",
      "2020-03-27 17:19:48 step 800/819 loss 0.2549\n",
      "lss_tr:  0.2688; scr_tr:  0.7420; [0.7533322409923672, 0.7714639075273408, 0.7460726978717755, 0.6969952710157065]\n",
      "lss_vl:  0.2839; scr_vl:  0.6742; [0.6906022504514093, 0.713343794448268, 0.6917082994533242, 0.6010499319043108]\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "set_seed(SEED)\n",
    "\n",
    "epc2loss_tr = []\n",
    "epc2loss_vl = []\n",
    "epc2scrs_tr = []\n",
    "epc2scrs_vl = []\n",
    "best_scr = float('-inf')\n",
    "save_p = f'{p_out}/mdl_{PRFX}.p'\n",
    "lendl = len(dl_tr)\n",
    "for epoch in range(EPOCHS):\n",
    "    print(dtnow(), f'epoch {epoch} starts')\n",
    "    ys_tr_ep = []\n",
    "    prd_tr_ep = []\n",
    "    for step, dat_b in enumerate(dl_tr):\n",
    "        model.train()\n",
    "        x_b,ys_b = (o.to(device) for o in dat_b)\n",
    "        prd_b = model(x_b)\n",
    "        loss =  F.binary_cross_entropy_with_logits(prd_b,ys_b)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        ys_tr_ep.append(ys_b.cpu().detach().numpy())\n",
    "        prd_tr_ep.append(prd_b.cpu().detach().numpy())\n",
    "        if step%100==0: print(dtnow(),f'step {step}/{lendl} loss {loss.item():.4f}')\n",
    "\n",
    "    prd_tr_ep = np.concatenate(prd_tr_ep)\n",
    "    ys_tr_ep = np.concatenate(ys_tr_ep)\n",
    "    scrs_tr = [roc_auc_score(ys_tr_ep[:,i], prd_tr_ep[:,i]) for i in range(4)]\n",
    "    scr_tr  = roc_auc_score(ys_tr_ep, prd_tr_ep)\n",
    "    loss_tr = loss.item()\n",
    "    \n",
    "    prd_vl_ep,ys_vl_ep,scrs_vl,scr_vl,loss_vl = evaluate(model, dl_vl)\n",
    "    print(f'lss_tr: {loss_tr: .4f}; scr_tr: {scr_tr: .4f}; {scrs_tr}')\n",
    "    print(f'lss_vl: {loss_vl: .4f}; scr_vl: {scr_vl: .4f}; {scrs_vl}')\n",
    "    if scr_vl>best_scr: \n",
    "        best_scr = scr_vl\n",
    "        best_prd_vl = prd_vl_ep\n",
    "        print(f'found better scr, saving model...')\n",
    "        torch.save(model.state_dict(),save_p)\n",
    "    \n",
    "    epc2loss_tr.append(loss_tr)\n",
    "    epc2loss_vl.append(loss_vl)\n",
    "    epc2scrs_tr.append(scrs_tr)\n",
    "    epc2scrs_vl.append(scrs_vl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2199435532093048, 0.27635905146598816, 0.1920751929283142, 0.2687980830669403]\n",
      "[0.2808614590515693, 0.27961794804367757, 0.2810440832335088, 0.2838532006781962]\n"
     ]
    }
   ],
   "source": [
    "print(epc2loss_tr)\n",
    "print(epc2loss_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61963302 0.64052349 0.65583202 0.50864093]\n",
      " [0.69412248 0.71812774 0.69954344 0.60338983]\n",
      " [0.72993495 0.74954161 0.72691655 0.6572697 ]\n",
      " [0.75333224 0.77146391 0.7460727  0.69699527]]\n",
      "[[0.67616616 0.69654829 0.68747242 0.58828067]\n",
      " [0.68909682 0.71081505 0.69449351 0.6202415 ]\n",
      " [0.69095162 0.71507502 0.69400564 0.6116579 ]\n",
      " [0.69060225 0.71334379 0.6917083  0.60104993]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(epc2scrs_tr))\n",
    "print(np.array(epc2scrs_vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcss20",
   "language": "python",
   "name": "rcss20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
